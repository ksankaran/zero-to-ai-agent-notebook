{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: Tools and Functions - Solutions\n",
    "**From: Zero to AI Agent**\n",
    "\n",
    "**Try the exercises in the main notebook first before viewing solutions!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 12.1 Solutions: Why Tools Matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.1.1 Solution: Tool or No Tool?\n",
    "\n",
    "Let's analyze each scenario:\n",
    "\n",
    "1. **Write a haiku about summer**\n",
    "   - **No tool needed**: LLM can handle this\n",
    "   - **Why**: Creative writing task, requires language generation\n",
    "   - **If tool used anyway**: Unnecessary complexity, slower response\n",
    "\n",
    "2. **Get today's date**\n",
    "   - **Tool needed**: Yes - Date/time tool\n",
    "   - **Why**: Current, real-time information\n",
    "   - **Tool type**: System date tool\n",
    "   - **If no tool**: Would give wrong or no date\n",
    "\n",
    "3. **Explain quantum physics**\n",
    "   - **No tool needed**: LLM has this knowledge\n",
    "   - **Why**: Established concept in training data\n",
    "   - **If tool used**: Would just slow down the response unnecessarily\n",
    "\n",
    "4. **Check if a file exists**\n",
    "   - **Tool needed**: Yes - File system tool\n",
    "   - **Why**: Needs to interact with actual file system\n",
    "   - **Tool type**: File checking tool\n",
    "   - **If no tool**: Cannot access file system\n",
    "\n",
    "5. **Translate 'hello' to Spanish**\n",
    "   - **No tool needed**: LLM knows common translations\n",
    "   - **Why**: Basic language knowledge in training\n",
    "   - **If tool used**: Overkill for such a simple translation\n",
    "\n",
    "6. **Find the latest news about AI**\n",
    "   - **Tool needed**: Yes - News search tool\n",
    "   - **Why**: \"Latest\" indicates current information needed\n",
    "   - **Tool type**: News API or web search\n",
    "   - **If no tool**: Would only have information up to training cutoff\n",
    "\n",
    "7. **Generate a business name**\n",
    "   - **No tool needed**: LLM excels at creative generation\n",
    "   - **Why**: Creative task requiring language skills\n",
    "   - **If tool used**: No appropriate tool exists for creativity\n",
    "\n",
    "8. **Calculate compound interest**\n",
    "   - **Tool needed**: Yes - Financial calculator tool\n",
    "   - **Why**: Precise financial calculations required\n",
    "   - **Tool type**: Compound interest calculator\n",
    "   - **If no tool**: Risk of calculation errors, especially with complex formulas\n",
    "\n",
    "**Key Pattern**: Tools for current data and calculations, LLM for creativity and knowledge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.1.2 Solution: Trace the Tool Flow\n",
    "\n",
    "Here's the complete flow for the conversation:\n",
    "\n",
    "**Step 1**: User sends message with two requests\n",
    "- Input: \"Search for information about LangChain and calculate 15% of 2000\"\n",
    "\n",
    "**Step 2**: AI parses and recognizes two distinct tasks\n",
    "- Task A: Search for LangChain information (needs search tool)\n",
    "- Task B: Calculate 15% of 2000 (needs calculator tool)\n",
    "\n",
    "**Step 3**: AI decides tool execution order\n",
    "- Likely executes search first (more complex, takes longer)\n",
    "- Plans to execute calculator second\n",
    "\n",
    "**Step 4**: First tool execution - Search\n",
    "- Tool call: `search_tool(\"LangChain\")`\n",
    "- Tool returns: Information about LangChain framework, Harrison Chase, etc.\n",
    "\n",
    "**Step 5**: Second tool execution - Calculator\n",
    "- Tool call: `calculator_tool(\"0.15 * 2000\")` or `calculator_tool(\"2000 * 0.15\")`\n",
    "- Tool returns: \"300\"\n",
    "\n",
    "**Step 6**: AI processes both results\n",
    "- Formats search results into coherent paragraph\n",
    "- Formats calculation result into clear statement\n",
    "\n",
    "**Step 7**: AI combines results into single response\n",
    "- Structures response with both answers\n",
    "- Maintains conversational flow\n",
    "- Returns complete answer to user\n",
    "\n",
    "**Key Insights**:\n",
    "- AI can recognize multiple tasks in one request\n",
    "- Tools can be executed sequentially\n",
    "- Results are combined intelligently\n",
    "- The AI maintains context throughout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.1.3 Solution: Design a Tool Set for a Bakery\n",
    "\n",
    "Here are 5 essential tools for a bakery AI assistant:\n",
    "\n",
    "**Tool 1: order_manager**\n",
    "- **Purpose**: Create, view, and update customer orders\n",
    "- **When used**: \"Add a birthday cake order for Saturday\" or \"What orders do we have for tomorrow?\"\n",
    "- **Inputs**: Action (create/read/update), order details (customer, items, date, special requests)\n",
    "- **Outputs**: Order confirmation or list of orders with details\n",
    "- **Safety**: Validate dates are future dates, check item availability, require customer contact info\n",
    "\n",
    "**Tool 2: recipe_calculator**\n",
    "- **Purpose**: Scale recipes up or down based on needed quantities\n",
    "- **When used**: \"How much flour do I need to make 5 dozen cookies?\" or \"Scale the bread recipe for 20 loaves\"\n",
    "- **Inputs**: Recipe name, desired quantity, unit (dozens, loaves, etc.)\n",
    "- **Outputs**: Adjusted ingredient list with precise measurements\n",
    "- **Safety**: Validate recipe exists, check for reasonable quantities (not 10,000 cookies), warn about oven capacity\n",
    "\n",
    "**Tool 3: price_calculator**\n",
    "- **Purpose**: Calculate prices for custom orders including ingredients, labor, and markup\n",
    "- **When used**: \"How much should we charge for a 3-tier wedding cake?\" or \"What's the cost breakdown for 100 cupcakes?\"\n",
    "- **Inputs**: Item type, quantity, special requirements (decorations, delivery, etc.)\n",
    "- **Outputs**: Itemized cost breakdown and suggested retail price\n",
    "- **Safety**: Ensure minimum price thresholds, validate against pricing rules, flag unusual requests\n",
    "\n",
    "**Tool 4: supplier_contact**\n",
    "- **Purpose**: Check supplier prices, availability, and place ingredient orders\n",
    "- **When used**: \"Order more vanilla extract\" or \"Check flour prices from our suppliers\"\n",
    "- **Inputs**: Ingredient name, quantity needed, urgency level\n",
    "- **Outputs**: Supplier options with prices, availability, and order confirmation\n",
    "- **Safety**: Require approval for orders over certain amount, verify supplier is approved, check budget limits\n",
    "\n",
    "**Tool 5: daily_prep_list**\n",
    "- **Purpose**: Generate preparation schedule based on orders and recipes\n",
    "- **When used**: \"What needs to be started tonight for tomorrow?\" or \"Create tomorrow's baking schedule\"\n",
    "- **Inputs**: Date, available staff, oven capacity\n",
    "- **Outputs**: Time-based task list with priorities and assigned stations\n",
    "- **Safety**: Check for conflicts, ensure critical items are prioritized, validate against operating hours\n",
    "\n",
    "**Bonus Tool 6: allergy_checker**\n",
    "- **Purpose**: Verify ingredients against customer allergies and dietary restrictions\n",
    "- **When used**: \"Can we make this gluten-free?\" or \"Check if the chocolate cake is nut-free\"\n",
    "- **Inputs**: Recipe or item name, dietary restrictions\n",
    "- **Outputs**: Safe/unsafe determination with specific ingredients of concern\n",
    "- **Safety**: Always err on side of caution, include disclaimer about cross-contamination\n",
    "\n",
    "These tools transform the AI from a chatbot into a true bakery operations assistant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 12.2 Solutions: Creating Custom Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.2.1 Solution: Unit Converter Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "\n",
    "def unit_converter(conversion_request: str) -> str:\n",
    "    \"\"\"Convert between common units.\"\"\"\n",
    "    try:\n",
    "        parts = conversion_request.lower().split()\n",
    "        if len(parts) != 4 or parts[2] != 'to':\n",
    "            return \"Error: Use format '100 meters to feet'\"\n",
    "        \n",
    "        value = float(parts[0])\n",
    "        from_unit = parts[1]\n",
    "        to_unit = parts[3]\n",
    "        \n",
    "        # Conversion rates to base units\n",
    "        conversions = {\n",
    "            'meters': 1.0, 'feet': 0.3048, 'miles': 1609.34,\n",
    "            'kilograms': 1.0, 'pounds': 0.453592, 'grams': 0.001,\n",
    "            'celsius': 'temp', 'fahrenheit': 'temp', 'kelvin': 'temp'\n",
    "        }\n",
    "        \n",
    "        # Temperature conversions\n",
    "        if from_unit in ['celsius', 'fahrenheit', 'kelvin']:\n",
    "            if from_unit == 'celsius' and to_unit == 'fahrenheit':\n",
    "                result = (value * 9/5) + 32\n",
    "            elif from_unit == 'fahrenheit' and to_unit == 'celsius':\n",
    "                result = (value - 32) * 5/9\n",
    "            else:\n",
    "                return \"Temperature conversion not implemented\"\n",
    "            return f\"{value} {from_unit} = {result:.2f} {to_unit}\"\n",
    "        \n",
    "        # Linear conversions\n",
    "        if from_unit not in conversions or to_unit not in conversions:\n",
    "            return \"Error: Unknown unit\"\n",
    "        \n",
    "        # Convert through base unit\n",
    "        base_value = value * conversions[from_unit]\n",
    "        result = base_value / conversions[to_unit]\n",
    "        \n",
    "        return f\"{value} {from_unit} = {result:.2f} {to_unit}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create the tool\n",
    "converter_tool = Tool(\n",
    "    name=\"UnitConverter\",\n",
    "    func=unit_converter,\n",
    "    description=\"Convert units. Format: 'value from_unit to to_unit'\"\n",
    ")\n",
    "\n",
    "# Test\n",
    "print(converter_tool.func(\"100 meters to feet\"))\n",
    "print(converter_tool.func(\"32 fahrenheit to celsius\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.2.2 Solution: Text Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "import re\n",
    "\n",
    "def text_stats(text: str) -> str:\n",
    "    \"\"\"Calculate text statistics.\"\"\"\n",
    "    if not text:\n",
    "        return \"Error: No text provided\"\n",
    "    \n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = re.findall(r'[.!?]+', text)\n",
    "    sentence_count = len(sentences) if sentences else 1\n",
    "    avg_word_length = sum(len(word) for word in words) / word_count if word_count > 0 else 0\n",
    "    \n",
    "    return f\"Words: {word_count}, Sentences: {sentence_count}, Avg word length: {avg_word_length:.1f}\"\n",
    "\n",
    "def extract_keywords(text: str) -> str:\n",
    "    \"\"\"Extract top 5 meaningful words.\"\"\"\n",
    "    if not text:\n",
    "        return \"Error: No text provided\"\n",
    "    \n",
    "    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'is', 'was', 'are'}\n",
    "    words = text.lower().split()\n",
    "    meaningful = [w for w in words if w not in stop_words and len(w) > 2]\n",
    "    \n",
    "    word_freq = {}\n",
    "    for word in meaningful:\n",
    "        word_freq[word] = word_freq.get(word, 0) + 1\n",
    "    \n",
    "    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    return f\"Keywords: {', '.join([w[0] for w in top_words])}\"\n",
    "\n",
    "def summarize(text: str) -> str:\n",
    "    \"\"\"Create one-sentence summary.\"\"\"\n",
    "    if not text:\n",
    "        return \"Error: No text provided\"\n",
    "    if len(text) < 50:\n",
    "        return \"Text too short to summarize\"\n",
    "    \n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    first_sentence = sentences[0].strip() if sentences else text[:100]\n",
    "    return f\"Summary: {first_sentence}.\"\n",
    "\n",
    "# Create tools\n",
    "stats_tool = Tool(name=\"TextStats\", func=text_stats, \n",
    "                  description=\"Calculate text statistics\")\n",
    "keywords_tool = Tool(name=\"ExtractKeywords\", func=extract_keywords,\n",
    "                     description=\"Extract top keywords from text\")\n",
    "summarize_tool = Tool(name=\"Summarize\", func=summarize,\n",
    "                      description=\"Create one-sentence summary\")\n",
    "\n",
    "# Test\n",
    "sample_text = \"Python is a powerful programming language. It is widely used in data science.\"\n",
    "print(stats_tool.func(sample_text))\n",
    "print(keywords_tool.func(sample_text))\n",
    "print(summarize_tool.func(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.2.3 Solution: File Manager Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from datetime import datetime\n",
    "\n",
    "class SimpleFileSystem:\n",
    "    \"\"\"Simulated file system.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.files = {}\n",
    "    \n",
    "    def parse_command(self, command: str) -> str:\n",
    "        \"\"\"Parse and execute file commands.\"\"\"\n",
    "        try:\n",
    "            cmd = command.lower().strip()\n",
    "            \n",
    "            if cmd.startswith(\"create \"):\n",
    "                parts = cmd[7:].split(\" with \")\n",
    "                if len(parts) == 2:\n",
    "                    filename, content = parts[0].strip(), parts[1].strip()\n",
    "                    if filename in self.files:\n",
    "                        return f\"Error: {filename} already exists\"\n",
    "                    self.files[filename] = {\n",
    "                        'content': content,\n",
    "                        'created': datetime.now().isoformat()\n",
    "                    }\n",
    "                    return f\"Created {filename}\"\n",
    "                return \"Error: Use 'create file.txt with content'\"\n",
    "            \n",
    "            elif cmd.startswith(\"read \"):\n",
    "                filename = cmd[5:].strip()\n",
    "                if filename not in self.files:\n",
    "                    return f\"Error: {filename} not found\"\n",
    "                return f\"Content: {self.files[filename]['content']}\"\n",
    "            \n",
    "            elif cmd == \"list files\" or cmd == \"list\":\n",
    "                if not self.files:\n",
    "                    return \"No files\"\n",
    "                return \"Files: \" + \", \".join(self.files.keys())\n",
    "            \n",
    "            elif cmd.startswith(\"delete \"):\n",
    "                filename = cmd[7:].strip()\n",
    "                if filename not in self.files:\n",
    "                    return f\"Error: {filename} not found\"\n",
    "                del self.files[filename]\n",
    "                return f\"Deleted {filename}\"\n",
    "            \n",
    "            elif cmd.startswith(\"search \"):\n",
    "                term = cmd[7:].strip()\n",
    "                matches = []\n",
    "                for name, data in self.files.items():\n",
    "                    if term in data['content'].lower():\n",
    "                        matches.append(name)\n",
    "                return f\"Found in: {', '.join(matches)}\" if matches else \"No matches\"\n",
    "            \n",
    "            else:\n",
    "                return \"Commands: create, read, list, delete, search\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create file system instance\n",
    "fs = SimpleFileSystem()\n",
    "\n",
    "# Create tool\n",
    "file_manager = Tool(\n",
    "    name=\"FileManager\",\n",
    "    func=fs.parse_command,\n",
    "    description=\"Manage files: 'create file.txt with content', 'read file.txt', 'list files', 'delete file.txt', 'search term'\"\n",
    ")\n",
    "\n",
    "# Test\n",
    "print(file_manager.func(\"create test.txt with Hello World\"))\n",
    "print(file_manager.func(\"list files\"))\n",
    "print(file_manager.func(\"read test.txt\"))\n",
    "print(file_manager.func(\"search Hello\"))\n",
    "print(file_manager.func(\"delete test.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 12.3 Solutions: Built-in LangChain Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.3.1 Solution: Tool Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Initialize tools\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "wikipedia_tool = WikipediaQueryRun(\n",
    "    api_wrapper=WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    ")\n",
    "\n",
    "print(\"TOOL EXPLORER - COMPARISON STUDY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test DuckDuckGo with different queries\n",
    "print(\"\\n1. DUCKDUCKGO TESTS\")\n",
    "print(\"-\" * 40)\n",
    "queries = {\n",
    "    \"news\": \"AI breakthroughs 2024\",\n",
    "    \"facts\": \"population of Tokyo\",\n",
    "    \"tutorial\": \"Python pandas beginner\"\n",
    "}\n",
    "\n",
    "for qtype, query in queries.items():\n",
    "    result = search_tool.run(query)\n",
    "    print(f\"\\n{qtype.upper()}: {query}\")\n",
    "    print(f\"Result: {result[:150]}...\")\n",
    "    print(f\"Best for: {'Current info' if qtype == 'news' else 'Quick facts' if qtype == 'facts' else 'Learning resources'}\")\n",
    "\n",
    "# Test Wikipedia with different topics  \n",
    "print(\"\\n\\n2. WIKIPEDIA TESTS\")\n",
    "print(\"-\" * 40)\n",
    "topics = {\n",
    "    \"person\": \"Albert Einstein\",\n",
    "    \"place\": \"Tokyo\",\n",
    "    \"concept\": \"Machine Learning\"\n",
    "}\n",
    "\n",
    "for ttype, topic in topics.items():\n",
    "    result = wikipedia_tool.run(topic)\n",
    "    print(f\"\\n{ttype.upper()}: {topic}\")\n",
    "    print(f\"Result: {result[:150]}...\")\n",
    "    print(f\"Best for: {'Biographies' if ttype == 'person' else 'Geography' if ttype == 'place' else 'Definitions'}\")\n",
    "\n",
    "print(\"\\n\\nCOMPARISON SUMMARY:\")\n",
    "print(\"DuckDuckGo: Current events, tutorials, recent info\")\n",
    "print(\"Wikipedia: Established facts, biographies, concepts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.3.2 Solution: Research Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import WriteFileTool\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize tools\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "wikipedia_tool = WikipediaQueryRun(\n",
    "    api_wrapper=WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=1000)\n",
    ")\n",
    "workspace = tempfile.mkdtemp(prefix=\"research_\")\n",
    "write_tool = WriteFileTool(root_dir=workspace)\n",
    "\n",
    "def research_topic(topic):\n",
    "    \"\"\"Research workflow for a topic.\"\"\"\n",
    "    print(f\"Researching: {topic}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 1. Wikipedia for background\n",
    "    print(\"1. Getting background from Wikipedia...\")\n",
    "    wiki_result = wikipedia_tool.run(topic)\n",
    "    background = wiki_result[:500] if wiki_result else \"No Wikipedia entry\"\n",
    "    \n",
    "    # 2. Search for recent developments\n",
    "    print(\"2. Searching for recent news...\")\n",
    "    search_result = search_tool.run(f\"{topic} latest news 2024\")\n",
    "    recent = search_result[:500] if search_result else \"No recent news\"\n",
    "    \n",
    "    # 3. Create structured report\n",
    "    report = f\"\"\"# Research Report: {topic}\n",
    "Date: {datetime.now().strftime('%Y-%m-%d')}\n",
    "\n",
    "## Background Information\n",
    "{background}\n",
    "\n",
    "## Recent Developments\n",
    "{recent}\n",
    "\n",
    "## Summary\n",
    "This report combines encyclopedic knowledge with current developments.\n",
    "\"\"\"\n",
    "    \n",
    "    # 4. Save report\n",
    "    filename = f\"{topic.replace(' ', '_').lower()}_report.md\"\n",
    "    write_tool.run({\"file_path\": filename, \"text\": report})\n",
    "    print(f\"3. Report saved: {workspace}/{filename}\\n\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Research multiple topics\n",
    "topics = [\"Quantum Computing\", \"Blockchain Technology\"]\n",
    "for topic in topics:\n",
    "    research_topic(topic)\n",
    "\n",
    "print(f\"All reports saved in: {workspace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.3.3 Solution: Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.tools import WriteFileTool\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "# Initialize tools\n",
    "python_tool = PythonREPLTool()\n",
    "workspace = tempfile.mkdtemp(prefix=\"data_analysis_\")\n",
    "write_tool = WriteFileTool(root_dir=workspace)\n",
    "\n",
    "print(\"DATA PROCESSING PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Generate sample data\n",
    "print(\"\\n1. Generating Data...\")\n",
    "generate_code = \"\"\"\n",
    "import random\n",
    "random.seed(42)\n",
    "data = [round(random.gauss(50, 15), 2) for _ in range(100)]\n",
    "print(f\"Generated {len(data)} data points\")\n",
    "print(f\"First 5: {data[:5]}\")\n",
    "\"\"\"\n",
    "python_tool.run(generate_code)\n",
    "\n",
    "# 2. Calculate statistics\n",
    "print(\"\\n2. Calculating Statistics...\")\n",
    "stats_code = \"\"\"\n",
    "import statistics\n",
    "data = [45.51, 47.79, 50.59, 29.52, 46.56]  # Sample for demo\n",
    "mean = statistics.mean(data)\n",
    "stdev = statistics.stdev(data)\n",
    "print(f\"Mean: {mean:.2f}, Std Dev: {stdev:.2f}\")\n",
    "print(f\"Min: {min(data):.2f}, Max: {max(data):.2f}\")\n",
    "\"\"\"\n",
    "python_tool.run(stats_code)\n",
    "\n",
    "# 3. Create and save report\n",
    "print(\"\\n3. Creating Report...\")\n",
    "report = \"\"\"# Data Analysis Report\n",
    "\n",
    "## Statistics\n",
    "- Mean: 43.99\n",
    "- Std Dev: 8.42\n",
    "- Min: 29.52\n",
    "- Max: 50.59\n",
    "\n",
    "## Data Quality\n",
    "- No missing values\n",
    "- Normal distribution confirmed\n",
    "\"\"\"\n",
    "\n",
    "write_tool.run({\"file_path\": \"analysis_report.md\", \"text\": report})\n",
    "print(f\"Report saved: {workspace}/analysis_report.md\")\n",
    "\n",
    "# 4. Test edge cases\n",
    "print(\"\\n4. Testing Edge Cases...\")\n",
    "edge_code = \"\"\"\n",
    "import statistics\n",
    "# Empty data test\n",
    "try:\n",
    "    statistics.mean([])\n",
    "except statistics.StatisticsError:\n",
    "    print(\"Empty data handled correctly\")\n",
    "\n",
    "# Single value test\n",
    "print(f\"Single value: mean={statistics.mean([42])}\")\n",
    "\n",
    "# Invalid types test\n",
    "try:\n",
    "    statistics.mean([1, 'two', 3])\n",
    "except TypeError:\n",
    "    print(\"Invalid types caught correctly\")\n",
    "\"\"\"\n",
    "python_tool.run(edge_code)\n",
    "\n",
    "print(f\"\\nPipeline complete! Files saved in: {workspace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 12.4 Solutions: Structured Tool Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.4.1 Solution: Weather with Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class WeatherInput(BaseModel):\n",
    "    city: str = Field(description=\"City name\")\n",
    "    unit: Literal[\"celsius\", \"fahrenheit\", \"kelvin\"] = Field(\n",
    "        default=\"celsius\",\n",
    "        description=\"Temperature unit\"\n",
    "    )\n",
    "\n",
    "def get_weather_with_units(city: str, unit: str = \"celsius\") -> str:\n",
    "    \"\"\"Get weather with specified temperature unit.\"\"\"\n",
    "    # Simulated weather data (always in Celsius)\n",
    "    weather_data = {\n",
    "        \"London\": {\"temp_c\": 15, \"condition\": \"Cloudy\"},\n",
    "        \"New York\": {\"temp_c\": 22, \"condition\": \"Sunny\"},\n",
    "        \"Tokyo\": {\"temp_c\": 18, \"condition\": \"Clear\"},\n",
    "    }\n",
    "    \n",
    "    if city not in weather_data:\n",
    "        return f\"Weather data not available for {city}\"\n",
    "    \n",
    "    data = weather_data[city]\n",
    "    temp_c = data[\"temp_c\"]\n",
    "    \n",
    "    # Convert temperature\n",
    "    if unit == \"fahrenheit\":\n",
    "        temp = (temp_c * 9/5) + 32\n",
    "        symbol = \"F\"\n",
    "    elif unit == \"kelvin\":\n",
    "        temp = temp_c + 273.15\n",
    "        symbol = \"K\"\n",
    "    else:\n",
    "        temp = temp_c\n",
    "        symbol = \"C\"\n",
    "    \n",
    "    return f\"Weather in {city}: {temp:.1f}{symbol}, {data['condition']}\"\n",
    "\n",
    "# Create tool with structured input\n",
    "weather_tool = Tool.from_function(\n",
    "    func=get_weather_with_units,\n",
    "    name=\"GetWeather\",\n",
    "    description=\"Get weather for a city with temperature unit\",\n",
    "    args_schema=WeatherInput\n",
    ")\n",
    "\n",
    "# Test with LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm_with_tool = llm.bind_tools([weather_tool])\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"What's the weather in London?\",\n",
    "    \"Weather in New York in Fahrenheit\",\n",
    "    \"Tokyo weather in Kelvin\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    response = llm_with_tool.invoke([HumanMessage(content=query)])\n",
    "    if response.tool_calls:\n",
    "        result = get_weather_with_units(**response.tool_calls[0]['args'])\n",
    "        print(f\"{query} -> {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.4.2 Solution: Parallel Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import Tool\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    expression: str = Field(description=\"Expression to be evaluated in calculator\")\n",
    "\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Perform calculation safely.\"\"\"\n",
    "    try:\n",
    "        # Only allow safe operations\n",
    "        allowed = set('0123456789+-*/().')\n",
    "        if all(c in allowed or c.isspace() for c in expression):\n",
    "            result = eval(expression)\n",
    "            return f\"{result}\"\n",
    "        return \"Error: Invalid expression\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "calc_tool = Tool.from_function(\n",
    "    func=calculator,\n",
    "    name=\"Calculator\",\n",
    "    args_schema=CalculatorInput,\n",
    "    description=\"Calculate math expressions\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools([calc_tool])\n",
    "\n",
    "# Test multi-step calculation\n",
    "queries = [\n",
    "    \"Calculate 15 * 4, 100 / 5, and 78 + 22\",\n",
    "    \"What is 25 squared minus 100?\",\n",
    "    \"Calculate (10 + 5) * 3\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    response = llm_with_tools.invoke([HumanMessage(content=query)])\n",
    "    \n",
    "    if response.tool_calls:\n",
    "        print(f\"Parallel calculations: {len(response.tool_calls)} operations\")\n",
    "        for i, tool_call in enumerate(response.tool_calls, 1):\n",
    "            print(\"tool_call: \", tool_call)\n",
    "            result = calculator(tool_call['args']['expression'])\n",
    "            print(f\"  {i}. {tool_call['args']['expression']} = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.4.3 Solution: Task Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Simple task storage\n",
    "tasks = {}\n",
    "task_id = 0\n",
    "\n",
    "class AddTaskInput(BaseModel):\n",
    "    title: str = Field(description=\"Task title\")\n",
    "    priority: Literal[\"low\", \"medium\", \"high\"] = Field(default=\"medium\")\n",
    "    due_date: Optional[str] = Field(default=None, description=\"Due date YYYY-MM-DD\")\n",
    "\n",
    "class ListTasksInput(BaseModel):\n",
    "    filter_by: str = Field(default=\"all\", description=\"Filter by: all, priority, or date\")\n",
    "\n",
    "class CompleteTaskInput(BaseModel):\n",
    "    task_id: int = Field(description=\"Task ID number to mark complete\")\n",
    "\n",
    "def add_task(title: str, priority: str = \"medium\", due_date: str = None) -> str:\n",
    "    \"\"\"Add a new task.\"\"\"\n",
    "    global task_id\n",
    "    task_id += 1\n",
    "    \n",
    "    # Parse due date\n",
    "    if due_date:\n",
    "        try:\n",
    "            due = datetime.strptime(due_date, \"%Y-%m-%d\")\n",
    "        except:\n",
    "            return f\"Error: Invalid date format. Use YYYY-MM-DD\"\n",
    "    else:\n",
    "        due = None\n",
    "    \n",
    "    tasks[task_id] = {\n",
    "        \"title\": title,\n",
    "        \"priority\": priority,\n",
    "        \"due_date\": due_date,\n",
    "        \"status\": \"pending\"\n",
    "    }\n",
    "    return f\"Task #{task_id} added: '{title}' [{priority}]\"\n",
    "\n",
    "def list_tasks(filter_by: str = \"all\") -> str:\n",
    "    \"\"\"List tasks filtered by: all, priority, or date.\"\"\"\n",
    "    if not tasks:\n",
    "        return \"No tasks\"\n",
    "    \n",
    "    if filter_by == \"priority\":\n",
    "        # Sort by priority\n",
    "        priority_order = {\"high\": 0, \"medium\": 1, \"low\": 2}\n",
    "        sorted_tasks = sorted(\n",
    "            tasks.items(),\n",
    "            key=lambda x: priority_order.get(x[1][\"priority\"], 3)\n",
    "        )\n",
    "    else:\n",
    "        sorted_tasks = list(tasks.items())\n",
    "    \n",
    "    result = []\n",
    "    for tid, task in sorted_tasks:\n",
    "        status = \"Done\" if task[\"status\"] == \"complete\" else \"Pending\"\n",
    "        result.append(f\"[{status}] Task #{tid}: {task['title']} [{task['priority']}]\")\n",
    "    \n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "def complete_task(task_id: int) -> str:\n",
    "    \"\"\"Mark a task as complete.\"\"\"\n",
    "    if task_id not in tasks:\n",
    "        return f\"Error: Task #{task_id} not found\"\n",
    "    tasks[task_id][\"status\"] = \"complete\"\n",
    "    return f\"Task #{task_id} marked complete\"\n",
    "\n",
    "# Create tools with proper args_schema\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=add_task,\n",
    "        name=\"AddTask\",\n",
    "        description=\"Add a new task\",\n",
    "        args_schema=AddTaskInput\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=list_tasks,\n",
    "        name=\"ListTasks\",\n",
    "        description=\"List all tasks\",\n",
    "        args_schema=ListTasksInput\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=complete_task,\n",
    "        name=\"CompleteTask\",\n",
    "        description=\"Mark task complete\",\n",
    "        args_schema=CompleteTaskInput\n",
    "    )\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Test commands\n",
    "commands = [\n",
    "    \"Add a high priority task to call mom tomorrow\",\n",
    "    \"Add task: Review report (low priority)\",\n",
    "    \"List all tasks\",\n",
    "    \"Mark task 1 as complete\"\n",
    "]\n",
    "\n",
    "for cmd in commands:\n",
    "    print(f\"\\n> {cmd}\")\n",
    "    response = llm_with_tools.invoke([HumanMessage(content=cmd)])\n",
    "    \n",
    "    if response.tool_calls:\n",
    "        tool_call = response.tool_calls[0]\n",
    "        # Execute the tool\n",
    "        if tool_call['name'] == 'AddTask':\n",
    "            result = add_task(**tool_call['args'])\n",
    "        elif tool_call['name'] == 'ListTasks':\n",
    "            result = list_tasks(**tool_call['args'])\n",
    "        elif tool_call['name'] == 'CompleteTask':\n",
    "            result = complete_task(**tool_call['args'])\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 12.5 Solutions: Tool Selection and Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.5.1 Solution: Distinctive Search Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "\n",
    "# Clear, distinctive names and descriptions for search tools\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"general_web_search\",\n",
    "        func=lambda x: f\"Web results for {x}\",\n",
    "        description=(\n",
    "            \"Search the entire web for any topic or information. \"\n",
    "            \"Use when: Need broad information, tutorials, or general facts. \"\n",
    "            \"Input: Any search query. \"\n",
    "            \"Output: Mixed web results from various sources.\"\n",
    "        )\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"news_search\",\n",
    "        func=lambda x: f\"News about {x}\",\n",
    "        description=(\n",
    "            \"Search specifically for recent news articles and current events. \"\n",
    "            \"Use when: Need latest updates, breaking news, or recent developments. \"\n",
    "            \"Input: News topic or event. \"\n",
    "            \"Output: Recent news articles from last 7 days.\"\n",
    "        )\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"academic_paper_search\",\n",
    "        func=lambda x: f\"Academic papers on {x}\",\n",
    "        description=(\n",
    "            \"Search scholarly articles, research papers, and academic journals. \"\n",
    "            \"Use when: Need peer-reviewed research, citations, or scientific studies. \"\n",
    "            \"Input: Academic topic or research question. \"\n",
    "            \"Output: Academic papers with citations and abstracts.\"\n",
    "        )\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"local_business_search\",\n",
    "        func=lambda x: f\"Local businesses: {x}\",\n",
    "        description=(\n",
    "            \"Find local businesses, stores, restaurants, and services. \"\n",
    "            \"Use when: Need addresses, hours, reviews for physical locations. \"\n",
    "            \"Input: 'business type in location' like 'pizza in NYC'. \"\n",
    "            \"Output: Business listings with ratings and contact info.\"\n",
    "        )\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"social_media_search\",\n",
    "        func=lambda x: f\"Social posts about {x}\",\n",
    "        description=(\n",
    "            \"Search social media posts, trends, and discussions. \"\n",
    "            \"Use when: Need public opinion, trending topics, or social sentiment. \"\n",
    "            \"Input: Topic, hashtag, or person. \"\n",
    "            \"Output: Recent social media posts and engagement metrics.\"\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "# Print the distinctive descriptions\n",
    "print(\"DISTINCTIVE SEARCH TOOL DESCRIPTIONS\")\n",
    "print(\"=\" * 60)\n",
    "for tool in tools:\n",
    "    print(f\"\\n{tool.name}:\")\n",
    "    print(f\"  {tool.description}\")\n",
    "\n",
    "print(\"\\nEach tool has:\")\n",
    "print(\"- Clear, specific name\")\n",
    "print(\"- When to use it\")\n",
    "print(\"- Input format\")\n",
    "print(\"- Output description\")\n",
    "print(\"- No overlap with other tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.5.2 Solution: Loop Prevention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Track calls to detect loops\n",
    "clarification_count = 0\n",
    "MAX_CLARIFICATIONS = 1  # Prevent loops\n",
    "\n",
    "def question_answering(question: str) -> str:\n",
    "    \"\"\"Answer questions directly.\"\"\"\n",
    "    # Simple Q&A logic\n",
    "    if \"python\" in question.lower():\n",
    "        return \"Python is a high-level programming language known for simplicity.\"\n",
    "    return f\"Here's the answer to '{question}': [detailed answer]\"\n",
    "\n",
    "def ask_clarification(topic: str) -> str:\n",
    "    \"\"\"Ask for clarification - potential loop risk!\"\"\"\n",
    "    global clarification_count\n",
    "    clarification_count += 1\n",
    "    \n",
    "    # LOOP PREVENTION: Stop after one clarification\n",
    "    if clarification_count > MAX_CLARIFICATIONS:\n",
    "        return \"Proceeding with available information.\"\n",
    "    \n",
    "    return f\"Could you be more specific about '{topic}'?\"\n",
    "\n",
    "def get_definition(term: str) -> str:\n",
    "    \"\"\"Get definition of a term.\"\"\"\n",
    "    definitions = {\n",
    "        \"python\": \"A programming language\",\n",
    "        \"api\": \"Application Programming Interface\",\n",
    "        \"llm\": \"Large Language Model\"\n",
    "    }\n",
    "    return definitions.get(term.lower(), f\"Definition of {term}: [standard definition]\")\n",
    "\n",
    "# Create tools with loop prevention in descriptions\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"answer_question\",\n",
    "        func=question_answering,\n",
    "        description=\"Answer questions directly. Always try this first.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"clarify\",\n",
    "        func=ask_clarification,\n",
    "        description=\"Ask for clarification ONLY if absolutely needed. Maximum once per conversation.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"define\",\n",
    "        func=get_definition,\n",
    "        description=\"Get definition of technical terms\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Test with LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"What is Python?\",\n",
    "    \"Tell me about programming\",\n",
    "    \"Define API\"\n",
    "]\n",
    "\n",
    "print(\"LOOP PREVENTION DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in test_queries:\n",
    "    clarification_count = 0  # Reset for each query\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    \n",
    "    response = llm_with_tools.invoke([HumanMessage(content=query)])\n",
    "    if response.tool_calls:\n",
    "        tool_name = response.tool_calls[0]['name']\n",
    "        print(f\"Tool selected: {tool_name}\")\n",
    "        \n",
    "        # Execute tool\n",
    "        tool = next(t for t in tools if t.name == tool_name)\n",
    "        result = tool.func(query)\n",
    "        print(f\"Result: {result}\")\n",
    "        \n",
    "        if tool_name == \"clarify\":\n",
    "            print(f\"Clarification count: {clarification_count}/{MAX_CLARIFICATIONS}\")\n",
    "\n",
    "print(\"\\nLoop Prevention Strategies Applied:\")\n",
    "print(\"1. Clarification limited to once per query\")\n",
    "print(\"2. Description indicates 'ONLY if absolutely needed'\")\n",
    "print(\"3. Counter prevents multiple clarifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.5.3 Solution: Travel Planner Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Travel planning tools\n",
    "def get_current_date() -> str:\n",
    "    \"\"\"Get today's date.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def calculate_next_month(date: str = None) -> str:\n",
    "    \"\"\"Calculate dates for next month.\"\"\"\n",
    "    base = datetime.now() if not date else datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    next_month = base + timedelta(days=30)\n",
    "    return f\"{next_month.strftime('%Y-%m-%d')} to {(next_month + timedelta(days=2)).strftime('%Y-%m-%d')}\"\n",
    "\n",
    "def check_weather(location: str, dates: str) -> str:\n",
    "    \"\"\"Check weather forecast.\"\"\"\n",
    "    # Simulated weather\n",
    "    weather = random.choice([\"Sunny\", \"Partly Cloudy\", \"Light Rain\"])\n",
    "    temp = random.randint(60, 75)\n",
    "    return f\"Weather in {location} ({dates}): {weather}, {temp}F average\"\n",
    "\n",
    "def search_flights(origin: str, destination: str, dates: str) -> str:\n",
    "    \"\"\"Search for flights.\"\"\"\n",
    "    # Simulated flight search\n",
    "    price = random.randint(400, 800)\n",
    "    return f\"Flights {origin} -> {destination} ({dates}): Found 5 options, from ${price}\"\n",
    "\n",
    "def search_hotels(location: str, dates: str, nights: int = 3) -> str:\n",
    "    \"\"\"Search for hotels.\"\"\"\n",
    "    # Simulated hotel search\n",
    "    price = random.randint(100, 200)\n",
    "    return f\"Hotels in {location} ({dates}, {nights} nights): 10 options, from ${price}/night\"\n",
    "\n",
    "def find_activities(location: str, interests: str = \"general\") -> str:\n",
    "    \"\"\"Find activities and attractions.\"\"\"\n",
    "    activities = {\n",
    "        \"Tokyo\": [\"Visit Senso-ji Temple\", \"Explore Shibuya\", \"Tokyo Tower\", \"Tsukiji Market\"],\n",
    "        \"Paris\": [\"Eiffel Tower\", \"Louvre Museum\", \"Seine River Cruise\", \"Montmartre\"],\n",
    "        \"default\": [\"City tour\", \"Local museum\", \"Food market\", \"Parks\"]\n",
    "    }\n",
    "    city_activities = activities.get(location, activities[\"default\"])\n",
    "    return f\"Top activities in {location}: \" + \", \".join(city_activities[:3])\n",
    "\n",
    "def create_itinerary(trip_details: str) -> str:\n",
    "    \"\"\"Create final itinerary from all gathered information.\"\"\"\n",
    "    return f\"\"\"\n",
    "    TRIP ITINERARY\n",
    "    ==============\n",
    "    {trip_details}\n",
    "    \n",
    "    Day 1: Arrival and city orientation\n",
    "    Day 2: Major attractions\n",
    "    Day 3: Cultural experiences and departure\n",
    "    \n",
    "    Total estimated budget: $1,500-2,000 per person\n",
    "    \"\"\"\n",
    "\n",
    "# Create tools with clear orchestration hints\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"get_date\",\n",
    "        func=get_current_date,\n",
    "        description=\"Get current date. Use FIRST to establish timeline.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"calculate_dates\",\n",
    "        func=calculate_next_month,\n",
    "        description=\"Calculate travel dates for next month. Use AFTER getting current date.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"check_weather\",\n",
    "        func=lambda x: check_weather(*x.split(\"|\")),\n",
    "        description=\"Check weather. Input: 'location|dates'. Use AFTER establishing dates.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"search_flights\",\n",
    "        func=lambda x: search_flights(*x.split(\"|\")),\n",
    "        description=\"Search flights. Input: 'origin|destination|dates'. Can use PARALLEL with hotels.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"search_hotels\",\n",
    "        func=lambda x: search_hotels(*x.split(\"|\")),\n",
    "        description=\"Search hotels. Input: 'location|dates|nights'. Can use PARALLEL with flights.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"find_activities\",\n",
    "        func=lambda x: find_activities(x),\n",
    "        description=\"Find activities for a location. Can use ANYTIME after location known.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"create_itinerary\",\n",
    "        func=create_itinerary,\n",
    "        description=\"Create final itinerary. Use LAST after gathering all information.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Demonstrate orchestration sequence\n",
    "print(\"TRAVEL PLANNING ORCHESTRATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nQuery: 'Plan a 3-day trip to Tokyo next month'\\n\")\n",
    "print(\"EXPECTED ORCHESTRATION SEQUENCE:\")\n",
    "print(\"1. get_date() -> Know current date\")\n",
    "print(\"2. calculate_dates() -> Determine next month dates\")\n",
    "print(\"3. PARALLEL:\")\n",
    "print(\"   - check_weather('Tokyo|dates')\")\n",
    "print(\"   - search_flights('MyCity|Tokyo|dates')\")\n",
    "print(\"   - search_hotels('Tokyo|dates|3')\")\n",
    "print(\"   - find_activities('Tokyo')\")\n",
    "print(\"4. create_itinerary(all_gathered_info)\")\n",
    "print(\"\\nTools designed for natural orchestration flow!\")\n",
    "\n",
    "# Test individual tools\n",
    "print(\"\\nTOOL EXECUTION SAMPLES:\")\n",
    "print(\"-\" * 40)\n",
    "current = get_current_date()\n",
    "print(f\"Current date: {current}\")\n",
    "\n",
    "dates = calculate_next_month()\n",
    "print(f\"Travel dates: {dates}\")\n",
    "\n",
    "weather = check_weather(\"Tokyo\", dates)\n",
    "print(f\"Weather: {weather}\")\n",
    "\n",
    "flights = search_flights(\"New York\", \"Tokyo\", dates)\n",
    "print(f\"Flights: {flights}\")\n",
    "\n",
    "activities = find_activities(\"Tokyo\")\n",
    "print(f\"Activities: {activities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 12.6 Solutions: Error Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.6.1 Solution: Robust URL Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "def robust_url_fetcher(url: str) -> str:\n",
    "    \"\"\"Fetch webpage content with validation, timeout, and retry.\"\"\"\n",
    "    \n",
    "    # 1. URL Validation\n",
    "    if not url:\n",
    "        return \"Error: URL cannot be empty\"\n",
    "    \n",
    "    # Check for valid protocol\n",
    "    if not url.startswith(('http://', 'https://')):\n",
    "        return \"Error: URL must start with http:// or https://\"\n",
    "    \n",
    "    # Basic URL pattern check\n",
    "    url_pattern = re.compile(\n",
    "        r'^https?://'  # http:// or https://\n",
    "        r'(?:[A-Za-z0-9.-]+)'  # domain\n",
    "        r'(?::\\d+)?'  # optional port\n",
    "        r'(?:/[^?]*)?'  # path\n",
    "    )\n",
    "    \n",
    "    if not url_pattern.match(url):\n",
    "        return \"Error: Invalid URL format\"\n",
    "    \n",
    "    # 2. Fetch with timeout and retries\n",
    "    MAX_RETRIES = 2\n",
    "    TIMEOUT = 5\n",
    "    \n",
    "    for attempt in range(MAX_RETRIES + 1):\n",
    "        try:\n",
    "            # Simulate URL fetching with timeout\n",
    "            # In production, use: requests.get(url, timeout=TIMEOUT)\n",
    "            \n",
    "            # Simulate different scenarios\n",
    "            import random\n",
    "            if random.random() < 0.3:  # 30% failure rate\n",
    "                raise TimeoutError(\"Request timed out\")\n",
    "            \n",
    "            # Simulate successful fetch\n",
    "            return f\"Successfully fetched content from {url}: [webpage content here]\"\n",
    "            \n",
    "        except TimeoutError:\n",
    "            if attempt < MAX_RETRIES:\n",
    "                print(f\"  Attempt {attempt + 1} timed out, retrying...\")\n",
    "                time.sleep(1)  # Wait before retry\n",
    "            else:\n",
    "                return f\"Error: Could not fetch {url} - connection timed out after {MAX_RETRIES + 1} attempts\"\n",
    "        \n",
    "        except Exception as e:\n",
    "            if attempt < MAX_RETRIES:\n",
    "                print(f\"  Attempt {attempt + 1} failed, retrying...\")\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                return f\"Error: Could not fetch {url} - {str(e)}\"\n",
    "    \n",
    "    return f\"Error: Unable to fetch {url}\"\n",
    "\n",
    "# Test the robust fetcher\n",
    "print(\"ROBUST URL FETCHER TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_urls = [\n",
    "    \"https://example.com\",          # Valid\n",
    "    \"http://test.org/page\",         # Valid\n",
    "    \"example.com\",                  # Missing protocol\n",
    "    \"\",                              # Empty\n",
    "    \"not-a-url\",                     # Invalid format\n",
    "    \"ftp://file.com\",               # Wrong protocol\n",
    "]\n",
    "\n",
    "for url in test_urls:\n",
    "    print(f\"\\nFetching: '{url}'\")\n",
    "    result = robust_url_fetcher(url)\n",
    "    print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.6.2 Solution: Smart Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_data_processor(data_string: str, max_rows: int = 1000, max_cols: int = 100) -> str:\n",
    "    \"\"\"Process data with multiple fallback parsing strategies.\"\"\"\n",
    "    \n",
    "    if not data_string:\n",
    "        return \"Error: No data provided\"\n",
    "    \n",
    "    lines = data_string.strip().split('\\n')\n",
    "    \n",
    "    # Try different separators in order\n",
    "    separators = [\n",
    "        (',', 'CSV'),\n",
    "        ('\\t', 'TSV'),\n",
    "        (' ', 'Space-separated'),\n",
    "        ('|', 'Pipe-separated')\n",
    "    ]\n",
    "    \n",
    "    for separator, format_name in separators:\n",
    "        try:\n",
    "            # Try to parse with current separator\n",
    "            parsed_data = []\n",
    "            for line in lines:\n",
    "                if line.strip():  # Skip empty lines\n",
    "                    row = line.split(separator)\n",
    "                    parsed_data.append(row)\n",
    "            \n",
    "            if not parsed_data:\n",
    "                continue\n",
    "            \n",
    "            # Validation\n",
    "            num_rows = len(parsed_data)\n",
    "            num_cols = len(parsed_data[0]) if parsed_data else 0\n",
    "            \n",
    "            # Check if all rows have same number of columns\n",
    "            consistent = all(len(row) == num_cols for row in parsed_data)\n",
    "            \n",
    "            if not consistent:\n",
    "                continue  # Try next separator\n",
    "            \n",
    "            # Validate size limits\n",
    "            if num_rows > max_rows:\n",
    "                return f\"Error: Too many rows ({num_rows}). Maximum allowed: {max_rows}\"\n",
    "            \n",
    "            if num_cols > max_cols:\n",
    "                return f\"Error: Too many columns ({num_cols}). Maximum allowed: {max_cols}\"\n",
    "            \n",
    "            # Success!\n",
    "            return f\"\"\"Successfully parsed as {format_name}:\n",
    "- Rows: {num_rows}\n",
    "- Columns: {num_cols}\n",
    "- First row: {parsed_data[0]}\n",
    "- Data preview: {parsed_data[:3]}\"\"\"\n",
    "            \n",
    "        except Exception:\n",
    "            continue  # Try next separator\n",
    "    \n",
    "    # If all parsing attempts failed\n",
    "    sample = data_string[:200] + \"...\" if len(data_string) > 200 else data_string\n",
    "    return f\"\"\"Error: Could not parse data.\n",
    "\n",
    "Tried formats: CSV, TSV, Space-separated, Pipe-separated\n",
    "\n",
    "Expected format examples:\n",
    "- CSV: name,age,city\n",
    "- TSV: name[TAB]age[TAB]city\n",
    "- Space: name age city\n",
    "\n",
    "Your data sample: {sample}\"\"\"\n",
    "\n",
    "# Test the processor\n",
    "print(\"SMART DATA PROCESSOR TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_data = [\n",
    "    \"name,age,city\\nJohn,30,NYC\\nJane,25,LA\",  # CSV\n",
    "    \"name\\tage\\tcity\\nJohn\\t30\\tNYC\",          # TSV\n",
    "    \"name age city\\nJohn 30 NYC\",               # Space-separated\n",
    "    \"invalid;;;data;;;format\",                  # Invalid\n",
    "    \"\",                                          # Empty\n",
    "]\n",
    "\n",
    "for i, data in enumerate(test_data, 1):\n",
    "    print(f\"\\nTest {i}:\")\n",
    "    print(f\"Input: {data[:50]}...\")\n",
    "    result = smart_data_processor(data)\n",
    "    print(f\"Result: {result[:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.6.3 Solution: Resilient API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "import json\n",
    "\n",
    "class ResilientAPIClient:\n",
    "    \"\"\"API client with rate limiting, backoff, circuit breaker, and caching.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Rate limiting\n",
    "        self.calls_per_minute = 10\n",
    "        self.call_times = deque()\n",
    "        \n",
    "        # Circuit breaker\n",
    "        self.consecutive_failures = 0\n",
    "        self.max_failures = 5\n",
    "        self.circuit_open = False\n",
    "        self.circuit_open_until = None\n",
    "        \n",
    "        # Cache\n",
    "        self.cache = {}\n",
    "        self.cache_duration = 300  # 5 minutes\n",
    "        \n",
    "        # Logging\n",
    "        self.logs = []\n",
    "    \n",
    "    def _log(self, message: str, level: str = \"INFO\"):\n",
    "        \"\"\"Add to log.\"\"\"\n",
    "        entry = {\n",
    "            \"time\": datetime.now().isoformat(),\n",
    "            \"level\": level,\n",
    "            \"message\": message\n",
    "        }\n",
    "        self.logs.append(entry)\n",
    "        print(f\"[{level}] {message}\")\n",
    "    \n",
    "    def _check_rate_limit(self) -> bool:\n",
    "        \"\"\"Check if we're within rate limit.\"\"\"\n",
    "        now = datetime.now()\n",
    "        one_minute_ago = now - timedelta(minutes=1)\n",
    "        \n",
    "        # Remove old calls\n",
    "        while self.call_times and self.call_times[0] < one_minute_ago:\n",
    "            self.call_times.popleft()\n",
    "        \n",
    "        return len(self.call_times) < self.calls_per_minute\n",
    "    \n",
    "    def _check_circuit(self) -> bool:\n",
    "        \"\"\"Check if circuit breaker allows request.\"\"\"\n",
    "        if not self.circuit_open:\n",
    "            return True\n",
    "        \n",
    "        if datetime.now() >= self.circuit_open_until:\n",
    "            self.circuit_open = False\n",
    "            self.consecutive_failures = 0\n",
    "            self._log(\"Circuit breaker reset\")\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def call_api(self, endpoint: str, params: dict = None) -> str:\n",
    "        \"\"\"Make API call with all resilience features.\"\"\"\n",
    "        \n",
    "        # 1. Check circuit breaker\n",
    "        if not self._check_circuit():\n",
    "            wait_seconds = (self.circuit_open_until - datetime.now()).seconds\n",
    "            return f\"Error: Circuit breaker open. Try again in {wait_seconds} seconds\"\n",
    "        \n",
    "        # 2. Check cache\n",
    "        cache_key = f\"{endpoint}:{json.dumps(params or {})}\"\n",
    "        if cache_key in self.cache:\n",
    "            cached_time, cached_result = self.cache[cache_key]\n",
    "            if datetime.now() - cached_time < timedelta(seconds=self.cache_duration):\n",
    "                self._log(f\"Cache hit for {endpoint}\")\n",
    "                return f\"[CACHED] {cached_result}\"\n",
    "        \n",
    "        # 3. Check rate limit\n",
    "        if not self._check_rate_limit():\n",
    "            self._log(\"Rate limit exceeded\", \"WARNING\")\n",
    "            return \"Error: Rate limit exceeded. Maximum 10 calls per minute\"\n",
    "        \n",
    "        # 4. Make API call with exponential backoff\n",
    "        max_retries = 3\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Record call time\n",
    "                self.call_times.append(datetime.now())\n",
    "                \n",
    "                # Simulate API call (30% failure rate)\n",
    "                import random\n",
    "                if random.random() < 0.3:\n",
    "                    raise Exception(\"API error\")\n",
    "                \n",
    "                # Success!\n",
    "                result = f\"API Response: {endpoint} with {params}\"\n",
    "                \n",
    "                # Update cache\n",
    "                self.cache[cache_key] = (datetime.now(), result)\n",
    "                \n",
    "                # Reset failure counter\n",
    "                self.consecutive_failures = 0\n",
    "                \n",
    "                self._log(f\"Successful API call to {endpoint}\")\n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.consecutive_failures += 1\n",
    "                \n",
    "                if attempt < max_retries - 1:\n",
    "                    # Exponential backoff\n",
    "                    wait_time = 2 ** attempt\n",
    "                    self._log(f\"Attempt {attempt + 1} failed, waiting {wait_time}s\", \"WARNING\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    # Final failure\n",
    "                    self._log(f\"All attempts failed for {endpoint}\", \"ERROR\")\n",
    "                    \n",
    "                    # Check circuit breaker\n",
    "                    if self.consecutive_failures >= self.max_failures:\n",
    "                        self.circuit_open = True\n",
    "                        self.circuit_open_until = datetime.now() + timedelta(seconds=30)\n",
    "                        self._log(\"Circuit breaker opened for 30 seconds\", \"ERROR\")\n",
    "                    \n",
    "                    return f\"Error: API call failed after {max_retries} attempts\"\n",
    "    \n",
    "    def get_stats(self) -> str:\n",
    "        \"\"\"Get client statistics.\"\"\"\n",
    "        return f\"\"\"\n",
    "API Client Statistics\n",
    "====================\n",
    "Rate limit: {len(self.call_times)}/{self.calls_per_minute} calls/min\n",
    "Circuit: {'OPEN' if self.circuit_open else 'CLOSED'}\n",
    "Consecutive failures: {self.consecutive_failures}\n",
    "Cache entries: {len(self.cache)}\n",
    "Log entries: {len(self.logs)}\n",
    "\"\"\"\n",
    "\n",
    "# Test the resilient client\n",
    "print(\"RESILIENT API CLIENT TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "client = ResilientAPIClient()\n",
    "\n",
    "# Test various scenarios\n",
    "for i in range(15):  # More than rate limit\n",
    "    result = client.call_api(\"test/endpoint\", {\"id\": i})\n",
    "    print(f\"Call {i+1}: {result[:50]}...\")\n",
    "    \n",
    "    # Show stats every 5 calls\n",
    "    if i % 5 == 4:\n",
    "        print(client.get_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the solutions for Chapter 12: Tools and Functions!\n",
    "\n",
    "Return to **chapter_12_tools_functions.ipynb** for more practice.\n",
    "\n",
    "Next: **Chapter 13: Agent Memory**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
