{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Introduction to LangChain - Solutions\n",
    "**From: Zero to AI Agent**\n",
    "\n",
    "**Try the exercises in the main notebook first before viewing solutions!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11.1 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.1.1: Framework Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution file not found: exercise_1_11_1_solution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.1.2: Use Case Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution file not found: exercise_2_11_1_solution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.1.3: Code Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_11_1_solution.py\n",
    "\n",
    "# Chapter 8 Challenges and LangChain Solutions\n",
    "\n",
    "challenges = {\n",
    "    \"1. Managing Message History\": {\n",
    "        \"Chapter 8 Problem\": \"\"\"\n",
    "        messages = []\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        # Manual management, easy to mess up formatting\n",
    "        \"\"\",\n",
    "        \"LangChain Solution\": \"\"\"\n",
    "        from langchain.memory import ConversationBufferMemory\n",
    "        memory = ConversationBufferMemory()\n",
    "        memory.save_context({\"input\": user_msg}, {\"output\": ai_response})\n",
    "        # Automatic management, consistent format\n",
    "        \"\"\"\n",
    "    },\n",
    "    \n",
    "    \"2. Handling Different Message Formats\": {\n",
    "        \"Chapter 8 Problem\": \"\"\"\n",
    "        # OpenAI format\n",
    "        {\"role\": \"system\", \"content\": \"...\"}\n",
    "        # Anthropic format different\n",
    "        # Google format different again\n",
    "        \"\"\",\n",
    "        \"LangChain Solution\": \"\"\"\n",
    "        from langchain.schema import SystemMessage, HumanMessage\n",
    "        # Same format works for all providers!\n",
    "        \"\"\"\n",
    "    },\n",
    "    \n",
    "    \"3. Error Handling\": {\n",
    "        \"Chapter 8 Problem\": \"\"\"\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(...)\n",
    "        except openai.error.APIError:\n",
    "            # Handle API errors\n",
    "        except openai.error.RateLimitError:\n",
    "            # Handle rate limits\n",
    "        # Different errors for each provider\n",
    "        \"\"\",\n",
    "        \"LangChain Solution\": \"\"\"\n",
    "        from langchain.callbacks import RetryWithErrorHandler\n",
    "        # Unified error handling across all providers\n",
    "        \"\"\"\n",
    "    },\n",
    "    \n",
    "    \"4. Switching Between Models\": {\n",
    "        \"Chapter 8 Problem\": \"\"\"\n",
    "        # Had to rewrite code for different models\n",
    "        if use_gpt4:\n",
    "            model = \"gpt-4\"\n",
    "            # Different parameters\n",
    "        else:\n",
    "            model = \"gpt-3.5-turbo\"\n",
    "            # Different handling\n",
    "        \"\"\",\n",
    "        \"LangChain Solution\": \"\"\"\n",
    "        llm = ChatOpenAI(model=model_name)\n",
    "        # Same interface for all models\n",
    "        \"\"\"\n",
    "    },\n",
    "    \n",
    "    \"5. Prompt Management\": {\n",
    "        \"Chapter 8 Problem\": \"\"\"\n",
    "        system_prompt = \"You are a helpful assistant...\"\n",
    "        user_prompt = f\"User said: {input}\"\n",
    "        # Strings everywhere, hard to maintain\n",
    "        \"\"\",\n",
    "        \"LangChain Solution\": \"\"\"\n",
    "        from langchain.prompts import ChatPromptTemplate\n",
    "        prompt = ChatPromptTemplate.from_template(\"...\")\n",
    "        # Reusable, testable, maintainable\n",
    "        \"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def demonstrate_improvement():\n",
    "    \"\"\"Show how LangChain simplifies each challenge\"\"\"\n",
    "    \n",
    "    print(\"\ud83c\udfaf How LangChain Solves Chapter 8 Challenges\\n\")\n",
    "    \n",
    "    for challenge, details in challenges.items():\n",
    "        print(f\"{challenge}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(\"\u274c Chapter 8 Approach:\")\n",
    "        print(details[\"Chapter 8 Problem\"])\n",
    "        print(\"\\n\u2705 LangChain Approach:\")\n",
    "        print(details[\"LangChain Solution\"])\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demonstrate_improvement()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11.2 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.2.1: Environment Detective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_11_2_solution.py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def generate_environment_report():\n",
    "    \"\"\"Generate a comprehensive environment report\"\"\"\n",
    "    \n",
    "    load_dotenv()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"\ud83d\udd0d ENVIRONMENT REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Python version\n",
    "    print(f\"\\n\ud83d\udccc Python Version: {sys.version}\")\n",
    "    print(f\"   Executable: {sys.executable}\")\n",
    "    \n",
    "    # LangChain version\n",
    "    try:\n",
    "        import langchain\n",
    "        print(f\"\\n\ud83d\udce6 LangChain Version: {langchain.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"\\n\u274c LangChain not installed\")\n",
    "    \n",
    "    # API Key check (without revealing it)\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if api_key:\n",
    "        print(f\"\\n\ud83d\udd11 OpenAI API Key: Present ({len(api_key)} characters)\")\n",
    "        print(f\"   Starts with: {api_key[:7]}...\")\n",
    "    else:\n",
    "        print(\"\\n\u274c OpenAI API Key: Not found\")\n",
    "    \n",
    "    # Current working directory\n",
    "    print(f\"\\n\ud83d\udcc1 Current Directory: {os.getcwd()}\")\n",
    "    \n",
    "    # Check if .env file exists\n",
    "    if os.path.exists(\".env\"):\n",
    "        print(\"   \u2705 .env file found\")\n",
    "    else:\n",
    "        print(\"   \u274c .env file not found\")\n",
    "    \n",
    "    # List key packages\n",
    "    print(\"\\n\ud83d\udcda Key Packages Installed:\")\n",
    "    key_packages = [\"langchain\", \"langchain-openai\", \"langchain-community\", \n",
    "                   \"openai\", \"python-dotenv\"]\n",
    "    \n",
    "    for package in key_packages:\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [\"pip\", \"show\", package],\n",
    "                capture_output=True,\n",
    "                text=True\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                for line in result.stdout.split('\\n'):\n",
    "                    if line.startswith('Version:'):\n",
    "                        version = line.split(':')[1].strip()\n",
    "                        print(f\"   \u2705 {package}: {version}\")\n",
    "                        break\n",
    "            else:\n",
    "                print(f\"   \u274c {package}: Not installed\")\n",
    "        except Exception:\n",
    "            print(f\"   \u26a0\ufe0f  {package}: Could not check\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Report complete! Save this when things are working.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_environment_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.2.2: Setup Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution file not found: exercise_2_11_2_solution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.2.3: Connection Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_11_2_solution.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def test_connection():\n",
    "    \"\"\"Comprehensive connection testing with fixes\"\"\"\n",
    "    \n",
    "    print(\"\ud83d\udd0c LangChain Connection Tester\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Step 1: Check environment\n",
    "    print(\"\\n1\ufe0f\u20e3 Checking environment setup...\")\n",
    "    load_dotenv()\n",
    "    \n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"\u274c No API key found\")\n",
    "        print(\"\\n\ud83d\udca1 Fix:\")\n",
    "        print(\"   1. Create a .env file in this directory\")\n",
    "        print(\"   2. Add: OPENAI_API_KEY=sk-...\")\n",
    "        print(\"   3. Get key from: https://platform.openai.com/api-keys\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\u2705 API key found ({len(api_key)} chars)\")\n",
    "    \n",
    "    # Step 2: Check imports\n",
    "    print(\"\\n2\ufe0f\u20e3 Checking LangChain installation...\")\n",
    "    try:\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        print(\"\u2705 LangChain imports successful\")\n",
    "    except ImportError as e:\n",
    "        print(f\"\u274c Import failed: {e}\")\n",
    "        print(\"\\n\ud83d\udca1 Fix:\")\n",
    "        print(\"   Run: pip install langchain langchain-openai\")\n",
    "        return False\n",
    "    \n",
    "    # Step 3: Test connection\n",
    "    print(\"\\n3\ufe0f\u20e3 Testing OpenAI connection...\")\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "        \n",
    "        # Simple test query\n",
    "        start = time.time()\n",
    "        response = llm.invoke(\"Say 'Connection successful!'\")\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        print(f\"\u2705 Connection successful! (Response in {elapsed:.2f}s)\")\n",
    "        print(f\"   Response: {response.content}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e).lower()\n",
    "        print(f\"\u274c Connection failed: {e}\")\n",
    "        \n",
    "        # Provide specific fixes based on error\n",
    "        print(\"\\n\ud83d\udca1 Suggested fixes:\")\n",
    "        \n",
    "        if \"api\" in error_msg and \"key\" in error_msg:\n",
    "            print(\"   \u2022 Check if your API key is valid\")\n",
    "            print(\"   \u2022 Ensure key starts with 'sk-'\")\n",
    "            print(\"   \u2022 Try generating a new key\")\n",
    "            \n",
    "        elif \"rate\" in error_msg:\n",
    "            print(\"   \u2022 You've hit rate limits\")\n",
    "            print(\"   \u2022 Wait a few minutes and try again\")\n",
    "            print(\"   \u2022 Consider upgrading your OpenAI plan\")\n",
    "            \n",
    "        elif \"connection\" in error_msg or \"network\" in error_msg:\n",
    "            print(\"   \u2022 Check your internet connection\")\n",
    "            print(\"   \u2022 Try disabling VPN if using one\")\n",
    "            print(\"   \u2022 Check if OpenAI is accessible from your location\")\n",
    "            \n",
    "        elif \"model\" in error_msg:\n",
    "            print(\"   \u2022 The model name might be incorrect\")\n",
    "            print(\"   \u2022 Try using 'gpt-3.5-turbo' or 'gpt-4'\")\n",
    "            \n",
    "        else:\n",
    "            print(\"   \u2022 Check OpenAI service status\")\n",
    "            print(\"   \u2022 Ensure you have credits in your account\")\n",
    "            print(\"   \u2022 Try updating LangChain: pip install -U langchain\")\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        print(\"\\n\" + \"=\" * 40)\n",
    "        print(\"Testing complete\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = test_connection()\n",
    "    sys.exit(0 if success else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11.3 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.3.1: Prompt Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_11_3_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Create three different prompts for different audiences\n",
    "technical_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Summarize this text for a technical audience. \n",
    "    Include specific details, technical terms, and implementation considerations.\n",
    "    \n",
    "    Text: {text}\n",
    "    \n",
    "    Technical Summary:\"\"\"\n",
    ")\n",
    "\n",
    "children_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Explain this text in a way a 10-year-old would understand.\n",
    "    Use simple words, fun examples, and make it engaging.\n",
    "    \n",
    "    Text: {text}\n",
    "    \n",
    "    Kid-Friendly Explanation:\"\"\"\n",
    ")\n",
    "\n",
    "business_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Summarize this text for business executives.\n",
    "    Focus on impact, ROI, strategic implications, and actionable insights.\n",
    "    \n",
    "    Text: {text}\n",
    "    \n",
    "    Executive Summary:\"\"\"\n",
    ")\n",
    "\n",
    "# Test text about AI\n",
    "test_text = \"\"\"\n",
    "Artificial neural networks are computing systems inspired by biological neural networks.\n",
    "They consist of interconnected nodes that process information using connectionist approaches.\n",
    "These networks can learn to perform tasks by considering examples, generally without \n",
    "being programmed with task-specific rules. They have revolutionized image recognition,\n",
    "natural language processing, and many other fields.\n",
    "\"\"\"\n",
    "\n",
    "# Create the model\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "# Test all three variations\n",
    "print(\"Original Text:\")\n",
    "print(test_text)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Technical audience\n",
    "tech_chain = technical_prompt | llm\n",
    "tech_result = tech_chain.invoke({\"text\": test_text})\n",
    "print(\"TECHNICAL AUDIENCE:\")\n",
    "print(tech_result.content)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Children audience\n",
    "children_chain = children_prompt | llm\n",
    "children_result = children_chain.invoke({\"text\": test_text})\n",
    "print(\"CHILDREN AUDIENCE:\")\n",
    "print(children_result.content)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Business audience\n",
    "business_chain = business_prompt | llm\n",
    "business_result = business_chain.invoke({\"text\": test_text})\n",
    "print(\"BUSINESS AUDIENCE:\")\n",
    "print(business_result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.3.2: Chain Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_11_3_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "# Step 1: Generate questions\n",
    "question_generator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Generate exactly 3 interesting questions about {topic}.\n",
    "    Number them 1, 2, and 3.\n",
    "    \n",
    "    Questions:\"\"\"\n",
    ")\n",
    "\n",
    "question_chain = question_generator_prompt | llm\n",
    "\n",
    "# Step 2: Pick the most interesting question\n",
    "question_selector_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"From these questions, pick the MOST interesting and thought-provoking one.\n",
    "    Return ONLY that question, nothing else.\n",
    "    \n",
    "    Questions:\n",
    "    {questions}\n",
    "    \n",
    "    Most interesting question:\"\"\"\n",
    ")\n",
    "\n",
    "selector_chain = question_selector_prompt | llm\n",
    "\n",
    "# Step 3: Answer the selected question\n",
    "answer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Provide a thoughtful, detailed answer to this question:\n",
    "    {question}\n",
    "    \n",
    "    Answer:\"\"\"\n",
    ")\n",
    "\n",
    "answer_chain = answer_prompt | llm\n",
    "\n",
    "# Run the complete process\n",
    "def explore_topic(topic):\n",
    "    \"\"\"Generate questions, select the best, and answer it\"\"\"\n",
    "    \n",
    "    print(f\"\ud83d\udcda Exploring Topic: {topic}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Generate questions\n",
    "    print(\"\\n1\ufe0f\u20e3 Generating questions...\")\n",
    "    questions_response = question_chain.invoke({\"topic\": topic})\n",
    "    questions = questions_response.content\n",
    "    print(questions)\n",
    "    \n",
    "    # Select most interesting\n",
    "    print(\"\\n2\ufe0f\u20e3 Selecting most interesting question...\")\n",
    "    selected_response = selector_chain.invoke({\"questions\": questions})\n",
    "    selected_question = selected_response.content\n",
    "    print(f\"Selected: {selected_question}\")\n",
    "    \n",
    "    # Answer it\n",
    "    print(\"\\n3\ufe0f\u20e3 Answering the question...\")\n",
    "    answer_response = answer_chain.invoke({\"question\": selected_question})\n",
    "    print(answer_response.content)\n",
    "    \n",
    "    return {\n",
    "        \"topic\": topic,\n",
    "        \"all_questions\": questions,\n",
    "        \"selected\": selected_question,\n",
    "        \"answer\": answer_response.content\n",
    "    }\n",
    "\n",
    "# Test with different topics\n",
    "topics = [\"quantum computing\", \"happiness\", \"climate change\"]\n",
    "\n",
    "for topic in topics:\n",
    "    result = explore_topic(topic)\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.3.3: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_11_3_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def compare_temperatures(prompt, temp1=0.0, temp2=1.0):\n",
    "    \"\"\"Compare outputs at different temperatures\"\"\"\n",
    "    \n",
    "    # Create models with different temperatures\n",
    "    focused_model = ChatOpenAI(temperature=temp1)\n",
    "    creative_model = ChatOpenAI(temperature=temp2)\n",
    "    \n",
    "    # Get responses\n",
    "    focused_response = focused_model.invoke(prompt)\n",
    "    creative_response = creative_model.invoke(prompt)\n",
    "    \n",
    "    focused_text = focused_response.content\n",
    "    creative_text = creative_response.content\n",
    "    \n",
    "    # Count words\n",
    "    focused_words = focused_text.split()\n",
    "    creative_words = creative_text.split()\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarity = SequenceMatcher(None, focused_text, creative_text).ratio()\n",
    "    \n",
    "    # Find different words\n",
    "    focused_set = set(focused_words)\n",
    "    creative_set = set(creative_words)\n",
    "    \n",
    "    unique_to_focused = focused_set - creative_set\n",
    "    unique_to_creative = creative_set - focused_set\n",
    "    \n",
    "    return {\n",
    "        \"focused\": focused_text,\n",
    "        \"creative\": creative_text,\n",
    "        \"focused_word_count\": len(focused_words),\n",
    "        \"creative_word_count\": len(creative_words),\n",
    "        \"similarity\": similarity,\n",
    "        \"unique_to_focused\": unique_to_focused,\n",
    "        \"unique_to_creative\": unique_to_creative\n",
    "    }\n",
    "\n",
    "# Test prompts\n",
    "test_prompts = [\n",
    "    \"Write a one-sentence description of coffee\",\n",
    "    \"What is the meaning of life?\",\n",
    "    \"Describe a sunset\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\ud83d\udcdd Prompt: {prompt}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    result = compare_temperatures(prompt)\n",
    "    \n",
    "    print(f\"\\n\ud83c\udfaf Temperature 0.0 (Focused):\")\n",
    "    print(result[\"focused\"])\n",
    "    print(f\"Words: {result['focused_word_count']}\")\n",
    "    \n",
    "    print(f\"\\n\ud83c\udfa8 Temperature 1.0 (Creative):\")\n",
    "    print(result[\"creative\"])\n",
    "    print(f\"Words: {result['creative_word_count']}\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca Analysis:\")\n",
    "    print(f\"Similarity: {result['similarity']:.1%}\")\n",
    "    print(f\"Unique to focused: {len(result['unique_to_focused'])} words\")\n",
    "    print(f\"Unique to creative: {len(result['unique_to_creative'])} words\")\n",
    "    \n",
    "    if result['unique_to_creative']:\n",
    "        print(f\"Creative additions: {list(result['unique_to_creative'])[:5]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"\ud83d\udca1 Insight: Higher temperature = more variation and creativity!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11.4 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.4.1: Specialized Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_11_4_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class SpecializedAssistant:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "        self.current_mode = \"translator\"\n",
    "        self.current_style = \"formal\"\n",
    "        \n",
    "        # Translator prompts\n",
    "        self.translator_prompts = {\n",
    "            \"formal\": ChatPromptTemplate.from_template(\n",
    "                \"Rewrite this text in formal, professional language: {text}\"\n",
    "            ),\n",
    "            \"casual\": ChatPromptTemplate.from_template(\n",
    "                \"Rewrite this text in casual, friendly language: {text}\"\n",
    "            ),\n",
    "            \"technical\": ChatPromptTemplate.from_template(\n",
    "                \"Rewrite this text using technical terminology: {text}\"\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Summarizer prompts\n",
    "        self.summarizer_prompts = {\n",
    "            \"brief\": ChatPromptTemplate.from_template(\n",
    "                \"Summarize this in one sentence: {text}\"\n",
    "            ),\n",
    "            \"standard\": ChatPromptTemplate.from_template(\n",
    "                \"Summarize this in 3-5 sentences: {text}\"\n",
    "            ),\n",
    "            \"detailed\": ChatPromptTemplate.from_template(\n",
    "                \"Provide a detailed summary with key points: {text}\"\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Analyzer prompts\n",
    "        self.analyzer_prompts = {\n",
    "            \"sentiment\": ChatPromptTemplate.from_template(\n",
    "                \"Analyze the sentiment and tone of this text: {text}\"\n",
    "            ),\n",
    "            \"structure\": ChatPromptTemplate.from_template(\n",
    "                \"Analyze the structure and organization of this text: {text}\"\n",
    "            ),\n",
    "            \"audience\": ChatPromptTemplate.from_template(\n",
    "                \"Analyze the target audience for this text: {text}\"\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def set_mode(self, mode, style=\"formal\"):\n",
    "        \"\"\"Switch between translator, summarizer, or analyzer\"\"\"\n",
    "        valid_modes = [\"translator\", \"summarizer\", \"analyzer\"]\n",
    "        if mode in valid_modes:\n",
    "            self.current_mode = mode\n",
    "            self.current_style = style\n",
    "            return f\"Switched to {mode} mode ({style})\"\n",
    "        return \"Invalid mode. Choose: translator, summarizer, or analyzer\"\n",
    "    \n",
    "    def process(self, text):\n",
    "        \"\"\"Process text based on current mode and style\"\"\"\n",
    "        \n",
    "        # Select appropriate prompts\n",
    "        if self.current_mode == \"translator\":\n",
    "            prompts = self.translator_prompts\n",
    "        elif self.current_mode == \"summarizer\":\n",
    "            prompts = self.summarizer_prompts\n",
    "        else:  # analyzer\n",
    "            prompts = self.analyzer_prompts\n",
    "        \n",
    "        # Get the right prompt for current style\n",
    "        prompt = prompts.get(self.current_style, prompts[list(prompts.keys())[0]])\n",
    "        \n",
    "        # Create chain and process\n",
    "        chain = prompt | self.llm\n",
    "        response = chain.invoke({\"text\": text})\n",
    "        \n",
    "        # Save to memory for context\n",
    "        self.memory.save_context(\n",
    "            {\"input\": f\"[{self.current_mode}:{self.current_style}] {text}\"},\n",
    "            {\"output\": response.content}\n",
    "        )\n",
    "        \n",
    "        return response.content\n",
    "\n",
    "# Test the assistant\n",
    "assistant = SpecializedAssistant()\n",
    "\n",
    "test_text = \"\"\"\n",
    "Machine learning is a subset of artificial intelligence that enables \n",
    "systems to learn and improve from experience without being explicitly programmed.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Original text:\", test_text)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test translator mode\n",
    "for style in [\"formal\", \"casual\", \"technical\"]:\n",
    "    assistant.set_mode(\"translator\", style)\n",
    "    result = assistant.process(test_text)\n",
    "    print(f\"TRANSLATOR ({style}):\")\n",
    "    print(result)\n",
    "    print()\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test summarizer mode\n",
    "for style in [\"brief\", \"standard\", \"detailed\"]:\n",
    "    assistant.set_mode(\"summarizer\", style)\n",
    "    result = assistant.process(test_text)\n",
    "    print(f\"SUMMARIZER ({style}):\")\n",
    "    print(result)\n",
    "    print()\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test analyzer mode\n",
    "for style in [\"sentiment\", \"structure\", \"audience\"]:\n",
    "    assistant.set_mode(\"analyzer\", style)\n",
    "    result = assistant.process(test_text)\n",
    "    print(f\"ANALYZER ({style}):\")\n",
    "    print(result)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.4.2: Learning Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_11_4_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class LearningTracker:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "        \n",
    "        # Track learning progress\n",
    "        self.topics_learned = {}\n",
    "        self.quiz_scores = {}\n",
    "        self.total_sessions = 0\n",
    "        \n",
    "        # Prompts for different functions\n",
    "        self.learn_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are an encouraging teacher. Explain topics clearly.\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            (\"human\", \"Teach me about: {topic}\")\n",
    "        ])\n",
    "        \n",
    "        self.quiz_prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"Create a quiz question about {topic}.\n",
    "            Include the question and 4 multiple choice options (A, B, C, D).\n",
    "            Mark the correct answer clearly.\"\"\"\n",
    "        )\n",
    "        \n",
    "        self.encourage_prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"The student has completed {sessions} learning sessions and studied these topics: {topics}.\n",
    "            Their average quiz score is {score}%.\n",
    "            Give them personalized encouragement and suggest what to study next.\"\"\"\n",
    "        )\n",
    "    \n",
    "    def learn_topic(self, topic):\n",
    "        \"\"\"Learn about a new topic\"\"\"\n",
    "        self.total_sessions += 1\n",
    "        \n",
    "        # Record topic\n",
    "        if topic not in self.topics_learned:\n",
    "            self.topics_learned[topic] = {\n",
    "                \"first_studied\": datetime.now().isoformat(),\n",
    "                \"times_reviewed\": 0,\n",
    "                \"quiz_attempts\": 0\n",
    "            }\n",
    "        \n",
    "        self.topics_learned[topic][\"times_reviewed\"] += 1\n",
    "        \n",
    "        # Get explanation\n",
    "        history = self.memory.load_memory_variables({})[\"history\"]\n",
    "        chain = self.learn_prompt | self.llm\n",
    "        \n",
    "        response = chain.invoke({\n",
    "            \"history\": history,\n",
    "            \"topic\": topic\n",
    "        })\n",
    "        \n",
    "        # Save to memory\n",
    "        self.memory.save_context(\n",
    "            {\"input\": f\"Teach me about: {topic}\"},\n",
    "            {\"output\": response.content}\n",
    "        )\n",
    "        \n",
    "        return response.content\n",
    "    \n",
    "    def quiz_me(self, topic=None):\n",
    "        \"\"\"Generate a quiz question\"\"\"\n",
    "        if not topic and self.topics_learned:\n",
    "            # Pick a random learned topic\n",
    "            import random\n",
    "            topic = random.choice(list(self.topics_learned.keys()))\n",
    "        elif not topic:\n",
    "            return \"No topics learned yet! Learn something first.\"\n",
    "        \n",
    "        chain = self.quiz_prompt | self.llm\n",
    "        response = chain.invoke({\"topic\": topic})\n",
    "        \n",
    "        # Track quiz attempt\n",
    "        if topic in self.topics_learned:\n",
    "            self.topics_learned[topic][\"quiz_attempts\"] += 1\n",
    "        \n",
    "        return {\n",
    "            \"topic\": topic,\n",
    "            \"question\": response.content\n",
    "        }\n",
    "    \n",
    "    def record_score(self, topic, score):\n",
    "        \"\"\"Record quiz score\"\"\"\n",
    "        if topic not in self.quiz_scores:\n",
    "            self.quiz_scores[topic] = []\n",
    "        self.quiz_scores[topic].append(score)\n",
    "        return f\"Score recorded: {score}% for {topic}\"\n",
    "    \n",
    "    def get_progress(self):\n",
    "        \"\"\"Get learning progress and encouragement\"\"\"\n",
    "        if not self.topics_learned:\n",
    "            return \"Start learning to track your progress!\"\n",
    "        \n",
    "        # Calculate average score\n",
    "        all_scores = []\n",
    "        for scores in self.quiz_scores.values():\n",
    "            all_scores.extend(scores)\n",
    "        \n",
    "        avg_score = sum(all_scores) / len(all_scores) if all_scores else 0\n",
    "        \n",
    "        # Get encouragement\n",
    "        chain = self.encourage_prompt | self.llm\n",
    "        response = chain.invoke({\n",
    "            \"sessions\": self.total_sessions,\n",
    "            \"topics\": \", \".join(self.topics_learned.keys()),\n",
    "            \"score\": round(avg_score)\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"sessions\": self.total_sessions,\n",
    "            \"topics_learned\": list(self.topics_learned.keys()),\n",
    "            \"average_score\": avg_score,\n",
    "            \"encouragement\": response.content\n",
    "        }\n",
    "    \n",
    "    def review_topic(self, topic):\n",
    "        \"\"\"Review a previously learned topic\"\"\"\n",
    "        if topic not in self.topics_learned:\n",
    "            return f\"You haven't learned about {topic} yet!\"\n",
    "        \n",
    "        history = self.memory.load_memory_variables({})[\"history\"]\n",
    "        \n",
    "        review_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Help the student review this topic they learned before.\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            (\"human\", f\"Help me review: {topic}\")\n",
    "        ])\n",
    "        \n",
    "        chain = review_prompt | self.llm\n",
    "        response = chain.invoke({\"history\": history})\n",
    "        \n",
    "        self.topics_learned[topic][\"times_reviewed\"] += 1\n",
    "        \n",
    "        return response.content\n",
    "\n",
    "# Interactive learning session\n",
    "def run_learning_session():\n",
    "    tracker = LearningTracker()\n",
    "    \n",
    "    print(\"\ud83d\udcda Learning Tracker Assistant\")\n",
    "    print(\"Commands: learn <topic>, quiz [topic], score <topic> <score>, progress, review <topic>, quit\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    while True:\n",
    "        command = input(\"\\nWhat would you like to do? \").strip().lower()\n",
    "        \n",
    "        if command.startswith(\"learn \"):\n",
    "            topic = command[6:]\n",
    "            print(f\"\\n\ud83d\udcd6 Learning about {topic}...\")\n",
    "            print(tracker.learn_topic(topic))\n",
    "            \n",
    "        elif command.startswith(\"quiz\"):\n",
    "            parts = command.split(maxsplit=1)\n",
    "            topic = parts[1] if len(parts) > 1 else None\n",
    "            quiz = tracker.quiz_me(topic)\n",
    "            print(f\"\\n\u2753 Quiz on {quiz['topic']}:\")\n",
    "            print(quiz['question'])\n",
    "            \n",
    "        elif command.startswith(\"score \"):\n",
    "            parts = command.split()\n",
    "            if len(parts) >= 3:\n",
    "                topic = parts[1]\n",
    "                score = int(parts[2])\n",
    "                print(tracker.record_score(topic, score))\n",
    "            \n",
    "        elif command == \"progress\":\n",
    "            progress = tracker.get_progress()\n",
    "            print(f\"\\n\ud83d\udcca Your Progress:\")\n",
    "            print(f\"Sessions: {progress['sessions']}\")\n",
    "            print(f\"Topics: {', '.join(progress['topics_learned'])}\")\n",
    "            print(f\"Average Score: {progress['average_score']:.1f}%\")\n",
    "            print(f\"\\n\ud83d\udcaa {progress['encouragement']}\")\n",
    "            \n",
    "        elif command.startswith(\"review \"):\n",
    "            topic = command[7:]\n",
    "            print(f\"\\n\ud83d\udd04 Reviewing {topic}...\")\n",
    "            print(tracker.review_topic(topic))\n",
    "            \n",
    "        elif command == \"quit\":\n",
    "            print(\"\\n\ud83d\udc4b Keep learning! You're doing great!\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"Unknown command. Try: learn, quiz, score, progress, review, or quit\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_learning_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.4.3: Writing Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_11_4_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class WritingWorkshop:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "        \n",
    "        # Track writing goals and common issues\n",
    "        self.writing_goals = []\n",
    "        self.common_issues = Counter()\n",
    "        self.improvement_history = []\n",
    "        \n",
    "        # Improvement style prompts\n",
    "        self.improvement_styles = {\n",
    "            \"clarity\": ChatPromptTemplate.from_template(\n",
    "                \"\"\"Improve this text for clarity. Make it easier to understand.\n",
    "                Remove ambiguity and simplify complex sentences.\n",
    "                \n",
    "                Text: {text}\n",
    "                \n",
    "                Improved version:\"\"\"\n",
    "            ),\n",
    "            \"creativity\": ChatPromptTemplate.from_template(\n",
    "                \"\"\"Make this text more creative and engaging.\n",
    "                Add vivid descriptions and interesting language.\n",
    "                \n",
    "                Text: {text}\n",
    "                \n",
    "                Creative version:\"\"\"\n",
    "            ),\n",
    "            \"conciseness\": ChatPromptTemplate.from_template(\n",
    "                \"\"\"Make this text more concise. Remove unnecessary words.\n",
    "                Keep the meaning but make it shorter and punchier.\n",
    "                \n",
    "                Text: {text}\n",
    "                \n",
    "                Concise version:\"\"\"\n",
    "            ),\n",
    "            \"professional\": ChatPromptTemplate.from_template(\n",
    "                \"\"\"Make this text more professional and formal.\n",
    "                Use appropriate business language and tone.\n",
    "                \n",
    "                Text: {text}\n",
    "                \n",
    "                Professional version:\"\"\"\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Analysis prompt\n",
    "        self.analysis_prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"Analyze this text and identify the top 3 issues that need improvement.\n",
    "            Be specific and constructive.\n",
    "            \n",
    "            Text: {text}\n",
    "            \n",
    "            Issues:\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Goal-aware feedback prompt\n",
    "        self.feedback_prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"The writer's goals are: {goals}\n",
    "            \n",
    "            Review this text and provide feedback focused on these goals:\n",
    "            {text}\n",
    "            \n",
    "            Feedback:\"\"\"\n",
    "        )\n",
    "    \n",
    "    def set_goals(self, goals):\n",
    "        \"\"\"Set writing goals\"\"\"\n",
    "        if isinstance(goals, str):\n",
    "            goals = [goals]\n",
    "        self.writing_goals = goals\n",
    "        return f\"Goals set: {', '.join(goals)}\"\n",
    "    \n",
    "    def improve(self, text, style=\"clarity\"):\n",
    "        \"\"\"Improve text in specified style\"\"\"\n",
    "        if style not in self.improvement_styles:\n",
    "            return f\"Unknown style. Choose: {', '.join(self.improvement_styles.keys())}\"\n",
    "        \n",
    "        prompt = self.improvement_styles[style]\n",
    "        chain = prompt | self.llm\n",
    "        response = chain.invoke({\"text\": text})\n",
    "        \n",
    "        # Track improvement\n",
    "        self.improvement_history.append({\n",
    "            \"original\": text[:100],\n",
    "            \"style\": style,\n",
    "            \"improved\": response.content[:100]\n",
    "        })\n",
    "        \n",
    "        # Save to memory\n",
    "        self.memory.save_context(\n",
    "            {\"input\": f\"Improve ({style}): {text}\"},\n",
    "            {\"output\": response.content}\n",
    "        )\n",
    "        \n",
    "        return response.content\n",
    "    \n",
    "    def analyze(self, text):\n",
    "        \"\"\"Analyze text for issues\"\"\"\n",
    "        chain = self.analysis_prompt | self.llm\n",
    "        response = chain.invoke({\"text\": text})\n",
    "        \n",
    "        # Extract and track issues\n",
    "        issues = response.content\n",
    "        \n",
    "        # Simple issue extraction (look for numbered items)\n",
    "        import re\n",
    "        found_issues = re.findall(r'\\d+\\.\\s+([^.]+)', issues)\n",
    "        for issue in found_issues:\n",
    "            # Track common issues\n",
    "            key_words = [\"clarity\", \"grammar\", \"structure\", \"flow\", \"word choice\", \n",
    "                        \"repetition\", \"passive voice\", \"complexity\"]\n",
    "            for word in key_words:\n",
    "                if word.lower() in issue.lower():\n",
    "                    self.common_issues[word] += 1\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    def get_feedback(self, text):\n",
    "        \"\"\"Get goal-focused feedback\"\"\"\n",
    "        if not self.writing_goals:\n",
    "            return \"Set your writing goals first for personalized feedback!\"\n",
    "        \n",
    "        chain = self.feedback_prompt | self.llm\n",
    "        response = chain.invoke({\n",
    "            \"goals\": \", \".join(self.writing_goals),\n",
    "            \"text\": text\n",
    "        })\n",
    "        \n",
    "        return response.content\n",
    "    \n",
    "    def show_patterns(self):\n",
    "        \"\"\"Show common issues and improvement patterns\"\"\"\n",
    "        if not self.common_issues:\n",
    "            return \"No patterns identified yet. Analyze more text!\"\n",
    "        \n",
    "        patterns = {\n",
    "            \"common_issues\": dict(self.common_issues.most_common(5)),\n",
    "            \"improvement_styles_used\": Counter(h[\"style\"] for h in self.improvement_history),\n",
    "            \"total_improvements\": len(self.improvement_history)\n",
    "        }\n",
    "        \n",
    "        return patterns\n",
    "    \n",
    "    def suggest_focus(self):\n",
    "        \"\"\"Suggest what to focus on based on patterns\"\"\"\n",
    "        if not self.common_issues:\n",
    "            return \"Analyze some text first to get suggestions!\"\n",
    "        \n",
    "        top_issue = self.common_issues.most_common(1)[0][0]\n",
    "        \n",
    "        suggestions = {\n",
    "            \"clarity\": \"Focus on simplifying sentences and removing ambiguity.\",\n",
    "            \"grammar\": \"Review grammar rules and use grammar checking tools.\",\n",
    "            \"structure\": \"Work on paragraph organization and logical flow.\",\n",
    "            \"flow\": \"Practice transitions between ideas and sentences.\",\n",
    "            \"repetition\": \"Expand your vocabulary and vary sentence structures.\",\n",
    "            \"passive voice\": \"Practice converting passive to active voice.\",\n",
    "            \"complexity\": \"Break down complex ideas into simpler components.\"\n",
    "        }\n",
    "        \n",
    "        return f\"Based on your writing, focus on: {top_issue}. {suggestions.get(top_issue, 'Keep practicing!')}\"\n",
    "\n",
    "# Test the writing workshop\n",
    "def demo_writing_workshop():\n",
    "    workshop = WritingWorkshop()\n",
    "    \n",
    "    # Set goals\n",
    "    print(workshop.set_goals([\"clarity\", \"conciseness\", \"professional tone\"]))\n",
    "    \n",
    "    # Sample text\n",
    "    sample = \"\"\"\n",
    "    The thing is that we need to basically consider thinking about maybe \n",
    "    implementing a new system that could potentially help us with the process \n",
    "    of managing our workflow in a way that might be more efficient.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nOriginal text:\", sample)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Analyze\n",
    "    print(\"\\n\ud83d\udcca ANALYSIS:\")\n",
    "    print(workshop.analyze(sample))\n",
    "    \n",
    "    # Improve in different styles\n",
    "    print(\"\\n\u2728 IMPROVEMENTS:\")\n",
    "    for style in [\"clarity\", \"conciseness\", \"professional\"]:\n",
    "        print(f\"\\n{style.upper()}:\")\n",
    "        print(workshop.improve(sample, style))\n",
    "    \n",
    "    # Get feedback based on goals\n",
    "    print(\"\\n\ud83d\udcac GOAL-BASED FEEDBACK:\")\n",
    "    print(workshop.get_feedback(sample))\n",
    "    \n",
    "    # Show patterns\n",
    "    print(\"\\n\ud83d\udcc8 PATTERNS:\")\n",
    "    print(workshop.show_patterns())\n",
    "    \n",
    "    # Get suggestions\n",
    "    print(\"\\n\ud83d\udca1 SUGGESTION:\")\n",
    "    print(workshop.suggest_focus())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_writing_workshop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11.5 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.5.1: Cost Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_11_5_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, date\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class CostTrackingAssistant:\n",
    "    def __init__(self, daily_budget=1.0):\n",
    "        self.daily_budget = daily_budget\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "        \n",
    "        # Cost per 1000 tokens (approximate)\n",
    "        self.costs = {\n",
    "            \"gpt-3.5-turbo\": 0.002,\n",
    "            \"gpt-4\": 0.06,\n",
    "            \"llama2\": 0.0  # Free local model\n",
    "        }\n",
    "        \n",
    "        # Usage tracking\n",
    "        self.daily_usage = {}\n",
    "        self.conversation_costs = []\n",
    "        self.current_conversation_cost = 0.0\n",
    "        \n",
    "        # Initialize models\n",
    "        self.models = {\n",
    "            \"gpt-3.5-turbo\": ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
    "            \"gpt-4\": ChatOpenAI(model=\"gpt-4\"),\n",
    "            \"llama2\": Ollama(model=\"llama2\")\n",
    "        }\n",
    "        \n",
    "        self.current_model = \"gpt-3.5-turbo\"\n",
    "    \n",
    "    def get_today_spent(self):\n",
    "        \"\"\"Get today's total spending\"\"\"\n",
    "        today = date.today().isoformat()\n",
    "        return self.daily_usage.get(today, 0.0)\n",
    "    \n",
    "    def select_model_by_budget(self):\n",
    "        \"\"\"Select model based on remaining budget\"\"\"\n",
    "        today_spent = self.get_today_spent()\n",
    "        remaining = self.daily_budget - today_spent\n",
    "        \n",
    "        if remaining <= 0:\n",
    "            # No budget left, use free model\n",
    "            self.current_model = \"llama2\"\n",
    "            print(f\"\ud83d\udcb0 Budget exhausted! Switching to free local model.\")\n",
    "        elif remaining < 0.1:\n",
    "            # Low budget, use cheapest\n",
    "            self.current_model = \"gpt-3.5-turbo\"\n",
    "            print(f\"\u26a0\ufe0f Low budget (${remaining:.3f} left). Using GPT-3.5.\")\n",
    "        elif remaining > 0.5:\n",
    "            # Good budget, can use better model for important queries\n",
    "            self.current_model = \"gpt-3.5-turbo\"  # Default to efficient\n",
    "            print(f\"\u2705 Budget available: ${remaining:.3f}\")\n",
    "        \n",
    "        return self.current_model\n",
    "    \n",
    "    def estimate_cost(self, text, model_name):\n",
    "        \"\"\"Estimate cost for a query\"\"\"\n",
    "        # Rough token estimation\n",
    "        tokens = len(text.split()) * 1.5  # Approximate\n",
    "        cost = (tokens / 1000) * self.costs[model_name]\n",
    "        return cost\n",
    "    \n",
    "    def chat(self, message, important=False):\n",
    "        \"\"\"Chat with cost tracking\"\"\"\n",
    "        \n",
    "        # Select model based on budget and importance\n",
    "        if important and self.get_today_spent() < (self.daily_budget * 0.7):\n",
    "            # Use better model for important queries if budget allows\n",
    "            self.current_model = \"gpt-4\"\n",
    "            print(f\"\ud83d\udccc Using GPT-4 for important query\")\n",
    "        else:\n",
    "            self.select_model_by_budget()\n",
    "        \n",
    "        # Get model\n",
    "        model = self.models[self.current_model]\n",
    "        \n",
    "        # Process message\n",
    "        try:\n",
    "            response = model.invoke(message)\n",
    "            \n",
    "            # Extract content\n",
    "            if hasattr(response, 'content'):\n",
    "                content = response.content\n",
    "            else:\n",
    "                content = str(response)\n",
    "            \n",
    "            # Calculate cost\n",
    "            estimated_cost = self.estimate_cost(message + content, self.current_model)\n",
    "            \n",
    "            # Track usage\n",
    "            today = date.today().isoformat()\n",
    "            if today not in self.daily_usage:\n",
    "                self.daily_usage[today] = 0.0\n",
    "            self.daily_usage[today] += estimated_cost\n",
    "            \n",
    "            self.current_conversation_cost += estimated_cost\n",
    "            \n",
    "            # Show cost\n",
    "            print(f\"\ud83d\udcb5 Cost: ${estimated_cost:.5f} | Today: ${self.daily_usage[today]:.4f}\")\n",
    "            \n",
    "            return content\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\u274c Error: {e}\")\n",
    "            return \"Error processing request\"\n",
    "    \n",
    "    def end_conversation(self):\n",
    "        \"\"\"End current conversation and record cost\"\"\"\n",
    "        if self.current_conversation_cost > 0:\n",
    "            self.conversation_costs.append({\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"cost\": self.current_conversation_cost,\n",
    "                \"model\": self.current_model\n",
    "            })\n",
    "            \n",
    "            cost = self.current_conversation_cost\n",
    "            self.current_conversation_cost = 0.0\n",
    "            return f\"Conversation cost: ${cost:.4f}\"\n",
    "        return \"No conversation to end\"\n",
    "    \n",
    "    def daily_report(self):\n",
    "        \"\"\"Generate daily spending report\"\"\"\n",
    "        report = {\n",
    "            \"date\": date.today().isoformat(),\n",
    "            \"budget\": self.daily_budget,\n",
    "            \"spent\": self.get_today_spent(),\n",
    "            \"remaining\": self.daily_budget - self.get_today_spent(),\n",
    "            \"conversations\": len(self.conversation_costs),\n",
    "            \"average_cost\": sum(c[\"cost\"] for c in self.conversation_costs) / len(self.conversation_costs) if self.conversation_costs else 0,\n",
    "            \"model_usage\": {}\n",
    "        }\n",
    "        \n",
    "        # Count model usage\n",
    "        for conv in self.conversation_costs:\n",
    "            model = conv.get(\"model\", \"unknown\")\n",
    "            if model not in report[\"model_usage\"]:\n",
    "                report[\"model_usage\"][model] = 0\n",
    "            report[\"model_usage\"][model] += 1\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def spending_alert(self):\n",
    "        \"\"\"Check spending and alert if needed\"\"\"\n",
    "        spent_percentage = (self.get_today_spent() / self.daily_budget) * 100\n",
    "        \n",
    "        if spent_percentage >= 100:\n",
    "            return \"\ud83d\udd34 BUDGET EXCEEDED! Using free models only.\"\n",
    "        elif spent_percentage >= 90:\n",
    "            return \"\ud83d\udfe1 WARNING: 90% of budget used!\"\n",
    "        elif spent_percentage >= 75:\n",
    "            return \"\ud83d\udfe0 CAUTION: 75% of budget used.\"\n",
    "        else:\n",
    "            return f\"\ud83d\udfe2 Budget healthy: {spent_percentage:.1f}% used\"\n",
    "\n",
    "# Test the cost tracking assistant\n",
    "def demo_cost_tracking():\n",
    "    assistant = CostTrackingAssistant(daily_budget=0.50)\n",
    "    \n",
    "    # Simulate conversations\n",
    "    queries = [\n",
    "        (\"What is Python?\", False),\n",
    "        (\"Explain quantum computing in detail\", True),  # Important\n",
    "        (\"How's the weather?\", False),\n",
    "        (\"Write a business plan\", True),  # Important\n",
    "        (\"Tell me a joke\", False)\n",
    "    ]\n",
    "    \n",
    "    print(\"\ud83d\udcb0 Cost-Aware Assistant Demo\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for query, important in queries:\n",
    "        print(f\"\\n\u2753 Query: {query}\")\n",
    "        print(f\"   Important: {important}\")\n",
    "        \n",
    "        response = assistant.chat(query, important)\n",
    "        print(f\"   Response: {response[:100]}...\")\n",
    "        print(f\"   Alert: {assistant.spending_alert()}\")\n",
    "        \n",
    "        # End conversation after each query for demo\n",
    "        print(f\"   {assistant.end_conversation()}\")\n",
    "    \n",
    "    # Show daily report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\ud83d\udcca DAILY REPORT:\")\n",
    "    report = assistant.daily_report()\n",
    "    print(json.dumps(report, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_cost_tracking()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.5.2: Speed Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_11_5_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from collections import deque\n",
    "import statistics\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class SpeedOptimizedAssistant:\n",
    "    def __init__(self):\n",
    "        # Initialize models\n",
    "        self.models = {\n",
    "            \"gpt-3.5-turbo\": {\n",
    "                \"instance\": ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
    "                \"response_times\": deque(maxlen=10),  # Keep last 10 times\n",
    "                \"failures\": 0,\n",
    "                \"total_calls\": 0\n",
    "            },\n",
    "            \"gpt-4\": {\n",
    "                \"instance\": ChatOpenAI(model=\"gpt-4\"),\n",
    "                \"response_times\": deque(maxlen=10),\n",
    "                \"failures\": 0,\n",
    "                \"total_calls\": 0\n",
    "            },\n",
    "            \"llama2\": {\n",
    "                \"instance\": Ollama(model=\"llama2\"),\n",
    "                \"response_times\": deque(maxlen=10),\n",
    "                \"failures\": 0,\n",
    "                \"total_calls\": 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Performance thresholds\n",
    "        self.timeout_seconds = 10\n",
    "        self.max_failures = 3\n",
    "    \n",
    "    def measure_response_time(self, model_name, prompt):\n",
    "        \"\"\"Measure how long a model takes to respond\"\"\"\n",
    "        model_data = self.models[model_name]\n",
    "        model = model_data[\"instance\"]\n",
    "        \n",
    "        start = time.time()\n",
    "        try:\n",
    "            response = model.invoke(prompt)\n",
    "            elapsed = time.time() - start\n",
    "            \n",
    "            # Record success\n",
    "            model_data[\"response_times\"].append(elapsed)\n",
    "            model_data[\"total_calls\"] += 1\n",
    "            \n",
    "            # Extract content\n",
    "            if hasattr(response, 'content'):\n",
    "                content = response.content\n",
    "            else:\n",
    "                content = str(response)\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"time\": elapsed,\n",
    "                \"content\": content\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - start\n",
    "            model_data[\"failures\"] += 1\n",
    "            model_data[\"total_calls\"] += 1\n",
    "            \n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"time\": elapsed,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    def get_fastest_available(self):\n",
    "        \"\"\"Get the fastest available model\"\"\"\n",
    "        available_models = []\n",
    "        \n",
    "        for name, data in self.models.items():\n",
    "            # Skip models with too many failures\n",
    "            if data[\"failures\"] >= self.max_failures:\n",
    "                continue\n",
    "            \n",
    "            # Calculate average response time\n",
    "            if data[\"response_times\"]:\n",
    "                avg_time = statistics.mean(data[\"response_times\"])\n",
    "                available_models.append((name, avg_time))\n",
    "            else:\n",
    "                # No data yet, assume reasonable default\n",
    "                default_times = {\n",
    "                    \"gpt-3.5-turbo\": 1.0,\n",
    "                    \"gpt-4\": 3.0,\n",
    "                    \"llama2\": 2.0\n",
    "                }\n",
    "                available_models.append((name, default_times.get(name, 5.0)))\n",
    "        \n",
    "        if not available_models:\n",
    "            return None\n",
    "        \n",
    "        # Sort by speed\n",
    "        available_models.sort(key=lambda x: x[1])\n",
    "        return available_models[0][0]\n",
    "    \n",
    "    def chat_with_fallback(self, prompt):\n",
    "        \"\"\"Chat with automatic fallback to slower models\"\"\"\n",
    "        \n",
    "        # Try fastest model first\n",
    "        fastest = self.get_fastest_available()\n",
    "        if not fastest:\n",
    "            return \"No models available!\"\n",
    "        \n",
    "        print(f\"\u26a1 Using {fastest} (fastest available)\")\n",
    "        \n",
    "        # Try primary model\n",
    "        result = self.measure_response_time(fastest, prompt)\n",
    "        \n",
    "        if result[\"success\"]:\n",
    "            print(f\"\u2705 Response in {result['time']:.2f}s\")\n",
    "            return result[\"content\"]\n",
    "        \n",
    "        # Fallback to other models\n",
    "        print(f\"\u274c {fastest} failed, trying fallbacks...\")\n",
    "        \n",
    "        for name, data in sorted(self.models.items(), \n",
    "                                 key=lambda x: len(x[1][\"response_times\"])):\n",
    "            if name == fastest:\n",
    "                continue\n",
    "            \n",
    "            print(f\"\ud83d\udd04 Trying {name}...\")\n",
    "            result = self.measure_response_time(name, prompt)\n",
    "            \n",
    "            if result[\"success\"]:\n",
    "                print(f\"\u2705 Fallback successful in {result['time']:.2f}s\")\n",
    "                return result[\"content\"]\n",
    "        \n",
    "        return \"All models failed!\"\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"Get performance statistics\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        for name, data in self.models.items():\n",
    "            if data[\"response_times\"]:\n",
    "                stats[name] = {\n",
    "                    \"average_time\": statistics.mean(data[\"response_times\"]),\n",
    "                    \"median_time\": statistics.median(data[\"response_times\"]),\n",
    "                    \"min_time\": min(data[\"response_times\"]),\n",
    "                    \"max_time\": max(data[\"response_times\"]),\n",
    "                    \"success_rate\": ((data[\"total_calls\"] - data[\"failures\"]) / \n",
    "                                   data[\"total_calls\"] * 100) if data[\"total_calls\"] > 0 else 0,\n",
    "                    \"total_calls\": data[\"total_calls\"]\n",
    "                }\n",
    "            else:\n",
    "                stats[name] = {\n",
    "                    \"average_time\": None,\n",
    "                    \"success_rate\": 0,\n",
    "                    \"total_calls\": 0\n",
    "                }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def optimize_for_speed(self):\n",
    "        \"\"\"Reorder models based on actual performance\"\"\"\n",
    "        stats = self.get_statistics()\n",
    "        \n",
    "        recommendations = []\n",
    "        for name, stat in stats.items():\n",
    "            if stat[\"average_time\"] is not None:\n",
    "                score = stat[\"average_time\"] * (1 + (100 - stat[\"success_rate\"]) / 100)\n",
    "                recommendations.append((name, score))\n",
    "        \n",
    "        recommendations.sort(key=lambda x: x[1])\n",
    "        \n",
    "        if recommendations:\n",
    "            return f\"Recommended order: {' -> '.join([r[0] for r in recommendations])}\"\n",
    "        return \"Not enough data for optimization\"\n",
    "\n",
    "# Test the speed optimizer\n",
    "def demo_speed_optimizer():\n",
    "    optimizer = SpeedOptimizedAssistant()\n",
    "    \n",
    "    queries = [\n",
    "        \"What is 2+2?\",\n",
    "        \"Explain the meaning of life\",\n",
    "        \"Write a haiku about speed\",\n",
    "        \"What's the capital of France?\",\n",
    "        \"Describe quantum computing\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\u26a1 Speed-Optimized Assistant Demo\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\n\u2753 Query: {query}\")\n",
    "        response = optimizer.chat_with_fallback(query)\n",
    "        print(f\"\ud83d\udcdd Response: {response[:100]}...\")\n",
    "    \n",
    "    # Show statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\ud83d\udcca PERFORMANCE STATISTICS:\")\n",
    "    \n",
    "    stats = optimizer.get_statistics()\n",
    "    for model, data in stats.items():\n",
    "        print(f\"\\n{model}:\")\n",
    "        if data[\"average_time\"]:\n",
    "            print(f\"  Average: {data['average_time']:.2f}s\")\n",
    "            print(f\"  Range: {data['min_time']:.2f}s - {data['max_time']:.2f}s\")\n",
    "            print(f\"  Success: {data['success_rate']:.1f}%\")\n",
    "            print(f\"  Calls: {data['total_calls']}\")\n",
    "    \n",
    "    # Get optimization recommendation\n",
    "    print(\"\\n\ud83d\udca1 Optimization:\")\n",
    "    print(optimizer.optimize_for_speed())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_speed_optimizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.5.3: Privacy Guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_11_5_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class PrivacyGuardianAssistant:\n",
    "    def __init__(self):\n",
    "        # Models\n",
    "        self.cloud_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "        self.local_model = Ollama(model=\"llama2\")\n",
    "        \n",
    "        # Privacy patterns\n",
    "        self.pii_patterns = {\n",
    "            \"ssn\": r'\\b\\d{3}-\\d{2}-\\d{4}\\b',\n",
    "            \"phone\": r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b',\n",
    "            \"email\": r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "            \"credit_card\": r'\\b\\d{4}[-\\s]?\\d{4}[-\\s]?\\d{4}[-\\s]?\\d{4}\\b',\n",
    "            \"address\": r'\\d+\\s+[\\w\\s]+\\s+(Street|St|Avenue|Ave|Road|Rd|Lane|Ln)',\n",
    "            \"medical\": r'\\b(diagnosis|prescription|medical|health condition|symptoms)\\b',\n",
    "            \"financial\": r'\\b(bank account|salary|income|tax|financial)\\b'\n",
    "        }\n",
    "        \n",
    "        # Audit log\n",
    "        self.audit_log = []\n",
    "    \n",
    "    def detect_private_info(self, text):\n",
    "        \"\"\"Detect if text contains private information\"\"\"\n",
    "        detected = []\n",
    "        \n",
    "        # Check for PII patterns\n",
    "        for info_type, pattern in self.pii_patterns.items():\n",
    "            if re.search(pattern, text, re.IGNORECASE):\n",
    "                detected.append(info_type)\n",
    "        \n",
    "        # Check for sensitive keywords\n",
    "        sensitive_keywords = [\n",
    "            \"password\", \"secret\", \"private\", \"confidential\",\n",
    "            \"personal\", \"medical\", \"health\", \"diagnosis\",\n",
    "            \"salary\", \"income\", \"bank\", \"account\"\n",
    "        ]\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        for keyword in sensitive_keywords:\n",
    "            if keyword in text_lower:\n",
    "                detected.append(f\"keyword:{keyword}\")\n",
    "        \n",
    "        return detected\n",
    "    \n",
    "    def anonymize_text(self, text):\n",
    "        \"\"\"Remove or mask private information\"\"\"\n",
    "        anonymized = text\n",
    "        \n",
    "        # Replace patterns with masks\n",
    "        replacements = {\n",
    "            \"ssn\": \"[SSN REMOVED]\",\n",
    "            \"phone\": \"[PHONE REMOVED]\",\n",
    "            \"email\": \"[EMAIL REMOVED]\",\n",
    "            \"credit_card\": \"[CARD REMOVED]\",\n",
    "            \"address\": \"[ADDRESS REMOVED]\"\n",
    "        }\n",
    "        \n",
    "        for info_type, pattern in self.pii_patterns.items():\n",
    "            if info_type in replacements:\n",
    "                anonymized = re.sub(pattern, replacements[info_type], \n",
    "                                   anonymized, flags=re.IGNORECASE)\n",
    "        \n",
    "        return anonymized\n",
    "    \n",
    "    def select_model(self, text):\n",
    "        \"\"\"Select appropriate model based on privacy\"\"\"\n",
    "        private_info = self.detect_private_info(text)\n",
    "        \n",
    "        if private_info:\n",
    "            return \"local\", private_info\n",
    "        else:\n",
    "            return \"cloud\", []\n",
    "    \n",
    "    def process_query(self, query):\n",
    "        \"\"\"Process query with privacy protection\"\"\"\n",
    "        \n",
    "        # Detect private information\n",
    "        model_choice, private_info = self.select_model(query)\n",
    "        \n",
    "        # Log the decision\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"query_length\": len(query),\n",
    "            \"model_used\": model_choice,\n",
    "            \"private_info_detected\": private_info,\n",
    "            \"query_hash\": hash(query)  # Store hash, not actual query\n",
    "        }\n",
    "        \n",
    "        self.audit_log.append(log_entry)\n",
    "        \n",
    "        # Inform user\n",
    "        if model_choice == \"local\":\n",
    "            print(f\"\ud83d\udd12 Private information detected: {', '.join(private_info)}\")\n",
    "            print(\"   Using local model for privacy protection\")\n",
    "            \n",
    "            # Use local model\n",
    "            model = self.local_model\n",
    "            \n",
    "            # Process locally\n",
    "            response = model.invoke(query)\n",
    "            \n",
    "            result = {\n",
    "                \"model\": \"local\",\n",
    "                \"response\": str(response),\n",
    "                \"privacy_protected\": True\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            print(\"\u2601\ufe0f No private information detected\")\n",
    "            print(\"   Using cloud model for better performance\")\n",
    "            \n",
    "            # Anonymize just in case\n",
    "            safe_query = self.anonymize_text(query)\n",
    "            \n",
    "            # Use cloud model\n",
    "            model = self.cloud_model\n",
    "            response = model.invoke(safe_query)\n",
    "            \n",
    "            result = {\n",
    "                \"model\": \"cloud\",\n",
    "                \"response\": response.content,\n",
    "                \"privacy_protected\": False\n",
    "            }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_audit_summary(self):\n",
    "        \"\"\"Get summary of model usage\"\"\"\n",
    "        if not self.audit_log:\n",
    "            return \"No queries processed yet\"\n",
    "        \n",
    "        total = len(self.audit_log)\n",
    "        local_count = sum(1 for log in self.audit_log if log[\"model_used\"] == \"local\")\n",
    "        cloud_count = total - local_count\n",
    "        \n",
    "        # Count types of private info detected\n",
    "        private_info_counts = {}\n",
    "        for log in self.audit_log:\n",
    "            for info in log[\"private_info_detected\"]:\n",
    "                private_info_counts[info] = private_info_counts.get(info, 0) + 1\n",
    "        \n",
    "        summary = {\n",
    "            \"total_queries\": total,\n",
    "            \"local_model_used\": local_count,\n",
    "            \"cloud_model_used\": cloud_count,\n",
    "            \"privacy_protection_rate\": (local_count / total * 100) if total > 0 else 0,\n",
    "            \"private_info_types\": private_info_counts\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def export_audit_log(self, filename=\"audit_log.json\"):\n",
    "        \"\"\"Export audit log for compliance\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(self.audit_log, f, indent=2)\n",
    "        return f\"Audit log exported to {filename}\"\n",
    "\n",
    "# Test the privacy guardian\n",
    "def demo_privacy_guardian():\n",
    "    guardian = PrivacyGuardianAssistant()\n",
    "    \n",
    "    # Test queries with different privacy levels\n",
    "    test_queries = [\n",
    "        \"What is the weather like today?\",  # Safe\n",
    "        \"My SSN is 123-45-6789, is this format correct?\",  # Private\n",
    "        \"How do I improve my credit score?\",  # Potentially sensitive\n",
    "        \"My email is john@example.com\",  # Private\n",
    "        \"What are the symptoms of flu?\",  # Medical - sensitive\n",
    "        \"Tell me about Python programming\",  # Safe\n",
    "        \"My bank account number is 1234567890\",  # Private\n",
    "        \"What's the capital of France?\"  # Safe\n",
    "    ]\n",
    "    \n",
    "    print(\"\ud83d\udd12 Privacy Guardian Assistant Demo\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n\u2753 Query: {query[:50]}...\")\n",
    "        result = guardian.process_query(query)\n",
    "        print(f\"\ud83d\udcdd Response: {result['response'][:100]}...\")\n",
    "        print(f\"   Model: {result['model']}\")\n",
    "        print(f\"   Protected: {result['privacy_protected']}\")\n",
    "    \n",
    "    # Show audit summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\ud83d\udcca AUDIT SUMMARY:\")\n",
    "    summary = guardian.get_audit_summary()\n",
    "    print(json.dumps(summary, indent=2))\n",
    "    \n",
    "    # Export audit log\n",
    "    print(f\"\\n\ud83d\udcc1 {guardian.export_audit_log()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_privacy_guardian()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11.6 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.6.1: Email Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_11_6_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class EmailDetails(BaseModel):\n",
    "    sender_name: str = Field(description=\"Sender's full name\")\n",
    "    sender_email: str = Field(description=\"Sender's email address\")\n",
    "    sender_company: Optional[str] = Field(description=\"Sender's company if mentioned\")\n",
    "    email_category: str = Field(description=\"Category: support, sales, or complaint\")\n",
    "    sentiment: str = Field(description=\"Sentiment: positive, negative, or neutral\")\n",
    "    action_required: bool = Field(description=\"Whether action is required\")\n",
    "    priority_level: str = Field(description=\"Priority: high, medium, or low\")\n",
    "    \n",
    "    @validator('email_category')\n",
    "    def validate_category(cls, v):\n",
    "        if v not in ['support', 'sales', 'complaint']:\n",
    "            raise ValueError('Category must be support, sales, or complaint')\n",
    "        return v\n",
    "    \n",
    "    @validator('sentiment')\n",
    "    def validate_sentiment(cls, v):\n",
    "        if v not in ['positive', 'negative', 'neutral']:\n",
    "            raise ValueError('Sentiment must be positive, negative, or neutral')\n",
    "        return v\n",
    "    \n",
    "    @validator('priority_level')\n",
    "    def validate_priority(cls, v):\n",
    "        if v not in ['high', 'medium', 'low']:\n",
    "            raise ValueError('Priority must be high, medium, or low')\n",
    "        return v\n",
    "\n",
    "class EmailAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.parser = PydanticOutputParser(pydantic_object=EmailDetails)\n",
    "        \n",
    "        self.prompt = PromptTemplate(\n",
    "            template=\"\"\"Analyze this email and extract the requested information.\n",
    "\n",
    "Email:\n",
    "{email_text}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Use these guidelines:\n",
    "- Support: asking for help or reporting issues\n",
    "- Sales: inquiring about products or services\n",
    "- Complaint: expressing dissatisfaction\n",
    "- High priority: urgent issues or from important senders\n",
    "- Action required: needs a response or follow-up\n",
    "\"\"\",\n",
    "            input_variables=[\"email_text\"],\n",
    "            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n",
    "        )\n",
    "        \n",
    "        self.chain = self.prompt | self.llm | self.parser\n",
    "    \n",
    "    def analyze(self, email_text):\n",
    "        \"\"\"Analyze an email and extract structured information\"\"\"\n",
    "        try:\n",
    "            result = self.chain.invoke({\"email_text\": email_text})\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing email: {e}\")\n",
    "            return None\n",
    "\n",
    "# Test the analyzer\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = EmailAnalyzer()\n",
    "    \n",
    "    test_email = \"\"\"\n",
    "    From: Jane Smith <jane.smith@techcorp.com>\n",
    "    Subject: Urgent: System not working properly\n",
    "    \n",
    "    Hello Support Team,\n",
    "    \n",
    "    I'm experiencing critical issues with your software. Our entire team \n",
    "    at TechCorp cannot access the dashboard since this morning. This is \n",
    "    blocking our work and we need immediate assistance.\n",
    "    \n",
    "    Please help us resolve this as soon as possible.\n",
    "    \n",
    "    Best regards,\n",
    "    Jane Smith\n",
    "    Senior Manager, TechCorp\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\ud83d\udce7 Email Analyzer\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = analyzer.analyze(test_email)\n",
    "    if result:\n",
    "        print(f\"Sender: {result.sender_name} ({result.sender_email})\")\n",
    "        print(f\"Company: {result.sender_company}\")\n",
    "        print(f\"Category: {result.email_category}\")\n",
    "        print(f\"Sentiment: {result.sentiment}\")\n",
    "        print(f\"Action Required: {result.action_required}\")\n",
    "        print(f\"Priority: {result.priority_level}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.6.2: Meeting Notes Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_11_6_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class ActionItem(BaseModel):\n",
    "    task: str = Field(description=\"The task to be completed\")\n",
    "    owner: str = Field(description=\"Person responsible\")\n",
    "    deadline: Optional[str] = Field(description=\"When it's due\")\n",
    "\n",
    "class MeetingMinutes(BaseModel):\n",
    "    meeting_date: str = Field(description=\"Date of the meeting\")\n",
    "    attendees: List[str] = Field(description=\"List of attendees\")\n",
    "    key_decisions: List[str] = Field(description=\"Key decisions made\")\n",
    "    action_items: List[ActionItem] = Field(description=\"Action items with owners\")\n",
    "    follow_up_dates: List[str] = Field(description=\"Follow-up dates mentioned\")\n",
    "    main_topics: List[str] = Field(description=\"Main topics discussed\")\n",
    "    \n",
    "    @validator('attendees')\n",
    "    def validate_attendees(cls, v):\n",
    "        if not v:\n",
    "            raise ValueError('At least one attendee required')\n",
    "        return v\n",
    "\n",
    "class MeetingNotesParser:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.parser = PydanticOutputParser(pydantic_object=MeetingMinutes)\n",
    "        \n",
    "        self.prompt = PromptTemplate(\n",
    "            template=\"\"\"Extract structured information from these meeting notes.\n",
    "\n",
    "Meeting Notes:\n",
    "{notes}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Focus on:\n",
    "- All people mentioned as attendees\n",
    "- Clear decisions (look for \"decided\", \"agreed\", \"will\")\n",
    "- Action items with specific owners\n",
    "- Any follow-up dates or deadlines\n",
    "\"\"\",\n",
    "            input_variables=[\"notes\"],\n",
    "            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n",
    "        )\n",
    "        \n",
    "        self.chain = self.prompt | self.llm | self.parser\n",
    "    \n",
    "    def parse(self, notes_text):\n",
    "        \"\"\"Parse meeting notes\"\"\"\n",
    "        try:\n",
    "            result = self.chain.invoke({\"notes\": notes_text})\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing notes: {e}\")\n",
    "            return None\n",
    "\n",
    "# Test the parser\n",
    "if __name__ == \"__main__\":\n",
    "    parser = MeetingNotesParser()\n",
    "    \n",
    "    test_notes = \"\"\"\n",
    "    Team Meeting - March 15, 2024\n",
    "    \n",
    "    Attendees: Alice Johnson (PM), Bob Chen (Dev Lead), Carol White (Designer)\n",
    "    \n",
    "    Discussion:\n",
    "    - Reviewed Q2 product roadmap\n",
    "    - Discussed user feedback from beta testing\n",
    "    - Decided to prioritize mobile app improvements\n",
    "    - Agreed on new feature freeze date: April 1st\n",
    "    \n",
    "    Action Items:\n",
    "    - Alice: Schedule stakeholder review by March 20\n",
    "    - Bob: Complete API documentation by March 25\n",
    "    - Carol: Deliver new mockups by March 22\n",
    "    \n",
    "    Follow-up meeting scheduled for March 29 to review progress.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\ud83d\udcdd Meeting Notes Parser\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = parser.parse(test_notes)\n",
    "    if result:\n",
    "        print(f\"Date: {result.meeting_date}\")\n",
    "        print(f\"Attendees: {', '.join(result.attendees)}\")\n",
    "        print(f\"\\nKey Decisions:\")\n",
    "        for decision in result.key_decisions:\n",
    "            print(f\"  \u2022 {decision}\")\n",
    "        print(f\"\\nAction Items:\")\n",
    "        for item in result.action_items:\n",
    "            print(f\"  \u2022 {item.task}\")\n",
    "            print(f\"    Owner: {item.owner}\")\n",
    "            if item.deadline:\n",
    "                print(f\"    Due: {item.deadline}\")\n",
    "        print(f\"\\nFollow-up Dates: {', '.join(result.follow_up_dates)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.6.3: Product Review Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_11_6_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class ProductReview(BaseModel):\n",
    "    overall_rating: float = Field(description=\"Overall rating from 1-5\")\n",
    "    pros: List[str] = Field(description=\"List of positive aspects\")\n",
    "    cons: List[str] = Field(description=\"List of negative aspects\") \n",
    "    would_recommend: bool = Field(description=\"Whether reviewer would recommend\")\n",
    "    key_features: List[str] = Field(description=\"Key product features mentioned\")\n",
    "    \n",
    "    @validator('overall_rating')\n",
    "    def validate_rating(cls, v):\n",
    "        if not 1 <= v <= 5:\n",
    "            raise ValueError('Rating must be between 1 and 5')\n",
    "        return v\n",
    "\n",
    "class ReviewExtractor:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.parser = PydanticOutputParser(pydantic_object=ProductReview)\n",
    "        \n",
    "        self.prompt = PromptTemplate(\n",
    "            template=\"\"\"Extract structured information from this product review.\n",
    "\n",
    "Review:\n",
    "{review_text}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Guidelines:\n",
    "- Extract rating on 1-5 scale (convert if necessary)\n",
    "- List specific pros mentioned\n",
    "- List specific cons mentioned\n",
    "- Determine if reviewer would recommend based on overall tone\n",
    "- Identify key product features discussed\n",
    "\"\"\",\n",
    "            input_variables=[\"review_text\"],\n",
    "            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n",
    "        )\n",
    "        \n",
    "        self.chain = self.prompt | self.llm | self.parser\n",
    "    \n",
    "    def extract(self, review_text):\n",
    "        \"\"\"Extract structured data from a review\"\"\"\n",
    "        try:\n",
    "            result = self.chain.invoke({\"review_text\": review_text})\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting review data: {e}\")\n",
    "            return None\n",
    "\n",
    "# Test the extractor\n",
    "if __name__ == \"__main__\":\n",
    "    extractor = ReviewExtractor()\n",
    "    \n",
    "    test_review = \"\"\"\n",
    "    I bought this wireless headphone last month and I'm giving it 4 stars.\n",
    "    \n",
    "    The good: Amazing sound quality with deep bass, comfortable for long wearing,\n",
    "    excellent battery life (30+ hours), and great noise cancellation. The bluetooth\n",
    "    connection is stable and the range is impressive.\n",
    "    \n",
    "    The not so good: They're quite expensive, the case is bulky for travel,\n",
    "    and the touch controls can be overly sensitive sometimes.\n",
    "    \n",
    "    Overall, despite the high price, I'd recommend these to anyone who values\n",
    "    audio quality and comfort. The noise cancellation alone makes them worth it\n",
    "    for frequent travelers or remote workers.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\ud83d\udce6 Product Review Extractor\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = extractor.extract(test_review)\n",
    "    if result:\n",
    "        print(f\"Rating: {'\u2b50' * int(result.overall_rating)} ({result.overall_rating}/5)\")\n",
    "        print(f\"\\n\u2705 Pros:\")\n",
    "        for pro in result.pros:\n",
    "            print(f\"  \u2022 {pro}\")\n",
    "        print(f\"\\n\u274c Cons:\")\n",
    "        for con in result.cons:\n",
    "            print(f\"  \u2022 {con}\")\n",
    "        print(f\"\\n\ud83d\udca1 Would Recommend: {'Yes' if result.would_recommend else 'No'}\")\n",
    "        print(f\"\\n\ud83d\udd27 Key Features Mentioned:\")\n",
    "        for feature in result.key_features:\n",
    "            print(f\"  \u2022 {feature}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11.7 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.7.1: Debug Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_11_7_solution.py\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class DebugDashboard:\n",
    "    def __init__(self):\n",
    "        self.components = {\n",
    "            \"api_key\": {\"status\": \"unknown\", \"last_check\": None},\n",
    "            \"llm\": {\"status\": \"unknown\", \"last_check\": None, \"model\": \"gpt-3.5-turbo\"},\n",
    "            \"memory\": {\"status\": \"unknown\", \"size\": 0},\n",
    "            \"chains\": {\"active\": [], \"failed\": []},\n",
    "            \"prompts\": {\"loaded\": 0, \"errors\": []}\n",
    "        }\n",
    "        \n",
    "        self.recent_errors = deque(maxlen=10)\n",
    "        self.performance_metrics = {\n",
    "            \"llm_calls\": [],\n",
    "            \"chain_executions\": [],\n",
    "            \"memory_operations\": []\n",
    "        }\n",
    "        \n",
    "        self.quick_fixes = {\n",
    "            \"api_key_missing\": \"Add OPENAI_API_KEY to your .env file\",\n",
    "            \"import_error\": \"Run: pip install langchain langchain-openai\",\n",
    "            \"rate_limit\": \"Wait 60 seconds or upgrade your API plan\",\n",
    "            \"memory_overflow\": \"Clear memory or use ConversationSummaryMemory\",\n",
    "            \"chain_error\": \"Check all required input variables are provided\"\n",
    "        }\n",
    "    \n",
    "    def check_api_key(self):\n",
    "        \"\"\"Check API key status\"\"\"\n",
    "        key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if key and key.startswith(\"sk-\"):\n",
    "            self.components[\"api_key\"][\"status\"] = \"\u2705 Valid\"\n",
    "        elif key:\n",
    "            self.components[\"api_key\"][\"status\"] = \"\u26a0\ufe0f Invalid format\"\n",
    "        else:\n",
    "            self.components[\"api_key\"][\"status\"] = \"\u274c Missing\"\n",
    "            self.recent_errors.append({\n",
    "                \"time\": datetime.now(),\n",
    "                \"component\": \"api_key\",\n",
    "                \"error\": \"No API key found\",\n",
    "                \"fix\": self.quick_fixes[\"api_key_missing\"]\n",
    "            })\n",
    "        \n",
    "        self.components[\"api_key\"][\"last_check\"] = datetime.now()\n",
    "    \n",
    "    def check_llm(self):\n",
    "        \"\"\"Check LLM connectivity\"\"\"\n",
    "        try:\n",
    "            llm = ChatOpenAI(model=self.components[\"llm\"][\"model\"])\n",
    "            \n",
    "            start = time.time()\n",
    "            response = llm.invoke(\"Test\")\n",
    "            elapsed = time.time() - start\n",
    "            \n",
    "            self.components[\"llm\"][\"status\"] = f\"\u2705 Working ({elapsed:.2f}s)\"\n",
    "            self.performance_metrics[\"llm_calls\"].append(elapsed)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.components[\"llm\"][\"status\"] = f\"\u274c Failed\"\n",
    "            self.recent_errors.append({\n",
    "                \"time\": datetime.now(),\n",
    "                \"component\": \"llm\",\n",
    "                \"error\": str(e),\n",
    "                \"fix\": self._suggest_fix(str(e))\n",
    "            })\n",
    "        \n",
    "        self.components[\"llm\"][\"last_check\"] = datetime.now()\n",
    "    \n",
    "    def check_memory(self):\n",
    "        \"\"\"Check memory status\"\"\"\n",
    "        try:\n",
    "            memory = ConversationBufferMemory()\n",
    "            \n",
    "            # Test save and load\n",
    "            memory.save_context({\"input\": \"test\"}, {\"output\": \"response\"})\n",
    "            history = memory.load_memory_variables({})\n",
    "            \n",
    "            self.components[\"memory\"][\"status\"] = \"\u2705 Working\"\n",
    "            self.components[\"memory\"][\"size\"] = len(str(history))\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.components[\"memory\"][\"status\"] = \"\u274c Failed\"\n",
    "            self.recent_errors.append({\n",
    "                \"time\": datetime.now(),\n",
    "                \"component\": \"memory\",\n",
    "                \"error\": str(e),\n",
    "                \"fix\": \"Check memory initialization\"\n",
    "            })\n",
    "    \n",
    "    def test_chain(self, chain_name=\"test\"):\n",
    "        \"\"\"Test a chain execution\"\"\"\n",
    "        try:\n",
    "            prompt = ChatPromptTemplate.from_template(\"Test: {input}\")\n",
    "            llm = ChatOpenAI()\n",
    "            chain = prompt | llm\n",
    "            \n",
    "            start = time.time()\n",
    "            result = chain.invoke({\"input\": \"test\"})\n",
    "            elapsed = time.time() - start\n",
    "            \n",
    "            self.components[\"chains\"][\"active\"].append(chain_name)\n",
    "            self.performance_metrics[\"chain_executions\"].append(elapsed)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.components[\"chains\"][\"failed\"].append(chain_name)\n",
    "            self.recent_errors.append({\n",
    "                \"time\": datetime.now(),\n",
    "                \"component\": f\"chain:{chain_name}\",\n",
    "                \"error\": str(e),\n",
    "                \"fix\": self.quick_fixes[\"chain_error\"]\n",
    "            })\n",
    "            return False\n",
    "    \n",
    "    def _suggest_fix(self, error_msg):\n",
    "        \"\"\"Suggest fix based on error\"\"\"\n",
    "        error_lower = error_msg.lower()\n",
    "        \n",
    "        if \"api\" in error_lower and \"key\" in error_lower:\n",
    "            return self.quick_fixes[\"api_key_missing\"]\n",
    "        elif \"rate\" in error_lower:\n",
    "            return self.quick_fixes[\"rate_limit\"]\n",
    "        elif \"import\" in error_lower:\n",
    "            return self.quick_fixes[\"import_error\"]\n",
    "        else:\n",
    "            return \"Check error message and documentation\"\n",
    "    \n",
    "    def run_diagnostics(self):\n",
    "        \"\"\"Run all diagnostic checks\"\"\"\n",
    "        print(\"\ud83d\udd0d Running diagnostics...\")\n",
    "        self.check_api_key()\n",
    "        self.check_llm()\n",
    "        self.check_memory()\n",
    "        self.test_chain()\n",
    "    \n",
    "    def display_dashboard(self):\n",
    "        \"\"\"Display the dashboard\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"\ud83c\udfaf LANGCHAIN DEBUG DASHBOARD\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Component Status\n",
    "        print(\"\\n\ud83d\udcca Component Status:\")\n",
    "        for name, info in self.components.items():\n",
    "            status = info.get(\"status\", \"unknown\")\n",
    "            print(f\"  {name:15} {status}\")\n",
    "        \n",
    "        # Performance Metrics\n",
    "        print(\"\\n\u26a1 Performance Metrics:\")\n",
    "        if self.performance_metrics[\"llm_calls\"]:\n",
    "            avg_llm = sum(self.performance_metrics[\"llm_calls\"]) / len(self.performance_metrics[\"llm_calls\"])\n",
    "            print(f\"  LLM Avg Response: {avg_llm:.2f}s\")\n",
    "        \n",
    "        if self.performance_metrics[\"chain_executions\"]:\n",
    "            avg_chain = sum(self.performance_metrics[\"chain_executions\"]) / len(self.performance_metrics[\"chain_executions\"])\n",
    "            print(f\"  Chain Avg Execution: {avg_chain:.2f}s\")\n",
    "        \n",
    "        # Recent Errors\n",
    "        if self.recent_errors:\n",
    "            print(\"\\n\u274c Recent Errors:\")\n",
    "            for error in list(self.recent_errors)[-3:]:  # Show last 3\n",
    "                print(f\"  [{error['time'].strftime('%H:%M:%S')}] {error['component']}\")\n",
    "                print(f\"    Error: {error['error'][:50]}...\")\n",
    "                print(f\"    Fix: {error['fix']}\")\n",
    "        \n",
    "        # Quick Actions\n",
    "        print(\"\\n\ud83d\udd27 Quick Actions:\")\n",
    "        print(\"  1. Clear Memory: memory.clear()\")\n",
    "        print(\"  2. Restart LLM: llm = ChatOpenAI()\")\n",
    "        print(\"  3. Check Env: load_dotenv(override=True)\")\n",
    "        print(\"  4. Debug Mode: set_debug(True)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Run the dashboard\n",
    "if __name__ == \"__main__\":\n",
    "    dashboard = DebugDashboard()\n",
    "    dashboard.run_diagnostics()\n",
    "    dashboard.display_dashboard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.7.2: Performance Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_11_7_solution.py\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "import statistics\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"llm_calls\": deque(maxlen=100),\n",
    "            \"chain_executions\": deque(maxlen=100),\n",
    "            \"prompt_formatting\": deque(maxlen=100),\n",
    "            \"memory_operations\": deque(maxlen=100),\n",
    "            \"tool_calls\": deque(maxlen=100)\n",
    "        }\n",
    "        \n",
    "        self.slow_threshold = {\n",
    "            \"llm_calls\": 2.0,\n",
    "            \"chain_executions\": 3.0,\n",
    "            \"prompt_formatting\": 0.1,\n",
    "            \"memory_operations\": 0.5,\n",
    "            \"tool_calls\": 1.0\n",
    "        }\n",
    "        \n",
    "        self.alerts = []\n",
    "    \n",
    "    def measure(self, component_type, func, *args, **kwargs):\n",
    "        \"\"\"Measure execution time of a component\"\"\"\n",
    "        start = time.time()\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            elapsed = time.time() - start\n",
    "            \n",
    "            # Record metric\n",
    "            self.metrics[component_type].append({\n",
    "                \"time\": elapsed,\n",
    "                \"timestamp\": datetime.now(),\n",
    "                \"success\": True\n",
    "            })\n",
    "            \n",
    "            # Check for slowness\n",
    "            if elapsed > self.slow_threshold[component_type]:\n",
    "                self.alert_slowdown(component_type, elapsed)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - start\n",
    "            self.metrics[component_type].append({\n",
    "                \"time\": elapsed,\n",
    "                \"timestamp\": datetime.now(),\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            raise\n",
    "    \n",
    "    def alert_slowdown(self, component_type, time_taken):\n",
    "        \"\"\"Alert on performance degradation\"\"\"\n",
    "        alert = {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"component\": component_type,\n",
    "            \"time\": time_taken,\n",
    "            \"threshold\": self.slow_threshold[component_type],\n",
    "            \"severity\": \"warning\" if time_taken < self.slow_threshold[component_type] * 2 else \"critical\"\n",
    "        }\n",
    "        \n",
    "        self.alerts.append(alert)\n",
    "        print(f\"\u26a0\ufe0f PERFORMANCE ALERT: {component_type} took {time_taken:.2f}s (threshold: {self.slow_threshold[component_type]}s)\")\n",
    "    \n",
    "    def get_statistics(self, component_type):\n",
    "        \"\"\"Get performance statistics for a component\"\"\"\n",
    "        if component_type not in self.metrics or not self.metrics[component_type]:\n",
    "            return None\n",
    "        \n",
    "        times = [m[\"time\"] for m in self.metrics[component_type] if m[\"success\"]]\n",
    "        \n",
    "        if not times:\n",
    "            return None\n",
    "        \n",
    "        return {\n",
    "            \"component\": component_type,\n",
    "            \"count\": len(times),\n",
    "            \"avg\": statistics.mean(times),\n",
    "            \"median\": statistics.median(times),\n",
    "            \"min\": min(times),\n",
    "            \"max\": max(times),\n",
    "            \"std_dev\": statistics.stdev(times) if len(times) > 1 else 0\n",
    "        }\n",
    "    \n",
    "    def identify_bottlenecks(self):\n",
    "        \"\"\"Identify performance bottlenecks\"\"\"\n",
    "        bottlenecks = []\n",
    "        \n",
    "        for component_type in self.metrics:\n",
    "            stats = self.get_statistics(component_type)\n",
    "            if stats and stats[\"avg\"] > self.slow_threshold[component_type]:\n",
    "                bottlenecks.append({\n",
    "                    \"component\": component_type,\n",
    "                    \"avg_time\": stats[\"avg\"],\n",
    "                    \"severity\": \"high\" if stats[\"avg\"] > self.slow_threshold[component_type] * 2 else \"medium\"\n",
    "                })\n",
    "        \n",
    "        return sorted(bottlenecks, key=lambda x: x[\"avg_time\"], reverse=True)\n",
    "    \n",
    "    def suggest_optimizations(self):\n",
    "        \"\"\"Suggest optimizations based on metrics\"\"\"\n",
    "        suggestions = []\n",
    "        bottlenecks = self.identify_bottlenecks()\n",
    "        \n",
    "        for bottleneck in bottlenecks:\n",
    "            component = bottleneck[\"component\"]\n",
    "            \n",
    "            if component == \"llm_calls\":\n",
    "                suggestions.append({\n",
    "                    \"component\": component,\n",
    "                    \"suggestion\": \"Consider using GPT-3.5-turbo instead of GPT-4 for faster response\",\n",
    "                    \"potential_improvement\": \"50-70% faster\"\n",
    "                })\n",
    "            elif component == \"chain_executions\":\n",
    "                suggestions.append({\n",
    "                    \"component\": component,\n",
    "                    \"suggestion\": \"Break complex chains into simpler steps\",\n",
    "                    \"potential_improvement\": \"20-30% faster\"\n",
    "                })\n",
    "            elif component == \"memory_operations\":\n",
    "                suggestions.append({\n",
    "                    \"component\": component,\n",
    "                    \"suggestion\": \"Use ConversationSummaryMemory for long conversations\",\n",
    "                    \"potential_improvement\": \"40-60% faster\"\n",
    "                })\n",
    "        \n",
    "        return suggestions\n",
    "    \n",
    "    def display_dashboard(self):\n",
    "        \"\"\"Display performance dashboard\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"\ud83d\udcca PERFORMANCE MONITOR DASHBOARD\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Component statistics\n",
    "        print(\"\\n\u23f1\ufe0f Component Performance:\")\n",
    "        for component_type in self.metrics:\n",
    "            stats = self.get_statistics(component_type)\n",
    "            if stats:\n",
    "                print(f\"\\n  {component_type}:\")\n",
    "                print(f\"    Calls: {stats['count']}\")\n",
    "                print(f\"    Avg: {stats['avg']:.3f}s\")\n",
    "                print(f\"    Min/Max: {stats['min']:.3f}s / {stats['max']:.3f}s\")\n",
    "        \n",
    "        # Bottlenecks\n",
    "        bottlenecks = self.identify_bottlenecks()\n",
    "        if bottlenecks:\n",
    "            print(\"\\n\ud83d\udea8 Bottlenecks:\")\n",
    "            for b in bottlenecks:\n",
    "                print(f\"  {b['component']}: {b['avg_time']:.3f}s ({b['severity']} severity)\")\n",
    "        \n",
    "        # Optimizations\n",
    "        suggestions = self.suggest_optimizations()\n",
    "        if suggestions:\n",
    "            print(\"\\n\ud83d\udca1 Optimization Suggestions:\")\n",
    "            for s in suggestions:\n",
    "                print(f\"  {s['component']}:\")\n",
    "                print(f\"    {s['suggestion']}\")\n",
    "                print(f\"    Expected: {s['potential_improvement']}\")\n",
    "        \n",
    "        # Recent alerts\n",
    "        if self.alerts:\n",
    "            print(f\"\\n\u26a0\ufe0f Recent Alerts ({len(self.alerts)} total):\")\n",
    "            for alert in self.alerts[-3:]:\n",
    "                print(f\"  [{alert['timestamp'].strftime('%H:%M:%S')}] {alert['component']}: {alert['time']:.2f}s\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Demo usage\n",
    "if __name__ == \"__main__\":\n",
    "    monitor = PerformanceMonitor()\n",
    "    \n",
    "    # Simulate some measurements\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    load_dotenv()\n",
    "    \n",
    "    # Measure LLM call\n",
    "    llm = ChatOpenAI()\n",
    "    monitor.measure(\"llm_calls\", llm.invoke, \"Test message\")\n",
    "    \n",
    "    # Measure prompt formatting\n",
    "    prompt = ChatPromptTemplate.from_template(\"Test: {input}\")\n",
    "    monitor.measure(\"prompt_formatting\", prompt.format_messages, input=\"test\")\n",
    "    \n",
    "    # Display results\n",
    "    monitor.display_dashboard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11.7.3: Error Recovery System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_11_7_solution.py\n",
    "\n",
    "import time\n",
    "import json\n",
    "from typing import Callable, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "class ErrorRecoverySystem:\n",
    "    def __init__(self):\n",
    "        self.error_log = []\n",
    "        self.recovery_strategies = {\n",
    "            \"api_key\": self.recover_api_key,\n",
    "            \"rate_limit\": self.recover_rate_limit,\n",
    "            \"timeout\": self.recover_timeout,\n",
    "            \"model_error\": self.recover_model_error,\n",
    "            \"memory_error\": self.recover_memory_error\n",
    "        }\n",
    "        self.max_retries = 3\n",
    "        self.backoff_factor = 2\n",
    "    \n",
    "    def detect_error_type(self, error: Exception) -> str:\n",
    "        \"\"\"Detect error type from exception\"\"\"\n",
    "        error_str = str(error).lower()\n",
    "        \n",
    "        if \"api\" in error_str and \"key\" in error_str:\n",
    "            return \"api_key\"\n",
    "        elif \"rate limit\" in error_str:\n",
    "            return \"rate_limit\"\n",
    "        elif \"timeout\" in error_str:\n",
    "            return \"timeout\"\n",
    "        elif \"model\" in error_str:\n",
    "            return \"model_error\"\n",
    "        elif \"memory\" in error_str:\n",
    "            return \"memory_error\"\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "    \n",
    "    def recover_api_key(self, context: Dict) -> Callable:\n",
    "        \"\"\"Recover from API key errors\"\"\"\n",
    "        print(\"\ud83d\udd27 Recovering from API key error...\")\n",
    "        from dotenv import load_dotenv\n",
    "        import os\n",
    "        \n",
    "        # Try reloading environment\n",
    "        load_dotenv(override=True)\n",
    "        \n",
    "        # Try alternative API key\n",
    "        if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "            # Try fallback to free model\n",
    "            from langchain_community.llms import Ollama\n",
    "            print(\"\u2705 Falling back to local model\")\n",
    "            return lambda: Ollama(model=\"llama2\")\n",
    "        \n",
    "        from langchain_openai import ChatOpenAI\n",
    "        return lambda: ChatOpenAI()\n",
    "    \n",
    "    def recover_rate_limit(self, context: Dict) -> Callable:\n",
    "        \"\"\"Recover from rate limit errors\"\"\"\n",
    "        print(\"\ud83d\udd27 Recovering from rate limit...\")\n",
    "        wait_time = min(60 * (context.get(\"attempt\", 1)), 300)\n",
    "        print(f\"\u23f3 Waiting {wait_time}s...\")\n",
    "        time.sleep(wait_time)\n",
    "        \n",
    "        # Return original function\n",
    "        return context.get(\"original_func\")\n",
    "    \n",
    "    def recover_timeout(self, context: Dict) -> Callable:\n",
    "        \"\"\"Recover from timeout errors\"\"\"\n",
    "        print(\"\ud83d\udd27 Recovering from timeout...\")\n",
    "        \n",
    "        # Return a simpler version\n",
    "        def simple_version(*args, **kwargs):\n",
    "            # Reduce complexity\n",
    "            if \"max_tokens\" in kwargs:\n",
    "                kwargs[\"max_tokens\"] = min(kwargs[\"max_tokens\"], 100)\n",
    "            if \"temperature\" in kwargs:\n",
    "                kwargs[\"temperature\"] = 0\n",
    "            return context[\"original_func\"](*args, **kwargs)\n",
    "        \n",
    "        return simple_version\n",
    "    \n",
    "    def recover_model_error(self, context: Dict) -> Callable:\n",
    "        \"\"\"Recover from model errors\"\"\"\n",
    "        print(\"\ud83d\udd27 Recovering from model error...\")\n",
    "        \n",
    "        # Try fallback model\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        \n",
    "        def fallback_model(*args, **kwargs):\n",
    "            # Use simpler model\n",
    "            llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "            return llm.invoke(*args, **kwargs)\n",
    "        \n",
    "        return fallback_model\n",
    "    \n",
    "    def recover_memory_error(self, context: Dict) -> Callable:\n",
    "        \"\"\"Recover from memory errors\"\"\"\n",
    "        print(\"\ud83d\udd27 Recovering from memory error...\")\n",
    "        \n",
    "        # Return function with cleared memory\n",
    "        def cleared_memory(*args, **kwargs):\n",
    "            if \"memory\" in kwargs:\n",
    "                kwargs[\"memory\"].clear()\n",
    "            return context[\"original_func\"](*args, **kwargs)\n",
    "        \n",
    "        return cleared_memory\n",
    "    \n",
    "    def exponential_backoff(self, attempt: int) -> float:\n",
    "        \"\"\"Calculate exponential backoff delay\"\"\"\n",
    "        return min(self.backoff_factor ** attempt, 60)\n",
    "    \n",
    "    def execute_with_recovery(self, func: Callable, *args, **kwargs) -> Any:\n",
    "        \"\"\"Execute function with automatic error recovery\"\"\"\n",
    "        \n",
    "        attempt = 0\n",
    "        last_error = None\n",
    "        \n",
    "        while attempt < self.max_retries:\n",
    "            attempt += 1\n",
    "            \n",
    "            try:\n",
    "                print(f\"\\n\ud83d\udd04 Attempt {attempt}/{self.max_retries}\")\n",
    "                result = func(*args, **kwargs)\n",
    "                \n",
    "                if attempt > 1:\n",
    "                    print(f\"\u2705 Succeeded after recovery\")\n",
    "                    self.log_recovery(func.__name__, attempt, \"success\", None)\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                error_type = self.detect_error_type(e)\n",
    "                \n",
    "                print(f\"\u274c Error: {str(e)[:100]}\")\n",
    "                print(f\"\ud83d\udd0d Error type: {error_type}\")\n",
    "                \n",
    "                self.log_recovery(func.__name__, attempt, \"error\", error_type)\n",
    "                \n",
    "                if error_type in self.recovery_strategies:\n",
    "                    context = {\n",
    "                        \"error\": e,\n",
    "                        \"attempt\": attempt,\n",
    "                        \"original_func\": func,\n",
    "                        \"args\": args,\n",
    "                        \"kwargs\": kwargs\n",
    "                    }\n",
    "                    \n",
    "                    # Apply recovery strategy\n",
    "                    recovered_func = self.recovery_strategies[error_type](context)\n",
    "                    \n",
    "                    if recovered_func:\n",
    "                        func = recovered_func\n",
    "                        print(f\"\u2705 Recovery strategy applied\")\n",
    "                    else:\n",
    "                        print(f\"\u274c Recovery failed\")\n",
    "                \n",
    "                if attempt < self.max_retries:\n",
    "                    delay = self.exponential_backoff(attempt)\n",
    "                    print(f\"\u23f3 Waiting {delay:.1f}s before retry...\")\n",
    "                    time.sleep(delay)\n",
    "        \n",
    "        # All attempts failed\n",
    "        self.log_recovery(func.__name__, attempt, \"failed\", str(last_error))\n",
    "        \n",
    "        # Try final fallback\n",
    "        print(\"\\n\ud83d\udea8 Attempting final fallback...\")\n",
    "        return self.final_fallback(*args, **kwargs)\n",
    "    \n",
    "    def final_fallback(self, *args, **kwargs):\n",
    "        \"\"\"Final fallback when all else fails\"\"\"\n",
    "        return {\n",
    "            \"status\": \"failed\",\n",
    "            \"message\": \"All recovery attempts failed. Please check logs.\",\n",
    "            \"fallback\": True\n",
    "        }\n",
    "    \n",
    "    def log_recovery(self, function: str, attempt: int, status: str, error_type: str):\n",
    "        \"\"\"Log recovery attempts\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"function\": function,\n",
    "            \"attempt\": attempt,\n",
    "            \"status\": status,\n",
    "            \"error_type\": error_type\n",
    "        }\n",
    "        \n",
    "        self.error_log.append(log_entry)\n",
    "    \n",
    "    def export_logs(self, filename=\"recovery_log.json\"):\n",
    "        \"\"\"Export recovery logs\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(self.error_log, f, indent=2)\n",
    "        print(f\"\ud83d\udcc1 Recovery log saved to {filename}\")\n",
    "    \n",
    "    def show_statistics(self):\n",
    "        \"\"\"Show recovery statistics\"\"\"\n",
    "        if not self.error_log:\n",
    "            print(\"No recovery attempts yet\")\n",
    "            return\n",
    "        \n",
    "        total = len(self.error_log)\n",
    "        successful = sum(1 for log in self.error_log if log[\"status\"] == \"success\")\n",
    "        failed = sum(1 for log in self.error_log if log[\"status\"] == \"failed\")\n",
    "        \n",
    "        print(\"\\n\ud83d\udcca Recovery Statistics:\")\n",
    "        print(f\"  Total attempts: {total}\")\n",
    "        print(f\"  Successful recoveries: {successful}\")\n",
    "        print(f\"  Failed recoveries: {failed}\")\n",
    "        print(f\"  Success rate: {(successful/total*100):.1f}%\")\n",
    "        \n",
    "        # Error type breakdown\n",
    "        error_types = {}\n",
    "        for log in self.error_log:\n",
    "            if log[\"error_type\"]:\n",
    "                error_types[log[\"error_type\"]] = error_types.get(log[\"error_type\"], 0) + 1\n",
    "        \n",
    "        if error_types:\n",
    "            print(\"\\n  Error types:\")\n",
    "            for error_type, count in error_types.items():\n",
    "                print(f\"    {error_type}: {count}\")\n",
    "\n",
    "# Test functions\n",
    "def test_function_that_fails():\n",
    "    \"\"\"Function that might fail\"\"\"\n",
    "    import random\n",
    "    if random.random() < 0.7:  # 70% chance of failure\n",
    "        raise Exception(\"Random failure for testing\")\n",
    "    return \"Success!\"\n",
    "\n",
    "# Demo\n",
    "if __name__ == \"__main__\":\n",
    "    recovery = ErrorRecoverySystem()\n",
    "    \n",
    "    print(\"\ud83d\udee1\ufe0f Error Recovery System Demo\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test recovery\n",
    "    result = recovery.execute_with_recovery(test_function_that_fails)\n",
    "    print(f\"\\nFinal result: {result}\")\n",
    "    \n",
    "    # Show statistics\n",
    "    recovery.show_statistics()\n",
    "    \n",
    "    # Export logs\n",
    "    recovery.export_logs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "Return to **Chapter 12: Next Topic**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}