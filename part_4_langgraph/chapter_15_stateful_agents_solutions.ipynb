{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15: Building Stateful Agents - Solutions\n",
    "**From: Zero to AI Agent**\n",
    "\n",
    "**Try the exercises in the main notebook first before viewing solutions!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.1 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.1.1: Conversation Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_15_1_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Agent that counts user visits and greets accordingly.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "class VisitState(TypedDict):\n",
    "    visit_count: int\n",
    "    greeting: str\n",
    "\n",
    "def greet_user(state: VisitState) -> dict:\n",
    "    \"\"\"Generate appropriate greeting based on visit count.\"\"\"\n",
    "    count = state[\"visit_count\"] + 1\n",
    "    \n",
    "    if count == 1:\n",
    "        greeting = \"Welcome! This is your first visit.\"\n",
    "    elif count == 2:\n",
    "        greeting = \"Welcome back! Good to see you again.\"\n",
    "    else:\n",
    "        greeting = f\"Hello again! This is visit #{count}.\"\n",
    "    \n",
    "    return {\"visit_count\": count, \"greeting\": greeting}\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(VisitState)\n",
    "graph.add_node(\"greet\", greet_user)\n",
    "graph.add_edge(START, \"greet\")\n",
    "graph.add_edge(\"greet\", END)\n",
    "\n",
    "app = graph.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Simulate multiple visits\n",
    "config = {\"configurable\": {\"thread_id\": \"user-123\"}}\n",
    "\n",
    "print(\"=== Conversation Counter ===\\n\")\n",
    "for i in range(4):\n",
    "    result = app.invoke({\"visit_count\": 0, \"greeting\": \"\"}, config)\n",
    "    print(f\"Visit {i+1}: {result['greeting']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.1.2: Multi-User Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_15_1_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Multi-user agent with separate state per user.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "class UserState(TypedDict):\n",
    "    user_name: str\n",
    "    visit_count: int\n",
    "\n",
    "def track_visit(state: UserState) -> dict:\n",
    "    return {\"visit_count\": state[\"visit_count\"] + 1}\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(UserState)\n",
    "graph.add_node(\"track\", track_visit)\n",
    "graph.add_edge(START, \"track\")\n",
    "graph.add_edge(\"track\", END)\n",
    "\n",
    "app = graph.compile(checkpointer=MemorySaver())\n",
    "\n",
    "def visit(user_name: str) -> int:\n",
    "    \"\"\"Simulate a user visit, return their visit count.\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": f\"user-{user_name}\"}}\n",
    "    result = app.invoke({\"user_name\": user_name, \"visit_count\": 0}, config)\n",
    "    return result[\"visit_count\"]\n",
    "\n",
    "# Simulate visits from different users\n",
    "print(\"=== Multi-User Tracker ===\\n\")\n",
    "\n",
    "# Alice visits 3 times\n",
    "for i in range(3):\n",
    "    count = visit(\"alice\")\n",
    "    print(f\"Alice visit: count = {count}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Bob visits 2 times\n",
    "for i in range(2):\n",
    "    count = visit(\"bob\")\n",
    "    print(f\"Bob visit: count = {count}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Alice visits again - should continue from 3\n",
    "count = visit(\"alice\")\n",
    "print(f\"Alice visit: count = {count} (continued from before!)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.1.3: State History Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_15_1_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Explore state history through a multi-node workflow.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "class WorkflowState(TypedDict):\n",
    "    steps_completed: Annotated[list[str], add]\n",
    "    current_value: int\n",
    "\n",
    "def step_one(state: WorkflowState) -> dict:\n",
    "    return {\n",
    "        \"steps_completed\": [\"step_one\"],\n",
    "        \"current_value\": 10\n",
    "    }\n",
    "\n",
    "def step_two(state: WorkflowState) -> dict:\n",
    "    return {\n",
    "        \"steps_completed\": [\"step_two\"],\n",
    "        \"current_value\": state[\"current_value\"] * 2\n",
    "    }\n",
    "\n",
    "def step_three(state: WorkflowState) -> dict:\n",
    "    return {\n",
    "        \"steps_completed\": [\"step_three\"],\n",
    "        \"current_value\": state[\"current_value\"] + 5\n",
    "    }\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(WorkflowState)\n",
    "graph.add_node(\"one\", step_one)\n",
    "graph.add_node(\"two\", step_two)\n",
    "graph.add_node(\"three\", step_three)\n",
    "graph.add_edge(START, \"one\")\n",
    "graph.add_edge(\"one\", \"two\")\n",
    "graph.add_edge(\"two\", \"three\")\n",
    "graph.add_edge(\"three\", END)\n",
    "\n",
    "app = graph.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Run the workflow\n",
    "config = {\"configurable\": {\"thread_id\": \"workflow-1\"}}\n",
    "result = app.invoke({\"steps_completed\": [], \"current_value\": 0}, config)\n",
    "\n",
    "# Explore the history\n",
    "print(\"=== State History Explorer ===\\n\")\n",
    "print(\"Final result:\", result)\n",
    "print(\"\\n--- History (newest first) ---\\n\")\n",
    "\n",
    "for i, snapshot in enumerate(app.get_state_history(config)):\n",
    "    print(f\"Snapshot {i}:\")\n",
    "    print(f\"  Steps: {snapshot.values.get('steps_completed', [])}\")\n",
    "    print(f\"  Value: {snapshot.values.get('current_value', 'N/A')}\")\n",
    "    print(f\"  Next: {snapshot.next}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.2 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.2.1: Validated User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_15_2_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Validated user profile with Pydantic.\n",
    "\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import Optional\n",
    "from enum import Enum\n",
    "import re\n",
    "\n",
    "class MembershipLevel(str, Enum):\n",
    "    FREE = \"free\"\n",
    "    BASIC = \"basic\"\n",
    "    PREMIUM = \"premium\"\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "    username: str = Field(min_length=3, max_length=20)\n",
    "    email: str\n",
    "    age: Optional[int] = Field(default=None, ge=13, le=120)\n",
    "    membership: MembershipLevel = MembershipLevel.FREE\n",
    "    \n",
    "    @field_validator('username')\n",
    "    @classmethod\n",
    "    def username_alphanumeric(cls, v):\n",
    "        if not re.match(r'^[a-zA-Z0-9]+$', v):\n",
    "            raise ValueError('Username must be alphanumeric')\n",
    "        return v.lower()\n",
    "    \n",
    "    @field_validator('email')\n",
    "    @classmethod\n",
    "    def email_valid(cls, v):\n",
    "        if not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,}$', v):\n",
    "            raise ValueError('Invalid email format')\n",
    "        return v.lower()\n",
    "\n",
    "# Test valid profiles\n",
    "print(\"=== Valid Profiles ===\")\n",
    "valid = UserProfile(username=\"Alice123\", email=\"alice@test.com\", age=25)\n",
    "print(f\"âœ“ {valid.username}, {valid.email}, {valid.membership.value}\")\n",
    "\n",
    "minimal = UserProfile(username=\"bob\", email=\"bob@test.com\")\n",
    "print(f\"âœ“ {minimal.username}, age={minimal.age}\")\n",
    "\n",
    "# Test invalid profiles\n",
    "print(\"\\n=== Invalid Profiles ===\")\n",
    "test_cases = [\n",
    "    ({\"username\": \"ab\", \"email\": \"a@b.com\"}, \"too short\"),\n",
    "    ({\"username\": \"test_user\", \"email\": \"a@b.com\"}, \"underscore\"),\n",
    "    ({\"username\": \"test\", \"email\": \"notanemail\"}, \"bad email\"),\n",
    "    ({\"username\": \"test\", \"email\": \"a@b.com\", \"age\": 10}, \"too young\"),\n",
    "]\n",
    "\n",
    "for data, reason in test_cases:\n",
    "    try:\n",
    "        UserProfile(**data)\n",
    "        print(f\"âœ— Should have failed: {reason}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ“ Caught ({reason})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.2.2: Chat Message Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_15_2_solution.py\n",
    "\n",
    "\"\"\"\n",
    "LangGraph node with Pydantic message validation.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Pydantic model for validation\n",
    "class Message(BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "    \n",
    "    @field_validator('role')\n",
    "    @classmethod\n",
    "    def valid_role(cls, v):\n",
    "        if v not in ('user', 'assistant'):\n",
    "            raise ValueError('Role must be \"user\" or \"assistant\"')\n",
    "        return v\n",
    "    \n",
    "    @field_validator('content')\n",
    "    @classmethod\n",
    "    def content_not_empty(cls, v):\n",
    "        if not v or not v.strip():\n",
    "            raise ValueError('Content cannot be empty')\n",
    "        return v.strip()\n",
    "\n",
    "# TypedDict for LangGraph\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[dict], add]\n",
    "    last_error: str\n",
    "\n",
    "def validate_and_add_message(state: ChatState) -> dict:\n",
    "    \"\"\"Validate incoming message and add to state.\"\"\"\n",
    "    # Simulate incoming raw message\n",
    "    raw_message = {\"role\": \"user\", \"content\": \"  Hello there!  \"}\n",
    "    \n",
    "    try:\n",
    "        validated = Message(**raw_message)\n",
    "        return {\n",
    "            \"messages\": [validated.model_dump()],\n",
    "            \"last_error\": \"\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"last_error\": str(e)\n",
    "        }\n",
    "\n",
    "# Build and test\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"validate\", validate_and_add_message)\n",
    "graph.add_edge(START, \"validate\")\n",
    "graph.add_edge(\"validate\", END)\n",
    "app = graph.compile()\n",
    "\n",
    "result = app.invoke({\"messages\": [], \"last_error\": \"\"})\n",
    "print(\"=== Message Validation ===\")\n",
    "print(f\"Messages: {result['messages']}\")\n",
    "print(f\"Notice: content was trimmed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.2.3: Order State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_15_2_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Order processing state with comprehensive validation.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from enum import Enum\n",
    "\n",
    "class OrderStatus(str, Enum):\n",
    "    PENDING = \"pending\"\n",
    "    PROCESSING = \"processing\"\n",
    "    SHIPPED = \"shipped\"\n",
    "    DELIVERED = \"delivered\"\n",
    "    CANCELLED = \"cancelled\"\n",
    "\n",
    "class OrderItem(BaseModel):\n",
    "    name: str = Field(min_length=1)\n",
    "    quantity: int = Field(gt=0)\n",
    "    price: float = Field(gt=0)\n",
    "    \n",
    "    @property\n",
    "    def subtotal(self) -> float:\n",
    "        return self.quantity * self.price\n",
    "\n",
    "class Order(BaseModel):\n",
    "    order_id: str\n",
    "    items: list[OrderItem] = Field(min_length=1)\n",
    "    total: float = Field(gt=0)\n",
    "    status: OrderStatus = OrderStatus.PENDING\n",
    "    \n",
    "    @model_validator(mode='after')\n",
    "    def validate_total(self):\n",
    "        calculated = sum(item.subtotal for item in self.items)\n",
    "        if abs(self.total - calculated) > 0.01:\n",
    "            raise ValueError(f'Total {self.total} != calculated {calculated}')\n",
    "        return self\n",
    "\n",
    "# TypedDict for LangGraph\n",
    "class OrderState(TypedDict):\n",
    "    order: dict\n",
    "    status_history: list[str]\n",
    "\n",
    "# Test\n",
    "print(\"=== Order Validation ===\\n\")\n",
    "\n",
    "# Valid order\n",
    "valid = Order(\n",
    "    order_id=\"ORD-001\",\n",
    "    items=[\n",
    "        {\"name\": \"Widget\", \"quantity\": 2, \"price\": 10.00},\n",
    "        {\"name\": \"Gadget\", \"quantity\": 1, \"price\": 25.00}\n",
    "    ],\n",
    "    total=45.00  # 2*10 + 1*25 = 45 âœ“\n",
    ")\n",
    "print(f\"âœ“ Valid order: {valid.order_id}, ${valid.total}\")\n",
    "\n",
    "# Invalid: wrong total\n",
    "try:\n",
    "    Order(\n",
    "        order_id=\"ORD-002\",\n",
    "        items=[{\"name\": \"Item\", \"quantity\": 2, \"price\": 10.00}],\n",
    "        total=100.00  # Should be 20!\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"âœ“ Caught bad total: {e}\")\n",
    "\n",
    "# Invalid: zero quantity\n",
    "try:\n",
    "    Order(\n",
    "        order_id=\"ORD-003\",\n",
    "        items=[{\"name\": \"Item\", \"quantity\": 0, \"price\": 10.00}],\n",
    "        total=0\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"âœ“ Caught zero quantity\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.3 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.3.1: Deduplicating Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_15_3_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Custom reducer that accumulates but removes duplicates.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def dedupe_messages(existing: list, new: list) -> list:\n",
    "    \"\"\"Accumulate messages, removing duplicates by content.\"\"\"\n",
    "    result = existing.copy()\n",
    "    seen = {msg[\"content\"] for msg in existing}\n",
    "    \n",
    "    for msg in new:\n",
    "        if msg[\"content\"] not in seen:\n",
    "            result.append(msg)\n",
    "            seen.add(msg[\"content\"])\n",
    "    \n",
    "    return result\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[dict], dedupe_messages]\n",
    "\n",
    "def greeting(state):\n",
    "    return {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Welcome!\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"How can I help?\"}\n",
    "    ]}\n",
    "\n",
    "def help_prompt(state):\n",
    "    return {\"messages\": [\n",
    "        {\"role\": \"assistant\", \"content\": \"How can I help?\"},  # Duplicate!\n",
    "        {\"role\": \"assistant\", \"content\": \"I'm here to assist.\"}\n",
    "    ]}\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"greet\", greeting)\n",
    "graph.add_node(\"help\", help_prompt)\n",
    "graph.add_edge(START, \"greet\")\n",
    "graph.add_edge(\"greet\", \"help\")\n",
    "graph.add_edge(\"help\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "result = app.invoke({\"messages\": []})\n",
    "\n",
    "print(\"=== Dedupe Reducer ===\")\n",
    "print(f\"Total messages: {len(result['messages'])}\")\n",
    "for msg in result['messages']:\n",
    "    print(f\"  - {msg['content']}\")\n",
    "print(\"\\n'How can I help?' appears only once!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.3.2: Priority Queue Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_15_3_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Reducer that maintains a priority-sorted task queue.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def priority_queue(existing: list, new: list) -> list:\n",
    "    \"\"\"Merge tasks, keeping highest priority first.\"\"\"\n",
    "    combined = existing + new\n",
    "    return sorted(combined, key=lambda x: x[\"priority\"], reverse=True)\n",
    "\n",
    "class TaskState(TypedDict):\n",
    "    tasks: Annotated[list[dict], priority_queue]\n",
    "\n",
    "def add_normal_tasks(state):\n",
    "    return {\"tasks\": [\n",
    "        {\"task\": \"Write docs\", \"priority\": 5},\n",
    "        {\"task\": \"Code review\", \"priority\": 6}\n",
    "    ]}\n",
    "\n",
    "def add_urgent_task(state):\n",
    "    return {\"tasks\": [\n",
    "        {\"task\": \"Fix critical bug\", \"priority\": 10}\n",
    "    ]}\n",
    "\n",
    "def add_low_priority(state):\n",
    "    return {\"tasks\": [\n",
    "        {\"task\": \"Update readme\", \"priority\": 2}\n",
    "    ]}\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(TaskState)\n",
    "graph.add_node(\"normal\", add_normal_tasks)\n",
    "graph.add_node(\"urgent\", add_urgent_task)\n",
    "graph.add_node(\"low\", add_low_priority)\n",
    "graph.add_edge(START, \"normal\")\n",
    "graph.add_edge(\"normal\", \"urgent\")\n",
    "graph.add_edge(\"urgent\", \"low\")\n",
    "graph.add_edge(\"low\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "result = app.invoke({\"tasks\": []})\n",
    "\n",
    "print(\"=== Priority Queue ===\")\n",
    "for task in result['tasks']:\n",
    "    print(f\"  [{task['priority']:2d}] {task['task']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.3.3: Change Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_15_3_solution.py\n",
    "\n",
    "\"\"\"\n",
    "State that tracks all changes in a changelog.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from datetime import datetime\n",
    "\n",
    "class TrackedState(TypedDict):\n",
    "    # Regular fields\n",
    "    counter: int\n",
    "    status: str\n",
    "    # Changelog accumulates\n",
    "    changelog: Annotated[list[dict], add]\n",
    "\n",
    "def make_change_entry(node_name: str, changes: dict) -> dict:\n",
    "    \"\"\"Create a changelog entry.\"\"\"\n",
    "    return {\n",
    "        \"node\": node_name,\n",
    "        \"time\": datetime.now().strftime(\"%H:%M:%S\"),\n",
    "        \"changes\": changes\n",
    "    }\n",
    "\n",
    "def initialize(state):\n",
    "    changes = {\"counter\": \"0 â†’ 1\", \"status\": \"â†’ initialized\"}\n",
    "    return {\n",
    "        \"counter\": 1,\n",
    "        \"status\": \"initialized\",\n",
    "        \"changelog\": [make_change_entry(\"initialize\", changes)]\n",
    "    }\n",
    "\n",
    "def process(state):\n",
    "    new_counter = state[\"counter\"] + 10\n",
    "    changes = {\"counter\": f\"{state['counter']} â†’ {new_counter}\"}\n",
    "    return {\n",
    "        \"counter\": new_counter,\n",
    "        \"changelog\": [make_change_entry(\"process\", changes)]\n",
    "    }\n",
    "\n",
    "def finalize(state):\n",
    "    changes = {\"status\": f\"{state['status']} â†’ complete\"}\n",
    "    return {\n",
    "        \"status\": \"complete\",\n",
    "        \"changelog\": [make_change_entry(\"finalize\", changes)]\n",
    "    }\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(TrackedState)\n",
    "graph.add_node(\"init\", initialize)\n",
    "graph.add_node(\"proc\", process)\n",
    "graph.add_node(\"final\", finalize)\n",
    "graph.add_edge(START, \"init\")\n",
    "graph.add_edge(\"init\", \"proc\")\n",
    "graph.add_edge(\"proc\", \"final\")\n",
    "graph.add_edge(\"final\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "result = app.invoke({\"counter\": 0, \"status\": \"\", \"changelog\": []})\n",
    "\n",
    "print(\"=== Change Tracker ===\")\n",
    "print(f\"\\nFinal state: counter={result['counter']}, status={result['status']}\")\n",
    "print(\"\\nChangelog:\")\n",
    "for entry in result['changelog']:\n",
    "    print(f\"  [{entry['time']}] {entry['node']}: {entry['changes']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.4 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.4.1: Multi-User Chat System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_15_4_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Multi-user chat system with SQLite persistence.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[dict], add]\n",
    "    user_id: str\n",
    "    last_activity: str\n",
    "\n",
    "def update_activity(state: ChatState) -> dict:\n",
    "    return {\"last_activity\": datetime.now().isoformat()}\n",
    "\n",
    "# Build minimal graph\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"update\", update_activity)\n",
    "graph.add_edge(START, \"update\")\n",
    "graph.add_edge(\"update\", END)\n",
    "\n",
    "DB_PATH = \"multiuser_chat.db\"\n",
    "\n",
    "def send_message(user_id: str, content: str, role: str = \"user\"):\n",
    "    \"\"\"Send a message in a user's chat.\"\"\"\n",
    "    with SqliteSaver.from_conn_string(DB_PATH) as saver:\n",
    "        app = graph.compile(checkpointer=saver)\n",
    "        thread_id = f\"chat:{user_id}\"\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        # Load or create state\n",
    "        try:\n",
    "            current = app.get_state(config).values or {}\n",
    "        except:\n",
    "            current = {}\n",
    "        \n",
    "        state = {\n",
    "            \"messages\": current.get(\"messages\", []) + [{\"role\": role, \"content\": content}],\n",
    "            \"user_id\": user_id,\n",
    "            \"last_activity\": \"\"\n",
    "        }\n",
    "        \n",
    "        return app.invoke(state, config)\n",
    "\n",
    "def list_user_conversations(user_id: str):\n",
    "    \"\"\"List all conversations for a user.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Find threads for this user\n",
    "    cursor.execute(\n",
    "        \"SELECT DISTINCT thread_id FROM checkpoints WHERE thread_id LIKE ?\",\n",
    "        (f\"chat:{user_id}%\",)\n",
    "    )\n",
    "    \n",
    "    conversations = []\n",
    "    with SqliteSaver.from_conn_string(DB_PATH) as saver:\n",
    "        app = graph.compile(checkpointer=saver)\n",
    "        \n",
    "        for (thread_id,) in cursor.fetchall():\n",
    "            config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "            state = app.get_state(config)\n",
    "            \n",
    "            if state.values:\n",
    "                conversations.append({\n",
    "                    \"thread_id\": thread_id,\n",
    "                    \"message_count\": len(state.values.get(\"messages\", [])),\n",
    "                    \"last_activity\": state.values.get(\"last_activity\", \"Unknown\")\n",
    "                })\n",
    "    \n",
    "    conn.close()\n",
    "    return conversations\n",
    "\n",
    "# Demo\n",
    "print(\"=== Multi-User Chat ===\\n\")\n",
    "\n",
    "# Alice sends messages\n",
    "send_message(\"alice\", \"Hello!\")\n",
    "send_message(\"alice\", \"How are you?\")\n",
    "send_message(\"alice\", \"Great, thanks!\", \"assistant\")\n",
    "\n",
    "# Bob sends messages\n",
    "send_message(\"bob\", \"Hi there\")\n",
    "\n",
    "# List Alice's conversations\n",
    "print(\"Alice's conversations:\")\n",
    "for conv in list_user_conversations(\"alice\"):\n",
    "    print(f\"  {conv['thread_id']}: {conv['message_count']} messages\")\n",
    "\n",
    "print(\"\\nBob's conversations:\")\n",
    "for conv in list_user_conversations(\"bob\"):\n",
    "    print(f\"  {conv['thread_id']}: {conv['message_count']} messages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.4.2: Checkpoint Cleanup Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_15_4_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Checkpoint cleanup and maintenance utility.\n",
    "\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import os\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "\n",
    "class DemoState(TypedDict):\n",
    "    counter: int\n",
    "\n",
    "def increment(state: DemoState) -> dict:\n",
    "    return {\"counter\": state[\"counter\"] + 1}\n",
    "\n",
    "# Build graph for creating test data\n",
    "graph = StateGraph(DemoState)\n",
    "graph.add_node(\"inc\", increment)\n",
    "graph.add_edge(START, \"inc\")\n",
    "graph.add_edge(\"inc\", END)\n",
    "\n",
    "DB_PATH = \"cleanup_demo.db\"\n",
    "\n",
    "def get_stats(db_path: str) -> dict:\n",
    "    \"\"\"Get checkpoint statistics.\"\"\"\n",
    "    if not os.path.exists(db_path):\n",
    "        return {\"total\": 0, \"threads\": 0, \"size_bytes\": 0}\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"SELECT COUNT(*) FROM checkpoints\")\n",
    "    total = cursor.fetchone()[0]\n",
    "    \n",
    "    cursor.execute(\"SELECT COUNT(DISTINCT thread_id) FROM checkpoints\")\n",
    "    threads = cursor.fetchone()[0]\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"threads\": threads,\n",
    "        \"size_bytes\": os.path.getsize(db_path)\n",
    "    }\n",
    "\n",
    "def cleanup(db_path: str, keep_per_thread: int = 3) -> int:\n",
    "    \"\"\"Remove old checkpoints, keeping N most recent per thread.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"SELECT DISTINCT thread_id FROM checkpoints\")\n",
    "    threads = [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "    deleted = 0\n",
    "    for thread_id in threads:\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT checkpoint_id FROM checkpoints \n",
    "            WHERE thread_id = ? ORDER BY checkpoint_id DESC\n",
    "        \"\"\", (thread_id,))\n",
    "        \n",
    "        checkpoints = [row[0] for row in cursor.fetchall()]\n",
    "        \n",
    "        for cp_id in checkpoints[keep_per_thread:]:\n",
    "            cursor.execute(\"DELETE FROM checkpoints WHERE checkpoint_id = ?\", (cp_id,))\n",
    "            deleted += 1\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.execute(\"VACUUM\")  # Reclaim space\n",
    "    conn.close()\n",
    "    \n",
    "    return deleted\n",
    "\n",
    "# Create test data\n",
    "print(\"=== Checkpoint Cleanup Utility ===\\n\")\n",
    "print(\"Creating test data...\")\n",
    "\n",
    "with SqliteSaver.from_conn_string(DB_PATH) as saver:\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    \n",
    "    for thread_num in range(3):\n",
    "        config = {\"configurable\": {\"thread_id\": f\"thread-{thread_num}\"}}\n",
    "        state = {\"counter\": 0}\n",
    "        for _ in range(10):\n",
    "            state = app.invoke(state, config)\n",
    "\n",
    "# Show before stats\n",
    "print(\"\\n--- Before Cleanup ---\")\n",
    "before = get_stats(DB_PATH)\n",
    "print(f\"Checkpoints: {before['total']}\")\n",
    "print(f\"Threads: {before['threads']}\")\n",
    "print(f\"Size: {before['size_bytes']:,} bytes\")\n",
    "\n",
    "# Run cleanup\n",
    "deleted = cleanup(DB_PATH, keep_per_thread=2)\n",
    "print(f\"\\n--- Cleanup ---\")\n",
    "print(f\"Deleted: {deleted} checkpoints\")\n",
    "\n",
    "# Show after stats\n",
    "print(\"\\n--- After Cleanup ---\")\n",
    "after = get_stats(DB_PATH)\n",
    "print(f\"Checkpoints: {after['total']}\")\n",
    "print(f\"Size: {after['size_bytes']:,} bytes\")\n",
    "print(f\"Space saved: {before['size_bytes'] - after['size_bytes']:,} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.4.3: Conversation Export Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_15_4_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Conversation export/import and forking utility.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class ConvoState(TypedDict):\n",
    "    messages: Annotated[list[dict], add]\n",
    "    metadata: dict\n",
    "\n",
    "def process(state: ConvoState) -> dict:\n",
    "    return {\"metadata\": {**state.get(\"metadata\", {}), \"updated\": datetime.now().isoformat()}}\n",
    "\n",
    "graph = StateGraph(ConvoState)\n",
    "graph.add_node(\"process\", process)\n",
    "graph.add_edge(START, \"process\")\n",
    "graph.add_edge(\"process\", END)\n",
    "\n",
    "DB_PATH = \"export_demo.db\"\n",
    "\n",
    "def export_conversation(thread_id: str, output_file: str):\n",
    "    \"\"\"Export conversation to JSON file.\"\"\"\n",
    "    with SqliteSaver.from_conn_string(DB_PATH) as saver:\n",
    "        app = graph.compile(checkpointer=saver)\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        state = app.get_state(config)\n",
    "        if not state.values:\n",
    "            raise ValueError(f\"Thread not found: {thread_id}\")\n",
    "        \n",
    "        export_data = {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"exported_at\": datetime.now().isoformat(),\n",
    "            \"state\": state.values\n",
    "        }\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(export_data, f, indent=2, default=str)\n",
    "        \n",
    "        return export_data\n",
    "\n",
    "def import_conversation(input_file: str, new_thread_id: str):\n",
    "    \"\"\"Import conversation from JSON file.\"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    state = data[\"state\"]\n",
    "    state[\"metadata\"] = {\n",
    "        **state.get(\"metadata\", {}),\n",
    "        \"imported_from\": data[\"thread_id\"],\n",
    "        \"imported_at\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with SqliteSaver.from_conn_string(DB_PATH) as saver:\n",
    "        app = graph.compile(checkpointer=saver)\n",
    "        config = {\"configurable\": {\"thread_id\": new_thread_id}}\n",
    "        return app.invoke(state, config)\n",
    "\n",
    "def fork_conversation(source_thread: str, new_thread: str):\n",
    "    \"\"\"Create a copy of a conversation in a new thread.\"\"\"\n",
    "    with SqliteSaver.from_conn_string(DB_PATH) as saver:\n",
    "        app = graph.compile(checkpointer=saver)\n",
    "        \n",
    "        # Load source\n",
    "        source_config = {\"configurable\": {\"thread_id\": source_thread}}\n",
    "        source_state = app.get_state(source_config).values\n",
    "        \n",
    "        # Add fork metadata\n",
    "        source_state[\"metadata\"] = {\n",
    "            **source_state.get(\"metadata\", {}),\n",
    "            \"forked_from\": source_thread,\n",
    "            \"forked_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Save to new thread\n",
    "        new_config = {\"configurable\": {\"thread_id\": new_thread}}\n",
    "        return app.invoke(source_state, new_config)\n",
    "\n",
    "# Demo\n",
    "print(\"=== Export/Import Tool ===\\n\")\n",
    "\n",
    "# Create a conversation\n",
    "with SqliteSaver.from_conn_string(DB_PATH) as saver:\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    config = {\"configurable\": {\"thread_id\": \"original\"}}\n",
    "    \n",
    "    state = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}],\n",
    "        \"metadata\": {\"topic\": \"greeting\"}\n",
    "    }\n",
    "    app.invoke(state, config)\n",
    "    print(\"Created original conversation\")\n",
    "\n",
    "# Export\n",
    "export_conversation(\"original\", \"backup.json\")\n",
    "print(\"Exported to backup.json\")\n",
    "\n",
    "# Import to new thread\n",
    "import_conversation(\"backup.json\", \"imported\")\n",
    "print(\"Imported to 'imported' thread\")\n",
    "\n",
    "# Fork\n",
    "fork_conversation(\"original\", \"forked\")\n",
    "print(\"Forked to 'forked' thread\")\n",
    "\n",
    "# Verify all exist\n",
    "print(\"\\n--- All Threads ---\")\n",
    "with SqliteSaver.from_conn_string(DB_PATH) as saver:\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    \n",
    "    for thread in [\"original\", \"imported\", \"forked\"]:\n",
    "        config = {\"configurable\": {\"thread_id\": thread}}\n",
    "        state = app.get_state(config)\n",
    "        print(f\"  {thread}: {len(state.values.get('messages', []))} messages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.5 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.5.1: Smart Retry Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_15_5_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Smart retry decorator with configurable policy and metadata.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from functools import wraps\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class RetryPolicy:\n",
    "    \"\"\"Configurable retry behavior.\"\"\"\n",
    "    max_attempts: int = 3\n",
    "    base_delay: float = 1.0\n",
    "    max_delay: float = 60.0\n",
    "    retryable_exceptions: tuple = (ConnectionError, TimeoutError)\n",
    "\n",
    "@dataclass \n",
    "class RetryResult:\n",
    "    \"\"\"Metadata about retry attempts.\"\"\"\n",
    "    success: bool\n",
    "    value: any = None\n",
    "    attempts: int = 0\n",
    "    errors: list = field(default_factory=list)\n",
    "    total_wait_time: float = 0.0\n",
    "\n",
    "def smart_retry(policy: RetryPolicy = None):\n",
    "    \"\"\"\n",
    "    Decorator with configurable policy and metadata return.\n",
    "    \n",
    "    Returns RetryResult with both the value and retry metadata.\n",
    "    \"\"\"\n",
    "    if policy is None:\n",
    "        policy = RetryPolicy()\n",
    "    \n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs) -> RetryResult:\n",
    "            result = RetryResult(success=False)\n",
    "            \n",
    "            for attempt in range(policy.max_attempts):\n",
    "                result.attempts = attempt + 1\n",
    "                timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "                \n",
    "                try:\n",
    "                    value = func(*args, **kwargs)\n",
    "                    result.success = True\n",
    "                    result.value = value\n",
    "                    print(f\"  [{timestamp}] Attempt {attempt + 1}: Success âœ“\")\n",
    "                    return result\n",
    "                    \n",
    "                except policy.retryable_exceptions as e:\n",
    "                    result.errors.append({\"attempt\": attempt + 1, \"error\": str(e)})\n",
    "                    print(f\"  [{timestamp}] Attempt {attempt + 1}: {e}\")\n",
    "                    \n",
    "                    if attempt < policy.max_attempts - 1:\n",
    "                        delay = min(policy.base_delay * (2 ** attempt), policy.max_delay)\n",
    "                        delay += random.uniform(0, delay * 0.1)\n",
    "                        result.total_wait_time += delay\n",
    "                        print(f\"  [{timestamp}] Waiting {delay:.1f}s before retry...\")\n",
    "                        time.sleep(delay)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    # Non-retryable exception - fail immediately\n",
    "                    result.errors.append({\"attempt\": attempt + 1, \"error\": str(e), \"retryable\": False})\n",
    "                    print(f\"  [{timestamp}] Non-retryable error: {e}\")\n",
    "                    return result\n",
    "            \n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# Demo\n",
    "def flaky_operation():\n",
    "    \"\"\"Fails 70% of the time.\"\"\"\n",
    "    if random.random() < 0.7:\n",
    "        raise ConnectionError(\"Service unavailable\")\n",
    "    return \"Success!\"\n",
    "\n",
    "# Apply smart retry\n",
    "aggressive_policy = RetryPolicy(max_attempts=5, base_delay=0.5)\n",
    "\n",
    "@smart_retry(policy=aggressive_policy)\n",
    "def reliable_operation():\n",
    "    return flaky_operation()\n",
    "\n",
    "print(\"=== Smart Retry Demo ===\\n\")\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    result = reliable_operation()\n",
    "    print(f\"  Result: {'âœ“' if result.success else 'âœ—'}\")\n",
    "    print(f\"  Attempts: {result.attempts}, Wait time: {result.total_wait_time:.1f}s\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.5.2: Circuit Breaker Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_15_5_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Circuit breaker pattern to prevent cascading failures.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import random\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"\n",
    "    Circuit breaker with three states:\n",
    "    - CLOSED: Normal operation, calls go through\n",
    "    - OPEN: Failing, calls blocked immediately  \n",
    "    - HALF_OPEN: Testing if service recovered\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold: int = 3, reset_timeout: float = 10.0):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.reset_timeout = reset_timeout\n",
    "        self.failures = 0\n",
    "        self.state = \"CLOSED\"\n",
    "        self.opened_at = None\n",
    "    \n",
    "    def can_execute(self) -> bool:\n",
    "        \"\"\"Check if we should attempt the call.\"\"\"\n",
    "        if self.state == \"CLOSED\":\n",
    "            return True\n",
    "            \n",
    "        if self.state == \"OPEN\":\n",
    "            # Check if cooldown period has passed\n",
    "            if datetime.now() - self.opened_at > timedelta(seconds=self.reset_timeout):\n",
    "                self.state = \"HALF_OPEN\"\n",
    "                print(f\"  ðŸ”„ Circuit HALF_OPEN: Testing service...\")\n",
    "                return True\n",
    "            return False\n",
    "            \n",
    "        # HALF_OPEN: allow one test call\n",
    "        return True\n",
    "    \n",
    "    def record_success(self):\n",
    "        \"\"\"Record a successful call.\"\"\"\n",
    "        self.failures = 0\n",
    "        if self.state == \"HALF_OPEN\":\n",
    "            print(f\"  âœ… Circuit CLOSED: Service recovered!\")\n",
    "        self.state = \"CLOSED\"\n",
    "    \n",
    "    def record_failure(self):\n",
    "        \"\"\"Record a failed call.\"\"\"\n",
    "        self.failures += 1\n",
    "        \n",
    "        if self.state == \"HALF_OPEN\":\n",
    "            # Failed during test - reopen\n",
    "            self.state = \"OPEN\"\n",
    "            self.opened_at = datetime.now()\n",
    "            print(f\"  ðŸ”´ Circuit OPEN: Test failed, blocking calls\")\n",
    "            \n",
    "        elif self.failures >= self.failure_threshold:\n",
    "            self.state = \"OPEN\"\n",
    "            self.opened_at = datetime.now()\n",
    "            print(f\"  ðŸ”´ Circuit OPEN: {self.failures} failures, blocking calls\")\n",
    "\n",
    "# Global circuit breaker (in real app, would be per-service)\n",
    "breaker = CircuitBreaker(failure_threshold=3, reset_timeout=5.0)\n",
    "\n",
    "class BreakerState(TypedDict):\n",
    "    requests: int\n",
    "    successes: int\n",
    "    blocked: int\n",
    "    log: Annotated[list[str], add]\n",
    "\n",
    "def call_with_breaker(state: BreakerState) -> dict:\n",
    "    \"\"\"Node that uses circuit breaker.\"\"\"\n",
    "    if not breaker.can_execute():\n",
    "        return {\n",
    "            \"blocked\": state[\"blocked\"] + 1,\n",
    "            \"log\": [f\"Request {state['requests'] + 1}: BLOCKED (circuit open)\"]\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        # Simulate flaky service (80% failure rate)\n",
    "        if random.random() < 0.8:\n",
    "            raise ConnectionError(\"Service failed\")\n",
    "        \n",
    "        breaker.record_success()\n",
    "        return {\n",
    "            \"requests\": state[\"requests\"] + 1,\n",
    "            \"successes\": state[\"successes\"] + 1,\n",
    "            \"log\": [f\"Request {state['requests'] + 1}: SUCCESS\"]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        breaker.record_failure()\n",
    "        return {\n",
    "            \"requests\": state[\"requests\"] + 1,\n",
    "            \"log\": [f\"Request {state['requests'] + 1}: FAILED - {e}\"]\n",
    "        }\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(BreakerState)\n",
    "graph.add_node(\"call\", call_with_breaker)\n",
    "graph.add_edge(START, \"call\")\n",
    "graph.add_edge(\"call\", END)\n",
    "app = graph.compile()\n",
    "\n",
    "# Demo: Make many requests to see circuit breaker in action\n",
    "print(\"=== Circuit Breaker Demo ===\\n\")\n",
    "\n",
    "state = {\"requests\": 0, \"successes\": 0, \"blocked\": 0, \"log\": []}\n",
    "\n",
    "for i in range(15):\n",
    "    state = app.invoke(state)\n",
    "    print(state[\"log\"][-1])\n",
    "    \n",
    "    if i == 9:  # Pause to let circuit reset\n",
    "        print(\"\\n  â³ Waiting for circuit reset...\\n\")\n",
    "        time.sleep(6)\n",
    "\n",
    "print(f\"\\nðŸ“Š Summary:\")\n",
    "print(f\"  Total requests: {state['requests']}\")\n",
    "print(f\"  Successful: {state['successes']}\")\n",
    "print(f\"  Blocked: {state['blocked']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.5.3: Retry Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_15_5_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Simple retry monitoring dashboard.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class RetryStats:\n",
    "    \"\"\"Statistics for a single node.\"\"\"\n",
    "    total_calls: int = 0\n",
    "    successful_calls: int = 0\n",
    "    total_retries: int = 0\n",
    "    \n",
    "    @property\n",
    "    def failure_rate(self) -> float:\n",
    "        if self.total_calls == 0:\n",
    "            return 0.0\n",
    "        return 1 - (self.successful_calls / self.total_calls)\n",
    "    \n",
    "    @property\n",
    "    def avg_retries_per_success(self) -> float:\n",
    "        if self.successful_calls == 0:\n",
    "            return 0.0\n",
    "        return self.total_retries / self.successful_calls\n",
    "\n",
    "class RetryDashboard:\n",
    "    \"\"\"Central monitoring for retry behavior.\"\"\"\n",
    "    \n",
    "    def __init__(self, alert_threshold: float = 0.5):\n",
    "        self.stats: dict[str, RetryStats] = {}\n",
    "        self.alert_threshold = alert_threshold\n",
    "    \n",
    "    def record(self, node_name: str, success: bool, retries: int):\n",
    "        \"\"\"Record an operation result.\"\"\"\n",
    "        if node_name not in self.stats:\n",
    "            self.stats[node_name] = RetryStats()\n",
    "        \n",
    "        stats = self.stats[node_name]\n",
    "        stats.total_calls += 1\n",
    "        stats.total_retries += retries\n",
    "        if success:\n",
    "            stats.successful_calls += 1\n",
    "        \n",
    "        # Check for alert condition\n",
    "        if stats.failure_rate > self.alert_threshold and stats.total_calls >= 5:\n",
    "            print(f\"  âš ï¸ ALERT: {node_name} failure rate is {stats.failure_rate:.0%}!\")\n",
    "    \n",
    "    def report(self):\n",
    "        \"\"\"Print dashboard report.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ðŸ“Š RETRY DASHBOARD\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for name, stats in self.stats.items():\n",
    "            print(f\"\\nðŸ“Œ {name}:\")\n",
    "            print(f\"   Calls: {stats.total_calls}\")\n",
    "            print(f\"   Success rate: {(1 - stats.failure_rate):.0%}\")\n",
    "            print(f\"   Total retries: {stats.total_retries}\")\n",
    "            print(f\"   Avg retries/success: {stats.avg_retries_per_success:.1f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# Global dashboard\n",
    "dashboard = RetryDashboard(alert_threshold=0.4)\n",
    "\n",
    "# Nodes that report to dashboard\n",
    "def node_a(state: dict) -> dict:\n",
    "    \"\"\"Mostly reliable node.\"\"\"\n",
    "    retries = 0\n",
    "    success = random.random() > 0.2  # 80% success\n",
    "    \n",
    "    if not success:\n",
    "        retries = random.randint(1, 3)\n",
    "        \n",
    "    dashboard.record(\"node_a\", success, retries)\n",
    "    return {\"a_done\": True}\n",
    "\n",
    "def node_b(state: dict) -> dict:\n",
    "    \"\"\"Less reliable node.\"\"\"\n",
    "    retries = 0\n",
    "    success = random.random() > 0.5  # 50% success\n",
    "    \n",
    "    if not success:\n",
    "        retries = random.randint(2, 5)\n",
    "        \n",
    "    dashboard.record(\"node_b\", success, retries)\n",
    "    return {\"b_done\": True}\n",
    "\n",
    "def node_c(state: dict) -> dict:\n",
    "    \"\"\"Unreliable node - will trigger alerts.\"\"\"\n",
    "    retries = 0\n",
    "    success = random.random() > 0.7  # Only 30% success\n",
    "    \n",
    "    if not success:\n",
    "        retries = random.randint(3, 5)\n",
    "        \n",
    "    dashboard.record(\"node_c\", success, retries)\n",
    "    return {\"c_done\": True}\n",
    "\n",
    "# Build graph\n",
    "class DashState(TypedDict):\n",
    "    a_done: bool\n",
    "    b_done: bool\n",
    "    c_done: bool\n",
    "\n",
    "graph = StateGraph(DashState)\n",
    "graph.add_node(\"a\", node_a)\n",
    "graph.add_node(\"b\", node_b)\n",
    "graph.add_node(\"c\", node_c)\n",
    "graph.add_edge(START, \"a\")\n",
    "graph.add_edge(\"a\", \"b\")\n",
    "graph.add_edge(\"b\", \"c\")\n",
    "graph.add_edge(\"c\", END)\n",
    "app = graph.compile()\n",
    "\n",
    "# Run multiple times\n",
    "print(\"=== Retry Dashboard Demo ===\\n\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Run {i + 1}...\")\n",
    "    app.invoke({\"a_done\": False, \"b_done\": False, \"c_done\": False})\n",
    "\n",
    "# Show report\n",
    "dashboard.report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.6 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.6.1: Multi-Source Aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_15_6_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Multi-source aggregator with failure handling.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import random\n",
    "\n",
    "class AggregatorState(TypedDict):\n",
    "    query: str\n",
    "    results: Annotated[list[dict], add]\n",
    "    errors: Annotated[list[str], add]\n",
    "\n",
    "def make_source(name: str, fail_rate: float = 0.5):\n",
    "    \"\"\"Create a source node with configurable failure rate.\"\"\"\n",
    "    def source_node(state: AggregatorState) -> dict:\n",
    "        if random.random() < fail_rate:\n",
    "            return {\"errors\": [f\"{name}: Connection failed\"]}\n",
    "        return {\"results\": [{\"source\": name, \"data\": f\"Data from {name}\"}]}\n",
    "    return source_node\n",
    "\n",
    "def aggregate(state: AggregatorState) -> dict:\n",
    "    \"\"\"Aggregate results and compute confidence.\"\"\"\n",
    "    successes = len(state[\"results\"])\n",
    "    failures = len(state[\"errors\"])\n",
    "    total = successes + failures\n",
    "    \n",
    "    confidence = successes / total if total > 0 else 0\n",
    "    \n",
    "    print(f\"\\n=== Aggregation Results ===\")\n",
    "    print(f\"Succeeded: {successes}/{total}\")\n",
    "    print(f\"Confidence: {confidence:.0%}\")\n",
    "    \n",
    "    if state[\"results\"]:\n",
    "        print(\"\\nData received:\")\n",
    "        for r in state[\"results\"]:\n",
    "            print(f\"  âœ“ {r['source']}: {r['data']}\")\n",
    "    \n",
    "    if state[\"errors\"]:\n",
    "        print(\"\\nFailures:\")\n",
    "        for e in state[\"errors\"]:\n",
    "            print(f\"  âœ— {e}\")\n",
    "    \n",
    "    return {}\n",
    "\n",
    "# Build graph with 4 sources\n",
    "graph = StateGraph(AggregatorState)\n",
    "\n",
    "graph.add_node(\"source_a\", make_source(\"Source A\", 0.3))\n",
    "graph.add_node(\"source_b\", make_source(\"Source B\", 0.7))\n",
    "graph.add_node(\"source_c\", make_source(\"Source C\", 0.5))\n",
    "graph.add_node(\"source_d\", make_source(\"Source D\", 0.4))\n",
    "graph.add_node(\"aggregate\", aggregate)\n",
    "\n",
    "# All sources run, then aggregate\n",
    "graph.add_edge(START, \"source_a\")\n",
    "graph.add_edge(START, \"source_b\")\n",
    "graph.add_edge(START, \"source_c\")\n",
    "graph.add_edge(START, \"source_d\")\n",
    "graph.add_edge(\"source_a\", \"aggregate\")\n",
    "graph.add_edge(\"source_b\", \"aggregate\")\n",
    "graph.add_edge(\"source_c\", \"aggregate\")\n",
    "graph.add_edge(\"source_d\", \"aggregate\")\n",
    "graph.add_edge(\"aggregate\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# Run it\n",
    "print(\"=== Multi-Source Aggregator Demo ===\")\n",
    "result = app.invoke({\"query\": \"test\", \"results\": [], \"errors\": []})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.6.2: Fallback Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_15_6_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Fallback chain with source tracking.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import random\n",
    "\n",
    "class FallbackState(TypedDict):\n",
    "    query: str\n",
    "    data: str\n",
    "    source_used: str\n",
    "    attempts: list[str]\n",
    "\n",
    "def try_primary(state: FallbackState) -> dict:\n",
    "    \"\"\"Primary API - fails 70% of the time.\"\"\"\n",
    "    attempts = state.get(\"attempts\", []) + [\"primary\"]\n",
    "    \n",
    "    if random.random() > 0.7:  # 30% success\n",
    "        return {\n",
    "            \"data\": \"Fresh data from primary API\",\n",
    "            \"source_used\": \"primary\",\n",
    "            \"attempts\": attempts\n",
    "        }\n",
    "    return {\"attempts\": attempts}\n",
    "\n",
    "def try_secondary(state: FallbackState) -> dict:\n",
    "    \"\"\"Secondary API - fails 40% of the time.\"\"\"\n",
    "    if state.get(\"data\"):  # Already have data\n",
    "        return {}\n",
    "    \n",
    "    attempts = state.get(\"attempts\", []) + [\"secondary\"]\n",
    "    \n",
    "    if random.random() > 0.4:  # 60% success\n",
    "        return {\n",
    "            \"data\": \"Data from secondary API\",\n",
    "            \"source_used\": \"secondary\",\n",
    "            \"attempts\": attempts\n",
    "        }\n",
    "    return {\"attempts\": attempts}\n",
    "\n",
    "def try_cache(state: FallbackState) -> dict:\n",
    "    \"\"\"Cache - always succeeds but stale.\"\"\"\n",
    "    if state.get(\"data\"):  # Already have data\n",
    "        return {}\n",
    "    \n",
    "    attempts = state.get(\"attempts\", []) + [\"cache\"]\n",
    "    return {\n",
    "        \"data\": \"Stale data from cache (24h old)\",\n",
    "        \"source_used\": \"cache\",\n",
    "        \"attempts\": attempts\n",
    "    }\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(FallbackState)\n",
    "graph.add_node(\"primary\", try_primary)\n",
    "graph.add_node(\"secondary\", try_secondary)\n",
    "graph.add_node(\"cache\", try_cache)\n",
    "\n",
    "graph.add_edge(START, \"primary\")\n",
    "graph.add_edge(\"primary\", \"secondary\")\n",
    "graph.add_edge(\"secondary\", \"cache\")\n",
    "graph.add_edge(\"cache\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# Test multiple times\n",
    "print(\"=== Fallback Chain Demo ===\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    result = app.invoke({\n",
    "        \"query\": \"test\",\n",
    "        \"data\": \"\",\n",
    "        \"source_used\": \"\",\n",
    "        \"attempts\": []\n",
    "    })\n",
    "    \n",
    "    print(f\"Run {i+1}:\")\n",
    "    print(f\"  Source: {result['source_used']}\")\n",
    "    print(f\"  Attempts: {' â†’ '.join(result['attempts'])}\")\n",
    "    print(f\"  Data: {result['data'][:30]}...\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.6.3: Graceful Feature Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_15_6_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Document analyzer with graceful feature degradation.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import random\n",
    "\n",
    "class AnalysisState(TypedDict):\n",
    "    document: str\n",
    "    features: dict\n",
    "    warnings: Annotated[list[str], add]\n",
    "\n",
    "def count_words(state: AnalysisState) -> dict:\n",
    "    \"\"\"Core feature - always works.\"\"\"\n",
    "    word_count = len(state[\"document\"].split())\n",
    "    features = state.get(\"features\", {})\n",
    "    features[\"word_count\"] = {\"value\": word_count, \"status\": \"ok\"}\n",
    "    return {\"features\": features}\n",
    "\n",
    "def analyze_sentiment(state: AnalysisState) -> dict:\n",
    "    \"\"\"Optional - fails 40% of the time.\"\"\"\n",
    "    features = state.get(\"features\", {})\n",
    "    \n",
    "    if random.random() < 0.4:\n",
    "        features[\"sentiment\"] = {\"value\": None, \"status\": \"failed\"}\n",
    "        return {\n",
    "            \"features\": features,\n",
    "            \"warnings\": [\"Sentiment analysis unavailable\"]\n",
    "        }\n",
    "    \n",
    "    features[\"sentiment\"] = {\"value\": \"positive\", \"status\": \"ok\"}\n",
    "    return {\"features\": features}\n",
    "\n",
    "def extract_keywords(state: AnalysisState) -> dict:\n",
    "    \"\"\"Optional - fails 30% of the time.\"\"\"\n",
    "    features = state.get(\"features\", {})\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        features[\"keywords\"] = {\"value\": None, \"status\": \"failed\"}\n",
    "        return {\n",
    "            \"features\": features,\n",
    "            \"warnings\": [\"Keyword extraction unavailable\"]\n",
    "        }\n",
    "    \n",
    "    words = state[\"document\"].split()[:3]\n",
    "    features[\"keywords\"] = {\"value\": words, \"status\": \"ok\"}\n",
    "    return {\"features\": features}\n",
    "\n",
    "def summarize(state: AnalysisState) -> dict:\n",
    "    \"\"\"Optional - fails 50% of the time.\"\"\"\n",
    "    features = state.get(\"features\", {})\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        features[\"summary\"] = {\"value\": None, \"status\": \"failed\"}\n",
    "        return {\n",
    "            \"features\": features,\n",
    "            \"warnings\": [\"Summarization unavailable\"]\n",
    "        }\n",
    "    \n",
    "    summary = state[\"document\"][:50] + \"...\"\n",
    "    features[\"summary\"] = {\"value\": summary, \"status\": \"ok\"}\n",
    "    return {\"features\": features}\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(AnalysisState)\n",
    "graph.add_node(\"words\", count_words)\n",
    "graph.add_node(\"sentiment\", analyze_sentiment)\n",
    "graph.add_node(\"keywords\", extract_keywords)\n",
    "graph.add_node(\"summary\", summarize)\n",
    "\n",
    "graph.add_edge(START, \"words\")\n",
    "graph.add_edge(\"words\", \"sentiment\")\n",
    "graph.add_edge(\"sentiment\", \"keywords\")\n",
    "graph.add_edge(\"keywords\", \"summary\")\n",
    "graph.add_edge(\"summary\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# Test\n",
    "doc = \"This is a sample document for testing the analyzer features.\"\n",
    "result = app.invoke({\"document\": doc, \"features\": {}, \"warnings\": []})\n",
    "\n",
    "print(\"=== Document Analysis Results ===\\n\")\n",
    "\n",
    "for feature, data in result[\"features\"].items():\n",
    "    status = \"âœ“\" if data[\"status\"] == \"ok\" else \"âœ—\"\n",
    "    value = data[\"value\"] if data[\"value\"] else \"N/A\"\n",
    "    print(f\"{status} {feature}: {value}\")\n",
    "\n",
    "if result[\"warnings\"]:\n",
    "    print(f\"\\nâš ï¸ Warnings: {len(result['warnings'])}\")\n",
    "    for w in result[\"warnings\"]:\n",
    "        print(f\"  - {w}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.7 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.7.1: State Diff Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_1_15_7_solution.py\n",
    "\n",
    "\"\"\"\n",
    "State diff viewer - compare snapshots and highlight changes.\n",
    "\"\"\"\n",
    "\n",
    "def diff_states(before: dict, after: dict) -> dict:\n",
    "    \"\"\"Compare two state snapshots.\"\"\"\n",
    "    diff = {\n",
    "        \"added\": {},\n",
    "        \"removed\": {},\n",
    "        \"modified\": {},\n",
    "        \"unchanged\": []\n",
    "    }\n",
    "    \n",
    "    all_keys = set(before.keys()) | set(after.keys())\n",
    "    \n",
    "    for key in all_keys:\n",
    "        if key not in before:\n",
    "            diff[\"added\"][key] = after[key]\n",
    "        elif key not in after:\n",
    "            diff[\"removed\"][key] = before[key]\n",
    "        elif before[key] != after[key]:\n",
    "            diff[\"modified\"][key] = {\n",
    "                \"from\": before[key],\n",
    "                \"to\": after[key]\n",
    "            }\n",
    "        else:\n",
    "            diff[\"unchanged\"].append(key)\n",
    "    \n",
    "    return diff\n",
    "\n",
    "def print_diff(diff: dict, title: str = \"State Diff\"):\n",
    "    \"\"\"Format and print state diff.\"\"\"\n",
    "    print(f\"\\n{'â•' * 50}\")\n",
    "    print(f\"ðŸ“Š {title}\")\n",
    "    print(f\"{'â•' * 50}\")\n",
    "    \n",
    "    if diff[\"added\"]:\n",
    "        print(\"\\nâœ… Added:\")\n",
    "        for key, value in diff[\"added\"].items():\n",
    "            print(f\"  + {key}: {value}\")\n",
    "    \n",
    "    if diff[\"removed\"]:\n",
    "        print(\"\\nâŒ Removed:\")\n",
    "        for key, value in diff[\"removed\"].items():\n",
    "            print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    if diff[\"modified\"]:\n",
    "        print(\"\\nðŸ“ Modified:\")\n",
    "        for key, change in diff[\"modified\"].items():\n",
    "            print(f\"  ~ {key}:\")\n",
    "            print(f\"      from: {change['from']}\")\n",
    "            print(f\"      to:   {change['to']}\")\n",
    "    \n",
    "    if diff[\"unchanged\"]:\n",
    "        print(f\"\\nâ¸ï¸ Unchanged: {', '.join(diff['unchanged'])}\")\n",
    "    \n",
    "    # Summary\n",
    "    total_changes = len(diff[\"added\"]) + len(diff[\"removed\"]) + len(diff[\"modified\"])\n",
    "    print(f\"\\n{'â”€' * 50}\")\n",
    "    print(f\"Summary: {total_changes} change(s)\")\n",
    "    print(f\"{'â•' * 50}\\n\")\n",
    "\n",
    "# Demo\n",
    "if __name__ == \"__main__\":\n",
    "    before = {\n",
    "        \"messages\": [\"Hello\"],\n",
    "        \"count\": 1,\n",
    "        \"status\": \"active\",\n",
    "        \"user\": \"alice\"\n",
    "    }\n",
    "    \n",
    "    after = {\n",
    "        \"messages\": [\"Hello\", \"World\"],\n",
    "        \"count\": 2,\n",
    "        \"status\": \"active\",\n",
    "        \"priority\": \"high\"  # Added\n",
    "        # \"user\" removed\n",
    "    }\n",
    "    \n",
    "    diff = diff_states(before, after)\n",
    "    print_diff(diff, \"Step 1 â†’ Step 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.7.2: Performance Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_2_15_7_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Performance dashboard for agent monitoring.\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "class PerformanceDashboard:\n",
    "    \"\"\"Track and report node performance.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.node_stats = defaultdict(lambda: {\n",
    "            \"calls\": 0,\n",
    "            \"successes\": 0,\n",
    "            \"failures\": 0,\n",
    "            \"total_time\": 0.0,\n",
    "            \"times\": []\n",
    "        })\n",
    "    \n",
    "    def record(self, node: str, duration: float, success: bool):\n",
    "        \"\"\"Record a node execution.\"\"\"\n",
    "        stats = self.node_stats[node]\n",
    "        stats[\"calls\"] += 1\n",
    "        stats[\"total_time\"] += duration\n",
    "        stats[\"times\"].append(duration)\n",
    "        \n",
    "        if success:\n",
    "            stats[\"successes\"] += 1\n",
    "        else:\n",
    "            stats[\"failures\"] += 1\n",
    "    \n",
    "    def wrap_node(self, node_name: str, func):\n",
    "        \"\"\"Create a wrapped node that auto-records metrics.\"\"\"\n",
    "        def wrapper(state):\n",
    "            start = time.time()\n",
    "            success = True\n",
    "            try:\n",
    "                result = func(state)\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                success = False\n",
    "                raise\n",
    "            finally:\n",
    "                self.record(node_name, time.time() - start, success)\n",
    "        return wrapper\n",
    "    \n",
    "    def print_report(self):\n",
    "        \"\"\"Print formatted performance report.\"\"\"\n",
    "        print(\"\\n\" + \"â•\" * 60)\n",
    "        print(\"ðŸ“Š PERFORMANCE DASHBOARD\")\n",
    "        print(\"â•\" * 60)\n",
    "        \n",
    "        # Calculate rankings\n",
    "        by_time = sorted(\n",
    "            self.node_stats.items(),\n",
    "            key=lambda x: x[1][\"total_time\"],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\nðŸ“ˆ Node Statistics:\")\n",
    "        print(\"â”€\" * 60)\n",
    "        print(f\"{'Node':<20} {'Calls':>6} {'Avg':>8} {'Total':>8} {'Success':>8}\")\n",
    "        print(\"â”€\" * 60)\n",
    "        \n",
    "        for node, stats in by_time:\n",
    "            avg = stats[\"total_time\"] / stats[\"calls\"] if stats[\"calls\"] else 0\n",
    "            rate = stats[\"successes\"] / stats[\"calls\"] * 100 if stats[\"calls\"] else 0\n",
    "            \n",
    "            print(f\"{node:<20} {stats['calls']:>6} {avg:>7.3f}s {stats['total_time']:>7.3f}s {rate:>7.0f}%\")\n",
    "        \n",
    "        print(\"â”€\" * 60)\n",
    "        \n",
    "        # Slowest nodes\n",
    "        print(\"\\nðŸ¢ Slowest Nodes (by avg time):\")\n",
    "        by_avg = sorted(\n",
    "            self.node_stats.items(),\n",
    "            key=lambda x: x[1][\"total_time\"] / max(x[1][\"calls\"], 1),\n",
    "            reverse=True\n",
    "        )[:3]\n",
    "        \n",
    "        for i, (node, stats) in enumerate(by_avg, 1):\n",
    "            avg = stats[\"total_time\"] / stats[\"calls\"]\n",
    "            print(f\"  {i}. {node}: {avg:.3f}s avg\")\n",
    "        \n",
    "        print(\"\\n\" + \"â•\" * 60)\n",
    "\n",
    "# Demo\n",
    "if __name__ == \"__main__\":\n",
    "    dashboard = PerformanceDashboard()\n",
    "    \n",
    "    # Simulate some runs\n",
    "    print(\"=== Performance Dashboard Demo ===\")\n",
    "    print(\"Simulating 10 agent runs...\\n\")\n",
    "    \n",
    "    for _ in range(10):\n",
    "        dashboard.record(\"fetch_data\", random.uniform(0.1, 0.5), random.random() > 0.1)\n",
    "        dashboard.record(\"process\", random.uniform(0.2, 0.8), random.random() > 0.2)\n",
    "        dashboard.record(\"save\", random.uniform(0.05, 0.15), random.random() > 0.05)\n",
    "    \n",
    "    dashboard.print_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.7.3: Alert System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: exercise_3_15_7_solution.py\n",
    "\n",
    "\"\"\"\n",
    "Simple alerting system with thresholds and severity.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class Severity(str, Enum):\n",
    "    INFO = \"info\"\n",
    "    WARNING = \"warning\"\n",
    "    CRITICAL = \"critical\"\n",
    "\n",
    "@dataclass\n",
    "class Alert:\n",
    "    severity: Severity\n",
    "    metric: str\n",
    "    message: str\n",
    "    value: float\n",
    "    threshold: float\n",
    "    timestamp: str\n",
    "\n",
    "class AlertSystem:\n",
    "    \"\"\"Monitor metrics and trigger alerts.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.thresholds = {}\n",
    "        self.alerts = []\n",
    "        self.metrics = {}\n",
    "    \n",
    "    def set_threshold(self, metric: str, warning: float, critical: float):\n",
    "        \"\"\"Set alert thresholds for a metric.\"\"\"\n",
    "        self.thresholds[metric] = {\n",
    "            \"warning\": warning,\n",
    "            \"critical\": critical\n",
    "        }\n",
    "    \n",
    "    def update_metric(self, metric: str, value: float):\n",
    "        \"\"\"Update a metric and check for alerts.\"\"\"\n",
    "        self.metrics[metric] = value\n",
    "        \n",
    "        if metric in self.thresholds:\n",
    "            t = self.thresholds[metric]\n",
    "            \n",
    "            if value >= t[\"critical\"]:\n",
    "                self._trigger(Severity.CRITICAL, metric, value, t[\"critical\"])\n",
    "            elif value >= t[\"warning\"]:\n",
    "                self._trigger(Severity.WARNING, metric, value, t[\"warning\"])\n",
    "    \n",
    "    def _trigger(self, severity: Severity, metric: str, value: float, threshold: float):\n",
    "        \"\"\"Trigger an alert.\"\"\"\n",
    "        alert = Alert(\n",
    "            severity=severity,\n",
    "            metric=metric,\n",
    "            message=f\"{metric} is {value:.1f} (threshold: {threshold:.1f})\",\n",
    "            value=value,\n",
    "            threshold=threshold,\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "        self.alerts.append(alert)\n",
    "        \n",
    "        # Print immediately\n",
    "        icon = \"ðŸ”´\" if severity == Severity.CRITICAL else \"ðŸŸ¡\"\n",
    "        print(f\"{icon} [{severity.value.upper()}] {alert.message}\")\n",
    "    \n",
    "    def get_active_alerts(self) -> list[Alert]:\n",
    "        \"\"\"Get alerts from last hour.\"\"\"\n",
    "        # In real system, filter by time\n",
    "        return self.alerts[-10:]  # Last 10 for demo\n",
    "    \n",
    "    def print_status(self):\n",
    "        \"\"\"Print current status.\"\"\"\n",
    "        print(\"\\n\" + \"â•\" * 50)\n",
    "        print(\"ðŸš¨ ALERT SYSTEM STATUS\")\n",
    "        print(\"â•\" * 50)\n",
    "        \n",
    "        print(\"\\nðŸ“Š Current Metrics:\")\n",
    "        for metric, value in self.metrics.items():\n",
    "            status = \"âœ“\"\n",
    "            if metric in self.thresholds:\n",
    "                t = self.thresholds[metric]\n",
    "                if value >= t[\"critical\"]:\n",
    "                    status = \"ðŸ”´\"\n",
    "                elif value >= t[\"warning\"]:\n",
    "                    status = \"ðŸŸ¡\"\n",
    "            print(f\"  {status} {metric}: {value:.1f}\")\n",
    "        \n",
    "        print(f\"\\nðŸ“‹ Alert History ({len(self.alerts)} total):\")\n",
    "        for alert in self.alerts[-5:]:\n",
    "            icon = \"ðŸ”´\" if alert.severity == Severity.CRITICAL else \"ðŸŸ¡\"\n",
    "            print(f\"  {icon} {alert.message}\")\n",
    "        \n",
    "        print(\"â•\" * 50)\n",
    "\n",
    "# Demo\n",
    "if __name__ == \"__main__\":\n",
    "    alerts = AlertSystem()\n",
    "    \n",
    "    # Set thresholds\n",
    "    alerts.set_threshold(\"error_rate\", warning=5.0, critical=10.0)\n",
    "    alerts.set_threshold(\"latency_ms\", warning=500, critical=1000)\n",
    "    alerts.set_threshold(\"queue_size\", warning=100, critical=200)\n",
    "    \n",
    "    print(\"=== Alert System Demo ===\\n\")\n",
    "    \n",
    "    # Simulate metrics - all OK\n",
    "    print(\"Initial metrics (all OK):\")\n",
    "    alerts.update_metric(\"error_rate\", 3.0)   # OK\n",
    "    alerts.update_metric(\"latency_ms\", 250)   # OK\n",
    "    alerts.update_metric(\"queue_size\", 50)    # OK\n",
    "    \n",
    "    print(\"\\n--- Situation worsens ---\\n\")\n",
    "    \n",
    "    alerts.update_metric(\"error_rate\", 7.0)   # Warning!\n",
    "    alerts.update_metric(\"latency_ms\", 1200)  # Critical!\n",
    "    alerts.update_metric(\"queue_size\", 150)   # Warning!\n",
    "    \n",
    "    alerts.print_status()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "Return to **Chapter 16: Next Topic**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}