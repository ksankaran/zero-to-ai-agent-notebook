{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: Introduction to LangGraph\n",
    "**From: Zero to AI Agent**\n",
    "\n",
    "## Overview\n",
    "In this chapter, you'll learn about:\n",
    "- Why LangGraph? Limitations of simple chains\n",
    "- Graph-based agent architectures\n",
    "- Installing and setting up LangGraph\n",
    "- Core concepts: nodes, edges, and state\n",
    "- Your first LangGraph application\n",
    "- Conditional edges and branching logic\n",
    "- Debugging LangGraph flows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 14.1: Why LangGraph? Limitations of simple chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 14.1 content\n",
    "# No source files found for this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 14.1 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.1.1: Identify Chain Limitations\n",
    "\n",
    "Think of an AI application you'd like to build (or pick one: email assistant, study tutor, recipe suggester). Write down:\n",
    "\n",
    "1. What steps would it need to perform?\n",
    "2. Where might it need to loop back (retry or refine)?\n",
    "3. Where might it need to branch (handle different cases)?\n",
    "4. What information would it need to track across steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.1.2: Flowchart Design\n",
    "\n",
    "Draw a flowchart (on paper or describe it in text) for a \"Smart Email Responder\" that:\n",
    "\n",
    "- Reads an incoming email\n",
    "- Classifies it (urgent, normal, spam)\n",
    "- For urgent: drafts an immediate response\n",
    "- For normal: adds to a queue\n",
    "- For spam: archives it\n",
    "- For drafted responses: gets human approval\n",
    "- If human requests changes: loops back to redraft\n",
    "\n",
    "Identify which parts would be impossible or messy with a simple chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.1.3: Analyze the Pattern\n",
    "\n",
    "Look at this pseudo-code:\n",
    "\n",
    "```python\n",
    "def smart_assistant(task):\n",
    "    plan = create_plan(task)\n",
    "    \n",
    "    while not is_complete(plan):\n",
    "        next_step = get_next_step(plan)\n",
    "        result = execute_step(next_step)\n",
    "        \n",
    "        if result.failed:\n",
    "            if result.retryable:\n",
    "                continue  # Try same step again\n",
    "            else:\n",
    "                plan = revise_plan(plan, result.error)\n",
    "        else:\n",
    "            update_plan(plan, result)\n",
    "    \n",
    "    return summarize_results(plan)\n",
    "```\n",
    "\n",
    "Explain why this would be difficult with simple chains. Identify: the loops, the branching points, and what state needs to persist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 14.2: Graph-based agent architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 14.2 content\n",
    "# No source files found for this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 14.2 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.2.1: Pattern Recognition\n",
    "\n",
    "For each scenario, identify which pattern(s) would be most appropriate:\n",
    "\n",
    "1. An agent that translates a document from English to Spanish\n",
    "2. An agent that keeps asking clarifying questions until it understands the user's request\n",
    "3. An agent that checks the weather in three cities simultaneously\n",
    "4. An agent that writes code, runs tests, and fixes bugs until all tests pass\n",
    "5. An agent that drafts a legal contract and requires lawyer approval before finalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.2.2: Design a Recipe Agent\n",
    "\n",
    "Design a graph for a cooking assistant agent that:\n",
    "- Takes a dish the user wants to make\n",
    "- Checks what ingredients the user has available\n",
    "- Finds a suitable recipe (might need to search multiple times for alternatives)\n",
    "- Adjusts the recipe based on available ingredients\n",
    "- Generates step-by-step cooking instructions\n",
    "- Can answer questions during cooking (loops back to handle questions)\n",
    "\n",
    "Sketch the graph and identify: the nodes, the decision points, any loops, and what state you'd need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.2.3: Identify the State\n",
    "\n",
    "For the customer service agent we designed in this section, list all the pieces of information that should be in the state. For each piece, explain which node(s) would write to it and which node(s) would read from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 14.3: Installing and setting up LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: verify_install.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.3\n",
    "# File: verify_install.py\n",
    "\n",
    "\"\"\"Verify that LangGraph is installed correctly.\"\"\"\n",
    "\n",
    "def check_installation():\n",
    "    \"\"\"Check all required packages.\"\"\"\n",
    "    print(\"üîç Checking LangGraph installation...\\n\")\n",
    "    \n",
    "    # Check langgraph\n",
    "    try:\n",
    "        import langgraph\n",
    "        print(f\"‚úÖ langgraph installed (version: {langgraph.__version__})\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå langgraph not installed\")\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        print(\"‚úÖ langgraph installed (version not available)\")\n",
    "    \n",
    "    # Check langchain\n",
    "    try:\n",
    "        import langchain\n",
    "        print(f\"‚úÖ langchain installed (version: {langchain.__version__})\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå langchain not installed\")\n",
    "        return False\n",
    "    \n",
    "    # Check langchain-openai\n",
    "    try:\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        print(\"‚úÖ langchain-openai installed\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå langchain-openai not installed\")\n",
    "        return False\n",
    "    \n",
    "    # Check python-dotenv\n",
    "    try:\n",
    "        import dotenv\n",
    "        print(\"‚úÖ python-dotenv installed\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå python-dotenv not installed\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\nüéâ All packages installed correctly!\")\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_installation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: verify_api.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.3\n",
    "# File: verify_api.py\n",
    "\n",
    "\"\"\"Verify API connection is working.\"\"\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def check_api():\n",
    "    \"\"\"Check that we can connect to OpenAI.\"\"\"\n",
    "    print(\"üîç Checking API connection...\\n\")\n",
    "    \n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Check for API key\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"‚ùå OPENAI_API_KEY not found in environment\")\n",
    "        print(\"   Make sure you have a .env file with your API key\")\n",
    "        return False\n",
    "    \n",
    "    if not api_key.startswith(\"sk-\"):\n",
    "        print(\"‚ö†Ô∏è  API key doesn't start with 'sk-' - it might be invalid\")\n",
    "    \n",
    "    print(\"‚úÖ API key found\")\n",
    "    \n",
    "    # Try to make a simple API call\n",
    "    print(\"\\nüîÑ Testing API connection...\")\n",
    "    \n",
    "    try:\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        \n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "        response = llm.invoke(\"Say 'Hello, LangGraph!' and nothing else.\")\n",
    "        \n",
    "        print(f\"‚úÖ API connection successful!\")\n",
    "        print(f\"   Response: {response.content}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_api()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: verify_langgraph.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.3\n",
    "# File: verify_langgraph.py\n",
    "\n",
    "\"\"\"Verify LangGraph components are accessible.\"\"\"\n",
    "\n",
    "def check_langgraph():\n",
    "    \"\"\"Check that we can import LangGraph components.\"\"\"\n",
    "    print(\"üîç Checking LangGraph components...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Core graph components\n",
    "        from langgraph.graph import StateGraph, END\n",
    "        print(\"‚úÖ StateGraph imported (for building graphs)\")\n",
    "        print(\"‚úÖ END imported (for marking end states)\")\n",
    "        \n",
    "        # State management\n",
    "        from typing import TypedDict\n",
    "        print(\"‚úÖ TypedDict available (for defining state)\")\n",
    "        \n",
    "        # Checkpointing (for persistence)\n",
    "        from langgraph.checkpoint.memory import MemorySaver\n",
    "        print(\"‚úÖ MemorySaver imported (for state persistence)\")\n",
    "        \n",
    "        print(\"\\nüéâ All LangGraph components ready!\")\n",
    "        print(\"\\nYou can now build graphs with:\")\n",
    "        print(\"  - StateGraph: Define your graph structure\")\n",
    "        print(\"  - Nodes: Add processing steps\")\n",
    "        print(\"  - Edges: Connect steps together\")\n",
    "        print(\"  - State: Share data between nodes\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Import failed: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_langgraph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 14.3 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.3.1: Environment Exploration\n",
    "\n",
    "Run `pip list` in your terminal and find all the packages that were installed as dependencies of LangGraph. Count how many there are. Then look up what three of them do (pick ones with interesting names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.3.2: API Key Security\n",
    "\n",
    "Explain in your own words why we use a `.env` file instead of putting the API key directly in our code. What could go wrong if you accidentally committed an API key to a public GitHub repository?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.3.3: Create a Setup Checker\n",
    "\n",
    "Combine all three verification scripts into one comprehensive `setup_check.py` that:\n",
    "- Checks all package installations\n",
    "- Verifies the API key exists and has the right format\n",
    "- Tests the API connection\n",
    "- Reports a summary at the end with overall pass/fail\n",
    "\n",
    "Make it user-friendly with clear instructions if anything fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 14.4: Core concepts: nodes, edges, and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: writer_loop.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.4\n",
    "# File: writer_loop.py\n",
    "\n",
    "\"\"\"\n",
    "A simple feedback loop demonstrating LangGraph core concepts:\n",
    "- State with TypedDict\n",
    "- Nodes that read/write state\n",
    "- Conditional edges for looping\n",
    "- The add reducer for list accumulation\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "# 1. Define our state\n",
    "class WriterState(TypedDict):\n",
    "    topic: str                           # What to write about\n",
    "    drafts: Annotated[list, add]         # Accumulate drafts\n",
    "    current_draft: str                   # Latest draft\n",
    "    quality_score: int                   # How good is it (1-10)\n",
    "\n",
    "\n",
    "# 2. Define our nodes\n",
    "def write_draft(state: WriterState) -> dict:\n",
    "    \"\"\"Write or rewrite a draft.\"\"\"\n",
    "    topic = state[\"topic\"]\n",
    "    attempt = len(state.get(\"drafts\", [])) + 1\n",
    "    \n",
    "    # In reality, this would call an LLM\n",
    "    draft = f\"Draft {attempt} about {topic}: [content here]\"\n",
    "    \n",
    "    return {\n",
    "        \"current_draft\": draft,\n",
    "        \"drafts\": [draft]  # Appends due to Annotated[list, add]\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_draft(state: WriterState) -> dict:\n",
    "    \"\"\"Score the current draft.\"\"\"\n",
    "    draft = state[\"current_draft\"]\n",
    "    \n",
    "    # In reality, this would use an LLM or other logic\n",
    "    # For demo, score increases with each attempt\n",
    "    score = min(len(state.get(\"drafts\", [])) * 3, 10)\n",
    "    \n",
    "    return {\"quality_score\": score}\n",
    "\n",
    "\n",
    "def decide_if_done(state: WriterState) -> str:\n",
    "    \"\"\"Decide whether to finish or revise.\"\"\"\n",
    "    if state[\"quality_score\"] >= 7:\n",
    "        return \"done\"\n",
    "    elif len(state.get(\"drafts\", [])) >= 3:\n",
    "        return \"done\"  # Give up after 3 attempts\n",
    "    else:\n",
    "        return \"revise\"\n",
    "\n",
    "\n",
    "# 3. Build the graph\n",
    "graph = StateGraph(WriterState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"write\", write_draft)\n",
    "graph.add_node(\"evaluate\", evaluate_draft)\n",
    "\n",
    "# Add edges\n",
    "graph.set_entry_point(\"write\")\n",
    "graph.add_edge(\"write\", \"evaluate\")\n",
    "graph.add_conditional_edges(\n",
    "    \"evaluate\",\n",
    "    decide_if_done,\n",
    "    {\n",
    "        \"done\": END,\n",
    "        \"revise\": \"write\"  # Loop back!\n",
    "    }\n",
    ")\n",
    "\n",
    "# 4. Compile the graph\n",
    "app = graph.compile()\n",
    "\n",
    "# 5. Run it!\n",
    "if __name__ == \"__main__\":\n",
    "    result = app.invoke({\"topic\": \"AI agents\", \"drafts\": []})\n",
    "    print(f\"Final draft: {result['current_draft']}\")\n",
    "    print(f\"Total attempts: {len(result['drafts'])}\")\n",
    "    print(f\"Final score: {result['quality_score']}\")\n",
    "    \n",
    "    # Show all drafts\n",
    "    print(\"\\nAll drafts:\")\n",
    "    for i, draft in enumerate(result['drafts'], 1):\n",
    "        print(f\"  {i}. {draft}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 14.4 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.4.1: Design a State\n",
    "\n",
    "Design the state TypedDict for a \"Code Review Agent\" that:\n",
    "- Receives code to review\n",
    "- Identifies issues (could be multiple)\n",
    "- Suggests fixes for each issue\n",
    "- Tracks which issues have been addressed\n",
    "- Knows when the review is complete\n",
    "\n",
    "Think about: What fields do you need? Which should be lists? Which need the `add` reducer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.4.2: Write the Nodes\n",
    "\n",
    "Using the state you designed in Exercise 1, write pseudocode (or real code) for three nodes:\n",
    "- `analyze_code`: Looks at the code and identifies issues\n",
    "- `suggest_fix`: Takes one issue and suggests a fix\n",
    "- `check_complete`: Determines if all issues are addressed\n",
    "\n",
    "Focus on: What does each node read from state? What does it write back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.4.3: Draw the Graph\n",
    "\n",
    "Sketch the graph (on paper or ASCII art) for the Code Review Agent. Include:\n",
    "- Where it starts\n",
    "- The flow between nodes\n",
    "- Any conditional edges (what are the conditions?)\n",
    "- Where loops occur\n",
    "- Where it ends\n",
    "\n",
    "Then write the LangGraph code to build this graph structure (just the graph building part‚Äînodes can be placeholder functions).\n",
    "\n",
    "\n",
    "This complete solution includes the state design (Exercise 1), node implementations (Exercise 2), and graph construction (Exercise 3) all in one runnable file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 14.5: Your first LangGraph application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: self_improving_writer.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.5\n",
    "# File: self_improving_writer.py\n",
    "\n",
    "\"\"\"A LangGraph application that writes and improves content iteratively.\n",
    "\n",
    "This demonstrates the fundamental generate ‚Üí evaluate ‚Üí improve ‚Üí repeat pattern\n",
    "used in many AI agents.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize our LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "\n",
    "# === STATE ===\n",
    "\n",
    "class WriterState(TypedDict):\n",
    "    topic: str                    # The topic to write about\n",
    "    draft: str                    # Current draft\n",
    "    critique: str                 # Feedback on the draft\n",
    "    revision_count: int           # How many revisions so far\n",
    "    max_revisions: int            # Maximum revisions allowed\n",
    "\n",
    "\n",
    "# === NODES ===\n",
    "\n",
    "def write(state: WriterState) -> dict:\n",
    "    \"\"\"Write or revise the draft based on current state.\"\"\"\n",
    "    topic = state[\"topic\"]\n",
    "    draft = state.get(\"draft\", \"\")\n",
    "    critique = state.get(\"critique\", \"\")\n",
    "    revision_count = state.get(\"revision_count\", 0)\n",
    "\n",
    "    if not draft:\n",
    "        # Initial draft - no existing content\n",
    "        prompt = f\"\"\"Write a short, informative paragraph about: {topic}\n",
    "\n",
    "        Keep it concise but engaging. Aim for 3-4 sentences.\"\"\"\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        print(f\"üìù Initial draft written ({len(response.content)} chars)\")\n",
    "\n",
    "        return {\n",
    "            \"draft\": response.content,\n",
    "            \"revision_count\": 0\n",
    "        }\n",
    "    else:\n",
    "        # Revision - improve based on critique\n",
    "        prompt = f\"\"\"Revise this draft about \"{topic}\" based on the feedback provided.\n",
    "\n",
    "        Current draft:\n",
    "        {draft}\n",
    "\n",
    "        Feedback:\n",
    "        {critique}\n",
    "\n",
    "        Write an improved version that addresses the feedback. Keep it concise.\"\"\"\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        new_count = revision_count + 1\n",
    "        print(f\"‚úèÔ∏è Revision {new_count} complete\")\n",
    "\n",
    "        return {\n",
    "            \"draft\": response.content,\n",
    "            \"revision_count\": new_count\n",
    "        }\n",
    "\n",
    "\n",
    "def critique_draft(state: WriterState) -> dict:\n",
    "    \"\"\"Analyze the draft and provide constructive feedback.\"\"\"\n",
    "    draft = state[\"draft\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    prompt = f\"\"\"Review this draft about \"{topic}\" and provide brief, constructive feedback.\n",
    "\n",
    "    Draft:\n",
    "    {draft}\n",
    "\n",
    "    Focus on:\n",
    "    1. Is the information accurate and complete?\n",
    "    2. Is it engaging and well-written?\n",
    "    3. What specific improvements would make it better?\n",
    "\n",
    "    If the draft is already excellent, say \"EXCELLENT\" at the start of your response.\n",
    "    Otherwise, provide 2-3 specific suggestions for improvement.\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    print(f\"üîç Critique: {response.content[:100]}...\")\n",
    "\n",
    "    return {\"critique\": response.content}\n",
    "\n",
    "\n",
    "# === DECISION FUNCTION ===\n",
    "\n",
    "def should_continue(state: WriterState) -> str:\n",
    "    \"\"\"Decide whether to revise again or finish.\"\"\"\n",
    "    critique = state[\"critique\"]\n",
    "    revision_count = state[\"revision_count\"]\n",
    "    max_revisions = state[\"max_revisions\"]\n",
    "    \n",
    "    # Stop if we've hit the revision limit\n",
    "    if revision_count >= max_revisions:\n",
    "        print(f\"üõë Max revisions ({max_revisions}) reached\")\n",
    "        return \"end\"\n",
    "    \n",
    "    # Stop if the critique says it's excellent\n",
    "    if \"EXCELLENT\" in critique.upper():\n",
    "        print(\"‚ú® Draft deemed excellent!\")\n",
    "        return \"end\"\n",
    "    \n",
    "    # Otherwise, keep improving\n",
    "    print(\"üîÑ Continuing to revise...\")\n",
    "    return \"continue\"\n",
    "\n",
    "\n",
    "# === GRAPH BUILDER ===\n",
    "\n",
    "def create_writer_graph():\n",
    "    \"\"\"Build and return the writer graph.\"\"\"\n",
    "\n",
    "    # Create the graph with our state type\n",
    "    graph = StateGraph(WriterState)\n",
    "\n",
    "    # Add our nodes\n",
    "    graph.add_node(\"write\", write)\n",
    "    graph.add_node(\"critique\", critique_draft)\n",
    "\n",
    "    # Set the entry point\n",
    "    graph.set_entry_point(\"write\")\n",
    "\n",
    "    # Add edges\n",
    "    graph.add_edge(\"write\", \"critique\")\n",
    "\n",
    "    graph.add_conditional_edges(\n",
    "        \"critique\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"write\",  # Loop back to write for revision\n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "# === MAIN ===\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run the self-improving writer.\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"üöÄ Self-Improving Writer\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create the graph\n",
    "    app = create_writer_graph()\n",
    "    \n",
    "    # Define our initial state\n",
    "    initial_state = {\n",
    "        \"topic\": \"Why learning to code is valuable in 2024\",\n",
    "        \"draft\": \"\",\n",
    "        \"critique\": \"\",\n",
    "        \"revision_count\": 0,\n",
    "        \"max_revisions\": 3\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìå Topic: {initial_state['topic']}\")\n",
    "    print(f\"üìå Max revisions: {initial_state['max_revisions']}\")\n",
    "    print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "    \n",
    "    # Run the graph\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    # Show the final result\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üìÑ FINAL DRAFT:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(result[\"draft\"])\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(f\"Total revisions: {result['revision_count']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 14.5 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.5.1: Add Draft History\n",
    "\n",
    "Modify the writer to keep a history of all drafts, not just the current one. You'll need to:\n",
    "- Change the state to use `Annotated[list, add]` for drafts\n",
    "- Update nodes to append drafts rather than replace\n",
    "- Display all versions at the end\n",
    "\n",
    "This lets you see how the writing evolved through revisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.5.2: Quality Scoring\n",
    "\n",
    "Add a numeric quality score (1-10) to the process:\n",
    "- Add a `quality_score` field to state\n",
    "- Modify `critique_draft` to also output a score\n",
    "- Update `should_continue` to use the score (stop when score \\>= 8)\n",
    "- Display the score progression at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.5.3: Different Writing Styles\n",
    "\n",
    "Add a `style` parameter that changes how the writer works:\n",
    "- \"formal\": Professional, business-like tone\n",
    "- \"casual\": Friendly, conversational tone  \n",
    "- \"creative\": Artistic, expressive tone\n",
    "\n",
    "Modify the prompts in each node to respect the chosen style. Test with the same topic but different styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 14.6: Conditional edges and branching logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: ticket_router.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.6\n",
    "# File: ticket_router.py\n",
    "\n",
    "\"\"\"A support ticket router with multi-way branching.\n",
    "\n",
    "Demonstrates Pattern 1: Multi-Way Branching\n",
    "- Classification node analyzes ticket\n",
    "- Routing function decides destination (5 options)\n",
    "- Specialized handlers for each category\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# === STATE ===\n",
    "\n",
    "class TicketState(TypedDict):\n",
    "    ticket_text: str          # The customer's message\n",
    "    category: str             # Classified category (BILLING, TECHNICAL, etc.)\n",
    "    priority: str             # Urgency level (HIGH, MEDIUM, LOW)\n",
    "    response: str             # Generated response\n",
    "    needs_human: bool         # Flag for escalation\n",
    "\n",
    "\n",
    "# === CLASSIFICATION NODE ===\n",
    "\n",
    "def classify_ticket(state: TicketState) -> dict:\n",
    "    \"\"\"Classify the ticket into a category and priority level.\n",
    "    \n",
    "    This node uses the LLM to analyze the ticket text and determine:\n",
    "    1. What type of issue it is (billing, technical, account, general)\n",
    "    2. How urgent it is (high, medium, low)\n",
    "    \n",
    "    High priority tickets will be escalated regardless of category.\n",
    "    \"\"\"\n",
    "    ticket = state[\"ticket_text\"]\n",
    "    \n",
    "    prompt = f\"\"\"Classify this support ticket into exactly one category.\n",
    "    \n",
    "    Ticket: {ticket}\n",
    "    \n",
    "    Categories:\n",
    "    - BILLING: Payment issues, invoices, refunds, subscriptions\n",
    "    - TECHNICAL: Bugs, errors, how-to questions, feature requests\n",
    "    - ACCOUNT: Login issues, password reset, profile changes\n",
    "    - GENERAL: Everything else\n",
    "    \n",
    "    Also determine priority:\n",
    "    - HIGH: Customer is angry, service is down, money involved\n",
    "    - MEDIUM: Normal requests, minor issues\n",
    "    - LOW: Questions, feedback, suggestions\n",
    "    \n",
    "    Respond in format:\n",
    "    CATEGORY: <category>\n",
    "    PRIORITY: <priority>\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    content = response.content.upper()\n",
    "    \n",
    "    # Parse category from response - default to GENERAL if not found\n",
    "    category = \"GENERAL\"\n",
    "    for cat in [\"BILLING\", \"TECHNICAL\", \"ACCOUNT\"]:\n",
    "        if cat in content:\n",
    "            category = cat\n",
    "            break\n",
    "    \n",
    "    # Parse priority from response - default to MEDIUM if not found\n",
    "    priority = \"MEDIUM\"\n",
    "    for pri in [\"HIGH\", \"LOW\"]:\n",
    "        if pri in content:\n",
    "            priority = pri\n",
    "            break\n",
    "    \n",
    "    print(f\"üìã Classified: {category} ({priority} priority)\")\n",
    "    \n",
    "    return {\n",
    "        \"category\": category,\n",
    "        \"priority\": priority\n",
    "    }\n",
    "\n",
    "\n",
    "# === ROUTING FUNCTION ===\n",
    "\n",
    "def route_by_category(state: TicketState) -> str:\n",
    "    \"\"\"Decide which handler should process this ticket.\n",
    "    \n",
    "    The routing logic:\n",
    "    1. HIGH priority tickets always go to escalation (human needed)\n",
    "    2. Otherwise, route to the specialized handler for that category\n",
    "    \n",
    "    Returns a string that matches one of our handler node names.\n",
    "    \"\"\"\n",
    "    category = state[\"category\"]\n",
    "    priority = state[\"priority\"]\n",
    "    \n",
    "    # High priority always escalates, regardless of category\n",
    "    if priority == \"HIGH\":\n",
    "        return \"escalate\"\n",
    "    \n",
    "    # Map categories to handler names\n",
    "    routes = {\n",
    "        \"BILLING\": \"handle_billing\",\n",
    "        \"TECHNICAL\": \"handle_technical\",\n",
    "        \"ACCOUNT\": \"handle_account\",\n",
    "        \"GENERAL\": \"handle_general\"\n",
    "    }\n",
    "    \n",
    "    return routes.get(category, \"handle_general\")\n",
    "\n",
    "\n",
    "# === HANDLER NODES ===\n",
    "\n",
    "def handle_billing(state: TicketState) -> dict:\n",
    "    \"\"\"Handle billing-related tickets.\n",
    "    \n",
    "    Specializes in: payments, invoices, refunds, subscription issues.\n",
    "    Uses a billing-focused prompt that knows about refund policies.\n",
    "    \"\"\"\n",
    "    ticket = state[\"ticket_text\"]\n",
    "    \n",
    "    prompt = f\"\"\"You are a billing support specialist. Help with this issue:\n",
    "    \n",
    "    {ticket}\n",
    "    \n",
    "    Be helpful and mention our refund policy if relevant.\n",
    "    Keep response concise (2-3 sentences).\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    print(\"üí≥ Billing handler responded\")\n",
    "    \n",
    "    return {\"response\": response.content, \"needs_human\": False}\n",
    "\n",
    "\n",
    "def handle_technical(state: TicketState) -> dict:\n",
    "    \"\"\"Handle technical support tickets.\n",
    "    \n",
    "    Specializes in: bugs, errors, how-to questions, troubleshooting.\n",
    "    Provides clear, step-by-step guidance.\n",
    "    \"\"\"\n",
    "    ticket = state[\"ticket_text\"]\n",
    "    \n",
    "    prompt = f\"\"\"You are a technical support specialist. Help with this issue:\n",
    "    \n",
    "    {ticket}\n",
    "    \n",
    "    Provide clear troubleshooting steps.\n",
    "    Keep response concise (2-3 sentences).\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    print(\"üîß Technical handler responded\")\n",
    "    \n",
    "    return {\"response\": response.content, \"needs_human\": False}\n",
    "\n",
    "\n",
    "def handle_account(state: TicketState) -> dict:\n",
    "    \"\"\"Handle account-related tickets.\n",
    "    \n",
    "    Specializes in: login issues, password reset, profile changes.\n",
    "    Prioritizes security in responses.\n",
    "    \"\"\"\n",
    "    ticket = state[\"ticket_text\"]\n",
    "    \n",
    "    prompt = f\"\"\"You are an account support specialist. Help with this issue:\n",
    "    \n",
    "    {ticket}\n",
    "    \n",
    "    Prioritize security and verification.\n",
    "    Keep response concise (2-3 sentences).\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    print(\"üë§ Account handler responded\")\n",
    "    \n",
    "    return {\"response\": response.content, \"needs_human\": False}\n",
    "\n",
    "\n",
    "def handle_general(state: TicketState) -> dict:\n",
    "    \"\"\"Handle general inquiries that don't fit other categories.\"\"\"\n",
    "    ticket = state[\"ticket_text\"]\n",
    "    \n",
    "    prompt = f\"\"\"You are a friendly support agent. Help with this inquiry:\n",
    "    \n",
    "    {ticket}\n",
    "    \n",
    "    Be warm and helpful.\n",
    "    Keep response concise (2-3 sentences).\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    print(\"üìß General handler responded\")\n",
    "    \n",
    "    return {\"response\": response.content, \"needs_human\": False}\n",
    "\n",
    "\n",
    "def escalate_ticket(state: TicketState) -> dict:\n",
    "    \"\"\"Escalate high-priority tickets to human agents.\n",
    "    \n",
    "    This node doesn't try to solve the problem‚Äîit acknowledges\n",
    "    the urgency and promises human follow-up.\n",
    "    \"\"\"\n",
    "    print(\"üö® Escalating to human agent\")\n",
    "    \n",
    "    return {\n",
    "        \"response\": \"This ticket has been escalated to a senior support agent who will contact you within 1 hour.\",\n",
    "        \"needs_human\": True\n",
    "    }\n",
    "\n",
    "\n",
    "# === GRAPH BUILDER ===\n",
    "\n",
    "def create_router_graph():\n",
    "    \"\"\"Build the ticket routing graph.\n",
    "    \n",
    "    The flow:\n",
    "    1. classify - Analyze the ticket\n",
    "    2. route_by_category - Decide which handler (conditional edge)\n",
    "    3. One of five handlers runs\n",
    "    4. END\n",
    "    \"\"\"\n",
    "    graph = StateGraph(TicketState)\n",
    "    \n",
    "    # Add all our nodes\n",
    "    graph.add_node(\"classify\", classify_ticket)\n",
    "    graph.add_node(\"handle_billing\", handle_billing)\n",
    "    graph.add_node(\"handle_technical\", handle_technical)\n",
    "    graph.add_node(\"handle_account\", handle_account)\n",
    "    graph.add_node(\"handle_general\", handle_general)\n",
    "    graph.add_node(\"escalate\", escalate_ticket)\n",
    "    \n",
    "    # Start at classification\n",
    "    graph.set_entry_point(\"classify\")\n",
    "    \n",
    "    # After classification, route to the appropriate handler\n",
    "    # This is the key part - 5-way conditional branching!\n",
    "    graph.add_conditional_edges(\n",
    "        \"classify\",\n",
    "        route_by_category,\n",
    "        {\n",
    "            \"handle_billing\": \"handle_billing\",\n",
    "            \"handle_technical\": \"handle_technical\",\n",
    "            \"handle_account\": \"handle_account\",\n",
    "            \"handle_general\": \"handle_general\",\n",
    "            \"escalate\": \"escalate\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # All handlers lead to END (no loops in this graph)\n",
    "    graph.add_edge(\"handle_billing\", END)\n",
    "    graph.add_edge(\"handle_technical\", END)\n",
    "    graph.add_edge(\"handle_account\", END)\n",
    "    graph.add_edge(\"handle_general\", END)\n",
    "    graph.add_edge(\"escalate\", END)\n",
    "    \n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "# === MAIN ===\n",
    "\n",
    "def main():\n",
    "    \"\"\"Test the ticket router with different types of tickets.\"\"\"\n",
    "    app = create_router_graph()\n",
    "    \n",
    "    test_tickets = [\n",
    "        \"I was charged twice for my subscription last month!\",\n",
    "        \"How do I reset my password?\",\n",
    "        \"The app crashes whenever I try to upload a photo\",\n",
    "        \"What are your business hours?\",\n",
    "        \"THIS IS OUTRAGEOUS! Your service has been down for 3 hours!\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üé´ Support Ticket Router\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for ticket in test_tickets:\n",
    "        print(f\"\\nüì© Ticket: {ticket[:50]}...\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        result = app.invoke({\n",
    "            \"ticket_text\": ticket,\n",
    "            \"category\": \"\",\n",
    "            \"priority\": \"\",\n",
    "            \"response\": \"\",\n",
    "            \"needs_human\": False\n",
    "        })\n",
    "        \n",
    "        print(f\"üì§ Response: {result['response'][:100]}...\")\n",
    "        if result[\"needs_human\"]:\n",
    "            print(\"‚ö†Ô∏è  Escalated to human\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: content_moderator.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.6\n",
    "# File: content_moderator.py\n",
    "\n",
    "\"\"\"Content moderation with sequential decision gates.\n",
    "\n",
    "Demonstrates Pattern 2: Chained Decisions\n",
    "- Safety check ‚Üí Topic check ‚Üí Quality check\n",
    "- Each gate can reject or pass to next\n",
    "- Fail fast on safety violations\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# === STATE ===\n",
    "\n",
    "class ModerationState(TypedDict):\n",
    "    content: str              # Content to moderate\n",
    "    is_safe: bool             # Passes safety check?\n",
    "    is_on_topic: bool         # Relevant to platform?\n",
    "    quality_score: int        # Content quality (1-10)\n",
    "    decision: str             # Final decision\n",
    "    reason: str               # Explanation for the decision\n",
    "\n",
    "\n",
    "# === GATE 1: SAFETY CHECK ===\n",
    "\n",
    "def check_safety(state: ModerationState) -> dict:\n",
    "    \"\"\"First gate: Check for harmful content.\n",
    "    \n",
    "    This runs FIRST because there's no point checking topic or quality\n",
    "    if the content is unsafe. We fail fast on safety violations.\n",
    "    \"\"\"\n",
    "    content = state[\"content\"]\n",
    "    \n",
    "    prompt = f\"\"\"Is this content safe and appropriate? Check for:\n",
    "    - Hate speech or discrimination\n",
    "    - Violence or threats\n",
    "    - Adult content\n",
    "    - Spam or scams\n",
    "    \n",
    "    Content: {content}\n",
    "    \n",
    "    Respond with only: SAFE or UNSAFE\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    is_safe = \"SAFE\" in response.content.upper() and \"UNSAFE\" not in response.content.upper()\n",
    "    \n",
    "    print(f\"üõ°Ô∏è Safety check: {'PASS' if is_safe else 'FAIL'}\")\n",
    "    \n",
    "    return {\"is_safe\": is_safe}\n",
    "\n",
    "\n",
    "def route_after_safety(state: ModerationState) -> str:\n",
    "    \"\"\"Route based on safety check result.\"\"\"\n",
    "    if state[\"is_safe\"]:\n",
    "        return \"check_topic\"      # Continue to next gate\n",
    "    else:\n",
    "        return \"reject_unsafe\"    # Stop here, reject immediately\n",
    "\n",
    "\n",
    "# === GATE 2: TOPIC RELEVANCE ===\n",
    "\n",
    "def check_topic(state: ModerationState) -> dict:\n",
    "    \"\"\"Second gate: Check if content is on-topic.\n",
    "    \n",
    "    We only reach here if safety passed. Now we check if\n",
    "    the content belongs on our technology forum.\n",
    "    \"\"\"\n",
    "    content = state[\"content\"]\n",
    "    \n",
    "    prompt = f\"\"\"Is this content relevant to a technology discussion forum?\n",
    "    \n",
    "    Content: {content}\n",
    "    \n",
    "    Respond with only: ON_TOPIC or OFF_TOPIC\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    is_on_topic = \"ON_TOPIC\" in response.content.upper()\n",
    "    \n",
    "    print(f\"üéØ Topic check: {'PASS' if is_on_topic else 'FAIL'}\")\n",
    "    \n",
    "    return {\"is_on_topic\": is_on_topic}\n",
    "\n",
    "\n",
    "def route_after_topic(state: ModerationState) -> str:\n",
    "    \"\"\"Route based on topic relevance.\"\"\"\n",
    "    if state[\"is_on_topic\"]:\n",
    "        return \"check_quality\"     # Continue to final gate\n",
    "    else:\n",
    "        return \"reject_off_topic\"  # Wrong forum\n",
    "\n",
    "\n",
    "# === GATE 3: QUALITY ASSESSMENT ===\n",
    "\n",
    "def check_quality(state: ModerationState) -> dict:\n",
    "    \"\"\"Third gate: Assess content quality.\n",
    "    \n",
    "    Safe, on-topic content still needs to meet quality standards.\n",
    "    We use a 1-10 score for nuanced decisions:\n",
    "    - 7-10: Approve\n",
    "    - 4-6: Approve with suggestions\n",
    "    - 1-3: Reject for low quality\n",
    "    \"\"\"\n",
    "    content = state[\"content\"]\n",
    "    \n",
    "    prompt = f\"\"\"Rate this content's quality from 1-10 based on:\n",
    "    - Clarity and coherence\n",
    "    - Usefulness to others\n",
    "    - Effort and thoughtfulness\n",
    "    \n",
    "    Content: {content}\n",
    "    \n",
    "    Respond with only a number 1-10.\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # Parse the score with fallback\n",
    "    try:\n",
    "        score = int(''.join(filter(str.isdigit, response.content)))\n",
    "        score = max(1, min(10, score))  # Clamp to valid range\n",
    "    except:\n",
    "        score = 5  # Default if parsing fails\n",
    "    \n",
    "    print(f\"‚≠ê Quality score: {score}/10\")\n",
    "    \n",
    "    return {\"quality_score\": score}\n",
    "\n",
    "\n",
    "def route_after_quality(state: ModerationState) -> str:\n",
    "    \"\"\"Route based on quality score.\"\"\"\n",
    "    score = state[\"quality_score\"]\n",
    "    \n",
    "    if score >= 7:\n",
    "        return \"approve\"\n",
    "    elif score >= 4:\n",
    "        return \"approve_with_note\"\n",
    "    else:\n",
    "        return \"reject_low_quality\"\n",
    "\n",
    "\n",
    "# === TERMINAL NODES ===\n",
    "\n",
    "def approve(state: ModerationState) -> dict:\n",
    "    \"\"\"Approve high-quality content.\"\"\"\n",
    "    print(\"‚úÖ Content approved!\")\n",
    "    return {\n",
    "        \"decision\": \"APPROVED\",\n",
    "        \"reason\": \"Content meets all quality standards.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def approve_with_note(state: ModerationState) -> dict:\n",
    "    \"\"\"Approve but suggest improvements.\"\"\"\n",
    "    print(\"‚úÖ Content approved with suggestions\")\n",
    "    return {\n",
    "        \"decision\": \"APPROVED_WITH_SUGGESTIONS\",\n",
    "        \"reason\": f\"Content approved. Quality: {state['quality_score']}/10. Consider adding more detail.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def reject_unsafe(state: ModerationState) -> dict:\n",
    "    \"\"\"Reject content that failed safety check.\"\"\"\n",
    "    print(\"‚ùå Rejected: Safety violation\")\n",
    "    return {\n",
    "        \"decision\": \"REJECTED\",\n",
    "        \"reason\": \"Content violates community safety guidelines.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def reject_off_topic(state: ModerationState) -> dict:\n",
    "    \"\"\"Reject content that's not relevant.\"\"\"\n",
    "    print(\"‚ùå Rejected: Off-topic\")\n",
    "    return {\n",
    "        \"decision\": \"REJECTED\",\n",
    "        \"reason\": \"Content is not relevant to this forum.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def reject_low_quality(state: ModerationState) -> dict:\n",
    "    \"\"\"Reject content that failed quality check.\"\"\"\n",
    "    print(\"‚ùå Rejected: Low quality\")\n",
    "    return {\n",
    "        \"decision\": \"REJECTED\",\n",
    "        \"reason\": \"Content does not meet quality standards. Please add more detail.\"\n",
    "    }\n",
    "\n",
    "\n",
    "# === GRAPH BUILDER ===\n",
    "\n",
    "def create_moderation_graph():\n",
    "    \"\"\"Build the moderation pipeline.\n",
    "    \n",
    "    Visual flow:\n",
    "    safety ‚Üí (pass) ‚Üí topic ‚Üí (pass) ‚Üí quality ‚Üí approve/reject\n",
    "              ‚Üì                ‚Üì                      \n",
    "           reject           reject\n",
    "    \"\"\"\n",
    "    graph = StateGraph(ModerationState)\n",
    "    \n",
    "    # Add all nodes\n",
    "    graph.add_node(\"check_safety\", check_safety)\n",
    "    graph.add_node(\"check_topic\", check_topic)\n",
    "    graph.add_node(\"check_quality\", check_quality)\n",
    "    graph.add_node(\"approve\", approve)\n",
    "    graph.add_node(\"approve_with_note\", approve_with_note)\n",
    "    graph.add_node(\"reject_unsafe\", reject_unsafe)\n",
    "    graph.add_node(\"reject_off_topic\", reject_off_topic)\n",
    "    graph.add_node(\"reject_low_quality\", reject_low_quality)\n",
    "    \n",
    "    # Start with safety\n",
    "    graph.set_entry_point(\"check_safety\")\n",
    "    \n",
    "    # Chain the decisions - each gate leads to the next or to rejection\n",
    "    graph.add_conditional_edges(\n",
    "        \"check_safety\",\n",
    "        route_after_safety,\n",
    "        {\"check_topic\": \"check_topic\", \"reject_unsafe\": \"reject_unsafe\"}\n",
    "    )\n",
    "    \n",
    "    graph.add_conditional_edges(\n",
    "        \"check_topic\",\n",
    "        route_after_topic,\n",
    "        {\"check_quality\": \"check_quality\", \"reject_off_topic\": \"reject_off_topic\"}\n",
    "    )\n",
    "    \n",
    "    graph.add_conditional_edges(\n",
    "        \"check_quality\",\n",
    "        route_after_quality,\n",
    "        {\n",
    "            \"approve\": \"approve\",\n",
    "            \"approve_with_note\": \"approve_with_note\",\n",
    "            \"reject_low_quality\": \"reject_low_quality\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # All terminal nodes go to END\n",
    "    for node in [\"approve\", \"approve_with_note\", \"reject_unsafe\", \n",
    "                 \"reject_off_topic\", \"reject_low_quality\"]:\n",
    "        graph.add_edge(node, END)\n",
    "    \n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "# === MAIN ===\n",
    "\n",
    "def main():\n",
    "    \"\"\"Test the moderation pipeline with various content.\"\"\"\n",
    "    app = create_moderation_graph()\n",
    "    \n",
    "    test_posts = [\n",
    "        \"Here's my detailed guide on setting up Docker containers for Python development...\",\n",
    "        \"Check out this awesome new JavaScript framework I found!\",\n",
    "        \"HATE HATE HATE everyone who uses tabs instead of spaces!!!\",\n",
    "        \"Anyone want to buy cheap watches? Click here: scam.com\",\n",
    "        \"hi\",\n",
    "        \"What's your favorite recipe for chocolate chip cookies?\",\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üîç Content Moderation Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for post in test_posts:\n",
    "        print(f\"\\nüìù Post: {post[:50]}...\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        result = app.invoke({\n",
    "            \"content\": post,\n",
    "            \"is_safe\": False,\n",
    "            \"is_on_topic\": False,\n",
    "            \"quality_score\": 0,\n",
    "            \"decision\": \"\",\n",
    "            \"reason\": \"\"\n",
    "        })\n",
    "        \n",
    "        print(f\"üìã Decision: {result['decision']}\")\n",
    "        print(f\"üìã Reason: {result['reason']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 14.6 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.6.1: Email Classifier\n",
    "\n",
    "Build a graph that classifies incoming emails and routes them to specialized handlers:\n",
    "- URGENT ‚Üí Generate quick acknowledgment\n",
    "- MEETING ‚Üí Extract date, time, participants  \n",
    "- NEWSLETTER ‚Üí Archive it\n",
    "- PERSONAL ‚Üí Flag for personal review\n",
    "- SPAM ‚Üí Delete it\n",
    "\n",
    "Your graph should have:\n",
    "- One classification node\n",
    "- Five different handler nodes\n",
    "- A routing function that maps categories to handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.6.2: Multi-Stage Interview\n",
    "\n",
    "Create an interview bot with three stages:\n",
    "- Stage 1: Basic info (name, background)\n",
    "- Stage 2: Technical questions (different paths for engineer vs designer)\n",
    "- Stage 3: Behavioral questions\n",
    "\n",
    "Requirements:\n",
    "- Only advance when current stage is complete\n",
    "- Engineers and designers get different technical questions\n",
    "- End with a summary of the interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.6.3: Retry with Backoff\n",
    "\n",
    "Enhance a research assistant to handle poor-quality results:\n",
    "- If search quality is LOW, retry with a modified query\n",
    "- Track retries per search (max 2 retries)\n",
    "- If still low after retries, move on to next search\n",
    "- Add `retry_count` and `current_quality` to state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 14.7: Debugging LangGraph flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: debug_utils.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.7\n",
    "# File: debug_utils.py\n",
    "\n",
    "\"\"\"Debugging utilities for LangGraph applications.\n",
    "\n",
    "Provides decorators to add debug output to nodes and routing functions\n",
    "without cluttering the main logic.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def debug_node(name: str):\n",
    "    \"\"\"Decorator that adds debug output to any node function.\n",
    "    \n",
    "    Usage:\n",
    "        @debug_node(\"my_node\")\n",
    "        def my_node(state: MyState) -> dict:\n",
    "            ...\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(state):\n",
    "            # Print entry\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"üîµ ENTERING: {name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # Print incoming state\n",
    "            print(f\"üì• State received:\")\n",
    "            for key, value in state.items():\n",
    "                str_val = str(value)[:60] + \"...\" if len(str(value)) > 60 else str(value)\n",
    "                print(f\"   {key}: {str_val}\")\n",
    "            \n",
    "            # Call the actual function\n",
    "            result = func(state)\n",
    "            \n",
    "            # Print outgoing updates\n",
    "            print(f\"\\nüì§ Returning updates:\")\n",
    "            if result:\n",
    "                for key, value in result.items():\n",
    "                    str_val = str(value)[:60] + \"...\" if len(str(value)) > 60 else str(value)\n",
    "                    print(f\"   {key}: {str_val}\")\n",
    "            else:\n",
    "                print(\"   (no updates)\")\n",
    "            \n",
    "            print(f\"{'='*50}\\n\")\n",
    "            \n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "def debug_router(name: str):\n",
    "    \"\"\"Decorator that adds debug output to routing functions.\n",
    "    \n",
    "    Usage:\n",
    "        @debug_router(\"my_router\")\n",
    "        def my_router(state: MyState) -> str:\n",
    "            ...\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(state):\n",
    "            result = func(state)\n",
    "            print(f\"üîÄ ROUTER '{name}' decided: {result}\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    from typing import TypedDict\n",
    "    \n",
    "    class ExampleState(TypedDict):\n",
    "        message: str\n",
    "        processed: bool\n",
    "    \n",
    "    @debug_node(\"example_node\")\n",
    "    def example_node(state: ExampleState) -> dict:\n",
    "        return {\"processed\": True}\n",
    "    \n",
    "    @debug_router(\"example_router\")\n",
    "    def example_router(state: ExampleState) -> str:\n",
    "        return \"next\" if state.get(\"processed\") else \"process\"\n",
    "    \n",
    "    # Test\n",
    "    test_state = {\"message\": \"Hello\", \"processed\": False}\n",
    "    result = example_node(test_state)\n",
    "    decision = example_router(test_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: state_tracker.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.7\n",
    "# File: state_tracker.py\n",
    "\n",
    "\"\"\"Track state changes through graph execution.\n",
    "\n",
    "Captures the full state at each node for later analysis.\n",
    "Useful for debugging complex state transformations.\n",
    "\"\"\"\n",
    "\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class StateTracker:\n",
    "    \"\"\"Captures state at each node for later analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "    \n",
    "    def capture(self, node_name: str, state: dict, updates: dict = None):\n",
    "        \"\"\"Record state at a point in execution.\n",
    "        \n",
    "        Args:\n",
    "            node_name: Name of the current node\n",
    "            state: The state dictionary before updates\n",
    "            updates: The updates being returned (optional)\n",
    "        \"\"\"\n",
    "        snapshot = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"node\": node_name,\n",
    "            \"state_before\": copy.deepcopy(dict(state)),\n",
    "            \"updates\": copy.deepcopy(updates) if updates else None\n",
    "        }\n",
    "        self.history.append(snapshot)\n",
    "    \n",
    "    def print_history(self):\n",
    "        \"\"\"Print the execution history.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìú EXECUTION HISTORY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for i, snapshot in enumerate(self.history):\n",
    "            print(f\"\\n--- Step {i + 1}: {snapshot['node']} ---\")\n",
    "            print(f\"Time: {snapshot['timestamp']}\")\n",
    "            \n",
    "            if snapshot['updates']:\n",
    "                print(\"Updates made:\")\n",
    "                for key, value in snapshot['updates'].items():\n",
    "                    print(f\"  {key}: {value}\")\n",
    "    \n",
    "    def find_changes(self, field: str):\n",
    "        \"\"\"Track how a specific field changed over time.\n",
    "        \n",
    "        Args:\n",
    "            field: The state field to track\n",
    "        \"\"\"\n",
    "        print(f\"\\nüìä History of '{field}':\")\n",
    "        \n",
    "        for snapshot in self.history:\n",
    "            value = snapshot['state_before'].get(field, '<not set>')\n",
    "            update = snapshot['updates'].get(field, '<no change>') if snapshot['updates'] else '<no change>'\n",
    "            print(f\"  {snapshot['node']}: {value} ‚Üí {update}\")\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Reset the history.\"\"\"\n",
    "        self.history = []\n",
    "\n",
    "\n",
    "# Global tracker instance for easy import\n",
    "tracker = StateTracker()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulate some node executions\n",
    "    tracker.capture(\"node_1\", {\"count\": 0, \"status\": \"starting\"}, {\"count\": 1})\n",
    "    tracker.capture(\"node_2\", {\"count\": 1, \"status\": \"starting\"}, {\"status\": \"processing\"})\n",
    "    tracker.capture(\"node_3\", {\"count\": 1, \"status\": \"processing\"}, {\"count\": 2, \"status\": \"done\"})\n",
    "    \n",
    "    # Show the history\n",
    "    tracker.print_history()\n",
    "    \n",
    "    # Track a specific field\n",
    "    tracker.find_changes(\"count\")\n",
    "    tracker.find_changes(\"status\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: step_executor.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.7\n",
    "# File: step_executor.py\n",
    "\n",
    "\"\"\"Execute a graph step by step for debugging.\n",
    "\n",
    "Allows you to pause between nodes, inspect state,\n",
    "and understand the execution flow interactively.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def step_through(app, initial_state: dict):\n",
    "    \"\"\"Execute graph step by step, pausing between nodes.\n",
    "    \n",
    "    This lets you inspect state after each node.\n",
    "    \n",
    "    Args:\n",
    "        app: A compiled LangGraph application\n",
    "        initial_state: The initial state dictionary\n",
    "        \n",
    "    Returns:\n",
    "        The final state after execution, or None if stopped early\n",
    "    \"\"\"\n",
    "    print(\"\\nüêõ Step-Through Debugger\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Commands: [enter]=next, 's'=show state, 'q'=quit\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get stream of execution steps\n",
    "    step_count = 0\n",
    "    \n",
    "    for event in app.stream(initial_state):\n",
    "        step_count += 1\n",
    "        \n",
    "        # event is a dict with the node name as key\n",
    "        for node_name, node_output in event.items():\n",
    "            print(f\"\\n--- Step {step_count}: {node_name} completed ---\")\n",
    "            \n",
    "            # Show what this node returned\n",
    "            if node_output:\n",
    "                print(\"Output:\")\n",
    "                for key, value in node_output.items():\n",
    "                    str_val = str(value)[:80]\n",
    "                    print(f\"  {key}: {str_val}\")\n",
    "        \n",
    "        # Interactive prompt\n",
    "        cmd = input(\"\\n> \").strip().lower()\n",
    "        \n",
    "        if cmd == 'q':\n",
    "            print(\"Stopped by user\")\n",
    "            return None\n",
    "        elif cmd == 's':\n",
    "            print(\"\\nFull state would be shown here\")\n",
    "            # Note: Getting full state mid-stream requires checkpointing\n",
    "            # which we'll cover in Chapter 15\n",
    "    \n",
    "    print(f\"\\n‚úÖ Execution complete ({step_count} steps)\")\n",
    "    return event\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"This module provides the step_through() function.\")\n",
    "    print(\"Usage:\")\n",
    "    print(\"  from step_executor import step_through\")\n",
    "    print(\"  app = create_my_graph()\")\n",
    "    print(\"  final_state = step_through(app, initial_state)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: debug_template.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14, Section 14.7\n",
    "# File: debug_template.py\n",
    "\n",
    "\"\"\"Template for debug-ready LangGraph applications.\n",
    "\n",
    "Use this as a starting point for new graphs that include\n",
    "debugging from the start. Set DEBUG = False for production.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Debug flag - set to False in production\n",
    "DEBUG = True\n",
    "\n",
    "\n",
    "def debug_print(*args, **kwargs):\n",
    "    \"\"\"Print only if DEBUG is True.\"\"\"\n",
    "    if DEBUG:\n",
    "        print(*args, **kwargs)\n",
    "\n",
    "\n",
    "# === STATE ===\n",
    "\n",
    "class MyState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    step_count: int  # Track iterations\n",
    "\n",
    "\n",
    "# === NODES (with debug output) ===\n",
    "\n",
    "def my_node(state: MyState) -> dict:\n",
    "    debug_print(f\"\\nüîµ my_node - Entered\")\n",
    "    debug_print(f\"   Input: {state.get('input', 'N/A')[:50]}\")\n",
    "    \n",
    "    # ... your logic here ...\n",
    "    result = \"processed\"\n",
    "    \n",
    "    updates = {\n",
    "        \"output\": result,\n",
    "        \"step_count\": state.get(\"step_count\", 0) + 1\n",
    "    }\n",
    "    \n",
    "    debug_print(f\"   Output: {result[:50]}\")\n",
    "    debug_print(f\"   Step: {updates['step_count']}\")\n",
    "    \n",
    "    return updates\n",
    "\n",
    "\n",
    "# === ROUTING (with debug output) ===\n",
    "\n",
    "def route_decision(state: MyState) -> str:\n",
    "    decision = \"end\"  # Your logic here\n",
    "    \n",
    "    debug_print(f\"üîÄ route_decision: {decision}\")\n",
    "    \n",
    "    return decision\n",
    "\n",
    "\n",
    "# === GRAPH ===\n",
    "\n",
    "def create_graph():\n",
    "    graph = StateGraph(MyState)\n",
    "    \n",
    "    graph.add_node(\"my_node\", my_node)\n",
    "    graph.set_entry_point(\"my_node\")\n",
    "    \n",
    "    graph.add_conditional_edges(\n",
    "        \"my_node\",\n",
    "        route_decision,\n",
    "        {\"continue\": \"my_node\", \"end\": END}\n",
    "    )\n",
    "    \n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "# === MAIN ===\n",
    "\n",
    "def main():\n",
    "    app = create_graph()\n",
    "    \n",
    "    # Print graph structure\n",
    "    if DEBUG:\n",
    "        print(\"\\nüìä Graph Structure:\")\n",
    "        print(app.get_graph().draw_mermaid())\n",
    "    \n",
    "    initial_state = {\n",
    "        \"input\": \"test input\",\n",
    "        \"output\": \"\",\n",
    "        \"step_count\": 0\n",
    "    }\n",
    "    \n",
    "    debug_print(\"\\nüöÄ Starting execution...\")\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    debug_print(f\"\\n‚úÖ Complete! Steps: {result['step_count']}\")\n",
    "    print(f\"\\nFinal output: {result['output']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: document_analyzer_challenge.py\n",
    "\n",
    "# From: Building AI Agents, Chapter 14 Challenge Project\n",
    "# Save as: document_analyzer_challenge.py\n",
    "# Challenge: Build a Multi-Stage Document Analyzer\n",
    "\n",
    "\"\"\"\n",
    "CHAPTER 14 CHALLENGE: Multi-Stage Document Analyzer\n",
    "\n",
    "Build a sophisticated document analysis agent that demonstrates everything\n",
    "you learned in Chapter 14:\n",
    "- State design with TypedDict and Annotated[list, add]\n",
    "- Multiple nodes (at least 6)\n",
    "- Multi-way branching (4+ document types)\n",
    "- Quality-check loops with iteration limits\n",
    "- Debugging support\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Classify documents into 4+ types (technical, business, legal, academic)\n",
    "2. Route to specialized extraction nodes based on type\n",
    "3. Evaluate extraction quality and retry if needed (max 2 retries)\n",
    "4. Accumulate extracted information using Annotated[list, add]\n",
    "5. Include debug output for tracing execution\n",
    "\n",
    "YOUR TASKS:\n",
    "1. Complete the State definition\n",
    "2. Implement all node functions\n",
    "3. Create the routing function\n",
    "4. Build and compile the graph\n",
    "5. Test with the sample documents provided\n",
    "\n",
    "Good luck! üöÄ\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from operator import add\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Uncomment when ready to use LLM\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# =============================================================================\n",
    "# DEBUG FLAG - Set to True to see execution trace\n",
    "# =============================================================================\n",
    "DEBUG = True\n",
    "\n",
    "def debug_print(*args, **kwargs):\n",
    "    \"\"\"Print only when DEBUG is True.\"\"\"\n",
    "    if DEBUG:\n",
    "        print(*args, **kwargs)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STATE DEFINITION\n",
    "# =============================================================================\n",
    "\n",
    "class DocumentState(TypedDict):\n",
    "    \"\"\"State for the document analyzer.\n",
    "    \n",
    "    TODO: Complete this state definition with:\n",
    "    - document: str - The input document text\n",
    "    - doc_type: str - Classification result (technical/business/legal/academic)\n",
    "    - extracted_info: Annotated[list, add] - Accumulated extractions\n",
    "    - quality_score: float - Quality of extraction (0.0 to 1.0)\n",
    "    - iteration_count: int - Number of extraction attempts\n",
    "    - max_iterations: int - Maximum allowed attempts\n",
    "    - final_summary: str - Final analysis summary\n",
    "    \"\"\"\n",
    "    # TODO: Add your state fields here\n",
    "    pass\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# NODE FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def classify_document(state: DocumentState) -> dict:\n",
    "    \"\"\"Classify the document into one of 4 types.\n",
    "    \n",
    "    Types:\n",
    "    - technical: Research papers, technical docs, API documentation\n",
    "    - business: Reports, memos, financial documents\n",
    "    - legal: Contracts, agreements, legal notices\n",
    "    - academic: Essays, thesis, scholarly articles\n",
    "    \n",
    "    TODO: Implement classification logic\n",
    "    - Use keywords or LLM to classify\n",
    "    - Return {\"doc_type\": \"technical|business|legal|academic\"}\n",
    "    \"\"\"\n",
    "    debug_print(f\"\\n{'='*50}\")\n",
    "    debug_print(\"üîµ ENTERING: classify_document\")\n",
    "    debug_print(f\"{'='*50}\")\n",
    "    \n",
    "    document = state.get(\"document\", \"\")\n",
    "    \n",
    "    # TODO: Implement classification\n",
    "    # Hint: Look for keywords like \"abstract\", \"whereas\", \"quarterly\", \"methodology\"\n",
    "    \n",
    "    doc_type = \"technical\"  # Placeholder\n",
    "    \n",
    "    debug_print(f\"üìÑ Classified as: {doc_type}\")\n",
    "    return {\"doc_type\": doc_type}\n",
    "\n",
    "\n",
    "def extract_technical(state: DocumentState) -> dict:\n",
    "    \"\"\"Extract information from technical documents.\n",
    "    \n",
    "    Extract:\n",
    "    - Methods/approaches used\n",
    "    - Key findings\n",
    "    - Technologies mentioned\n",
    "    \n",
    "    TODO: Implement extraction logic\n",
    "    - Return {\"extracted_info\": [list of extracted items]}\n",
    "    - Increment iteration_count\n",
    "    \"\"\"\n",
    "    debug_print(f\"\\n{'='*50}\")\n",
    "    debug_print(\"üîµ ENTERING: extract_technical\")\n",
    "    debug_print(f\"{'='*50}\")\n",
    "    \n",
    "    # TODO: Implement technical extraction\n",
    "    \n",
    "    return {\n",
    "        \"extracted_info\": [\"[Technical extraction placeholder]\"],\n",
    "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_business(state: DocumentState) -> dict:\n",
    "    \"\"\"Extract information from business documents.\n",
    "    \n",
    "    Extract:\n",
    "    - Key metrics and numbers\n",
    "    - Decisions made\n",
    "    - Action items\n",
    "    \n",
    "    TODO: Implement extraction logic\n",
    "    \"\"\"\n",
    "    debug_print(f\"\\n{'='*50}\")\n",
    "    debug_print(\"üîµ ENTERING: extract_business\")\n",
    "    debug_print(f\"{'='*50}\")\n",
    "    \n",
    "    # TODO: Implement business extraction\n",
    "    \n",
    "    return {\n",
    "        \"extracted_info\": [\"[Business extraction placeholder]\"],\n",
    "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_legal(state: DocumentState) -> dict:\n",
    "    \"\"\"Extract information from legal documents.\n",
    "    \n",
    "    Extract:\n",
    "    - Parties involved\n",
    "    - Key obligations\n",
    "    - Important dates\n",
    "    \n",
    "    TODO: Implement extraction logic\n",
    "    \"\"\"\n",
    "    debug_print(f\"\\n{'='*50}\")\n",
    "    debug_print(\"üîµ ENTERING: extract_legal\")\n",
    "    debug_print(f\"{'='*50}\")\n",
    "    \n",
    "    # TODO: Implement legal extraction\n",
    "    \n",
    "    return {\n",
    "        \"extracted_info\": [\"[Legal extraction placeholder]\"],\n",
    "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_academic(state: DocumentState) -> dict:\n",
    "    \"\"\"Extract information from academic documents.\n",
    "    \n",
    "    Extract:\n",
    "    - Main thesis/argument\n",
    "    - Methodology\n",
    "    - Conclusions\n",
    "    \n",
    "    TODO: Implement extraction logic\n",
    "    \"\"\"\n",
    "    debug_print(f\"\\n{'='*50}\")\n",
    "    debug_print(\"üîµ ENTERING: extract_academic\")\n",
    "    debug_print(f\"{'='*50}\")\n",
    "    \n",
    "    # TODO: Implement academic extraction\n",
    "    \n",
    "    return {\n",
    "        \"extracted_info\": [\"[Academic extraction placeholder]\"],\n",
    "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_quality(state: DocumentState) -> dict:\n",
    "    \"\"\"Evaluate the quality of extraction.\n",
    "    \n",
    "    TODO: Implement quality evaluation\n",
    "    - Check if extracted_info is meaningful\n",
    "    - Return {\"quality_score\": 0.0 to 1.0}\n",
    "    \n",
    "    Quality criteria:\n",
    "    - At least 3 items extracted\n",
    "    - Items are not placeholders\n",
    "    - Items are relevant to doc_type\n",
    "    \"\"\"\n",
    "    debug_print(f\"\\n{'='*50}\")\n",
    "    debug_print(\"üîµ ENTERING: evaluate_quality\")\n",
    "    debug_print(f\"{'='*50}\")\n",
    "    \n",
    "    extracted = state.get(\"extracted_info\", [])\n",
    "    \n",
    "    # TODO: Implement quality scoring\n",
    "    # Placeholder: simple length-based score\n",
    "    quality_score = min(len(extracted) / 5, 1.0)\n",
    "    \n",
    "    debug_print(f\"üìä Quality score: {quality_score}\")\n",
    "    debug_print(f\"üìä Iteration: {state.get('iteration_count', 0)}\")\n",
    "    \n",
    "    return {\"quality_score\": quality_score}\n",
    "\n",
    "\n",
    "def generate_summary(state: DocumentState) -> dict:\n",
    "    \"\"\"Generate final summary of the analysis.\n",
    "    \n",
    "    TODO: Implement summary generation\n",
    "    - Combine all extracted information\n",
    "    - Create a coherent summary\n",
    "    - Return {\"final_summary\": \"...\"}\n",
    "    \"\"\"\n",
    "    debug_print(f\"\\n{'='*50}\")\n",
    "    debug_print(\"üîµ ENTERING: generate_summary\")\n",
    "    debug_print(f\"{'='*50}\")\n",
    "    \n",
    "    doc_type = state.get(\"doc_type\", \"unknown\")\n",
    "    extracted = state.get(\"extracted_info\", [])\n",
    "    \n",
    "    # TODO: Generate a meaningful summary\n",
    "    summary = f\"Analysis of {doc_type} document. Found {len(extracted)} items.\"\n",
    "    \n",
    "    debug_print(f\"üìù Summary generated\")\n",
    "    return {\"final_summary\": summary}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ROUTING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def route_by_doc_type(state: DocumentState) -> Literal[\"extract_technical\", \"extract_business\", \"extract_legal\", \"extract_academic\"]:\n",
    "    \"\"\"Route to appropriate extraction node based on document type.\n",
    "    \n",
    "    TODO: Implement routing logic\n",
    "    - Read doc_type from state\n",
    "    - Return the appropriate node name\n",
    "    \"\"\"\n",
    "    debug_print(f\"\\nüîÄ ROUTING: route_by_doc_type\")\n",
    "    \n",
    "    doc_type = state.get(\"doc_type\", \"technical\")\n",
    "    \n",
    "    # TODO: Implement routing\n",
    "    route_map = {\n",
    "        \"technical\": \"extract_technical\",\n",
    "        \"business\": \"extract_business\",\n",
    "        \"legal\": \"extract_legal\",\n",
    "        \"academic\": \"extract_academic\"\n",
    "    }\n",
    "    \n",
    "    destination = route_map.get(doc_type, \"extract_technical\")\n",
    "    debug_print(f\"   ‚Üí Going to: {destination}\")\n",
    "    \n",
    "    return destination\n",
    "\n",
    "\n",
    "def route_quality_check(state: DocumentState) -> Literal[\"generate_summary\", \"retry_extraction\"]:\n",
    "    \"\"\"Decide whether to retry extraction or proceed to summary.\n",
    "    \n",
    "    TODO: Implement quality check routing\n",
    "    - If quality_score >= 0.7, go to generate_summary\n",
    "    - If iteration_count >= max_iterations, go to generate_summary (give up)\n",
    "    - Otherwise, go to retry_extraction\n",
    "    \"\"\"\n",
    "    debug_print(f\"\\nüîÄ ROUTING: route_quality_check\")\n",
    "    \n",
    "    quality = state.get(\"quality_score\", 0)\n",
    "    iterations = state.get(\"iteration_count\", 0)\n",
    "    max_iter = state.get(\"max_iterations\", 2)\n",
    "    \n",
    "    # TODO: Implement routing logic\n",
    "    if quality >= 0.7:\n",
    "        debug_print(f\"   ‚úÖ Quality sufficient ({quality}), proceeding to summary\")\n",
    "        return \"generate_summary\"\n",
    "    elif iterations >= max_iter:\n",
    "        debug_print(f\"   ‚ö†Ô∏è Max iterations reached ({iterations}), proceeding anyway\")\n",
    "        return \"generate_summary\"\n",
    "    else:\n",
    "        debug_print(f\"   üîÑ Quality low ({quality}), retrying extraction\")\n",
    "        return \"retry_extraction\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# GRAPH CONSTRUCTION\n",
    "# =============================================================================\n",
    "\n",
    "def build_document_analyzer():\n",
    "    \"\"\"Build the document analyzer graph.\n",
    "    \n",
    "    TODO: Implement the graph structure\n",
    "    \n",
    "    Graph structure:\n",
    "    START ‚Üí classify_document ‚Üí [route_by_doc_type] ‚Üí extract_* ‚Üí evaluate_quality\n",
    "                                                                        ‚Üì\n",
    "                                                        [route_quality_check]\n",
    "                                                           ‚Üì           ‚Üì\n",
    "                                              generate_summary    retry (loop back)\n",
    "                                                      ‚Üì\n",
    "                                                     END\n",
    "    \n",
    "    Hints:\n",
    "    1. Create StateGraph with DocumentState\n",
    "    2. Add all nodes\n",
    "    3. Add edge from START to classify_document\n",
    "    4. Add conditional edges for routing\n",
    "    5. Add edge from generate_summary to END\n",
    "    6. Handle retry loop (goes back to appropriate extract_* node)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Build your graph here\n",
    "    # \n",
    "    # graph = StateGraph(DocumentState)\n",
    "    # \n",
    "    # # Add nodes\n",
    "    # graph.add_node(\"classify_document\", classify_document)\n",
    "    # graph.add_node(\"extract_technical\", extract_technical)\n",
    "    # ... add more nodes ...\n",
    "    # \n",
    "    # # Add edges\n",
    "    # graph.add_edge(START, \"classify_document\")\n",
    "    # graph.add_conditional_edges(\n",
    "    #     \"classify_document\",\n",
    "    #     route_by_doc_type,\n",
    "    #     {...}\n",
    "    # )\n",
    "    # ... add more edges ...\n",
    "    # \n",
    "    # return graph.compile()\n",
    "    \n",
    "    print(\"TODO: Implement build_document_analyzer()\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TEST DOCUMENTS\n",
    "# =============================================================================\n",
    "\n",
    "SAMPLE_DOCUMENTS = {\n",
    "    \"technical\": \"\"\"\n",
    "    Abstract: This paper presents a novel approach to natural language processing\n",
    "    using transformer architectures. We implement a BERT-based model with custom\n",
    "    attention mechanisms. Our methodology involves fine-tuning on domain-specific\n",
    "    data. Key findings show 15% improvement in accuracy. Technologies used include\n",
    "    PyTorch, Hugging Face Transformers, and CUDA for GPU acceleration.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"business\": \"\"\"\n",
    "    Q3 2024 Performance Report\n",
    "    \n",
    "    Revenue increased 23% year-over-year to $4.2M. The board has decided to\n",
    "    expand into European markets. Action items: 1) Hire regional sales manager\n",
    "    by Dec 1, 2) Complete compliance audit by Nov 15, 3) Launch marketing\n",
    "    campaign in January. Customer acquisition cost decreased to $45.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"legal\": \"\"\"\n",
    "    SERVICE AGREEMENT\n",
    "    \n",
    "    This Agreement is entered into between ABC Corporation (\"Provider\") and\n",
    "    XYZ Inc. (\"Client\") effective January 1, 2025. Provider agrees to deliver\n",
    "    consulting services as described in Exhibit A. Client shall pay $10,000\n",
    "    monthly. This agreement shall terminate on December 31, 2025. Either party\n",
    "    may terminate with 30 days written notice.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"academic\": \"\"\"\n",
    "    Introduction: This thesis examines the impact of social media on political\n",
    "    discourse. The central argument posits that algorithmic curation creates\n",
    "    echo chambers. Our methodology combines quantitative analysis of 10,000\n",
    "    posts with qualitative interviews of 50 participants. We conclude that\n",
    "    platform design significantly influences information diversity. Future\n",
    "    research should explore intervention strategies.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN - Test your implementation\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Test the document analyzer with sample documents.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìÑ DOCUMENT ANALYZER CHALLENGE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Build the graph\n",
    "    analyzer = build_document_analyzer()\n",
    "    \n",
    "    if analyzer is None:\n",
    "        print(\"\\n‚ùå Graph not implemented yet!\")\n",
    "        print(\"Complete the TODO items and try again.\")\n",
    "        return\n",
    "    \n",
    "    # Test with each document type\n",
    "    for doc_type, document in SAMPLE_DOCUMENTS.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìÑ Testing {doc_type.upper()} document\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        initial_state = {\n",
    "            \"document\": document,\n",
    "            \"doc_type\": \"\",\n",
    "            \"extracted_info\": [],\n",
    "            \"quality_score\": 0.0,\n",
    "            \"iteration_count\": 0,\n",
    "            \"max_iterations\": 2,\n",
    "            \"final_summary\": \"\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            result = analyzer.invoke(initial_state)\n",
    "            \n",
    "            print(f\"\\n‚úÖ RESULTS:\")\n",
    "            print(f\"   Document type: {result.get('doc_type')}\")\n",
    "            print(f\"   Items extracted: {len(result.get('extracted_info', []))}\")\n",
    "            print(f\"   Quality score: {result.get('quality_score')}\")\n",
    "            print(f\"   Iterations: {result.get('iteration_count')}\")\n",
    "            print(f\"   Summary: {result.get('final_summary', '')[:100]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"üèÅ Challenge complete!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 14.7 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.7.1: Add Debugging to the Ticket Router\n",
    "\n",
    "Take the ticket router from section 14.6 and add:\n",
    "- Debug output for every node\n",
    "- State tracking\n",
    "- A loop counter safety valve\n",
    "- Graph visualization at startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.7.2: Find the Bug\n",
    "\n",
    "Here's a buggy graph with 3 bugs. Use debugging techniques to find and fix:\n",
    "1. List not accumulating (missing `Annotated[list, add]`)\n",
    "2. KeyError on state access (missing `.get()` with default)\n",
    "3. Routing mismatch (return values don't match mapping keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14.7.3: Build a Debug Dashboard\n",
    "\n",
    "Create a function that produces a summary report:\n",
    "- Total nodes visited\n",
    "- Time spent\n",
    "- State changes for each field\n",
    "- Fields that never changed\n",
    "- Routing decisions made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "- Check your answers in **chapter_14_langgraph_intro_solutions.ipynb**\n",
    "- Proceed to **Chapter 15**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}