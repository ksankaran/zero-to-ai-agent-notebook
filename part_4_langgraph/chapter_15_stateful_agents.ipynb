{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15: Building Stateful Agents\n",
    "**From: Zero to AI Agent**\n",
    "\n",
    "## Overview\n",
    "In this chapter, you'll learn about:\n",
    "- Understanding agent state management\n",
    "- Defining state schemas\n",
    "- State updates and transformations\n",
    "- Checkpointing and persistence\n",
    "- Implementing retry logic\n",
    "- Handling partial failures\n",
    "- State visualization and monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.1: Understanding agent state management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: no_state_demo.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.1\n",
    "# File: no_state_demo.py\n",
    "\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class CounterState(TypedDict):\n",
    "    count: int\n",
    "\n",
    "def increment(state: CounterState) -> dict:\n",
    "    new_count = state[\"count\"] + 1\n",
    "    print(f\"Count is now: {new_count}\")\n",
    "    return {\"count\": new_count}\n",
    "\n",
    "graph = StateGraph(CounterState)\n",
    "graph.add_node(\"increment\", increment)\n",
    "graph.add_edge(START, \"increment\")\n",
    "graph.add_edge(\"increment\", END)\n",
    "\n",
    "app = graph.compile()  # No checkpointer!\n",
    "\n",
    "# Run three times\n",
    "for i in range(3):\n",
    "    result = app.invoke({\"count\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: with_state_demo.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.1\n",
    "# File: with_state_demo.py\n",
    "\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "class CounterState(TypedDict):\n",
    "    count: int\n",
    "\n",
    "def increment(state: CounterState) -> dict:\n",
    "    new_count = state[\"count\"] + 1\n",
    "    print(f\"Count is now: {new_count}\")\n",
    "    return {\"count\": new_count}\n",
    "\n",
    "graph = StateGraph(CounterState)\n",
    "graph.add_node(\"increment\", increment)\n",
    "graph.add_edge(START, \"increment\")\n",
    "graph.add_edge(\"increment\", END)\n",
    "\n",
    "# Add checkpointer!\n",
    "checkpointer = MemorySaver()\n",
    "app = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "# The secret ingredient: thread_id\n",
    "config = {\"configurable\": {\"thread_id\": \"my-counter\"}}\n",
    "\n",
    "# Run three times with SAME thread_id\n",
    "for i in range(3):\n",
    "    result = app.invoke({\"count\": 0}, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 15.1 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.1.1: Conversation Counter\n",
    "\n",
    "Build a simple agent that:\n",
    "- Tracks how many times a user has talked to it\n",
    "- Greets returning users differently from new users\n",
    "- Uses MemorySaver for persistence during the session\n",
    "\n",
    "Try invoking it multiple times with the same thread_id and see the count increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.1.2: Multi-User Tracker\n",
    "\n",
    "Create an agent that:\n",
    "- Supports multiple users (different thread_ids)\n",
    "- Tracks each user's visit count separately\n",
    "- Demonstrates that thread_ids isolate state completely\n",
    "\n",
    "Run it with \"alice\" and \"bob\" thread_ids and verify they have separate counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.1.3: State History Explorer\n",
    "\n",
    "Build a 3-node workflow that:\n",
    "- Each node adds something to the state\n",
    "- After running, use `get_state_history()` to print all snapshots\n",
    "- Show how state evolved through the graph\n",
    "\n",
    "This helps you understand how checkpointing captures every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.2: Defining state schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: well_designed_schema.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.2\n",
    "# File: well_designed_schema.py\n",
    "\n",
    "\"\"\"\n",
    "Example of a well-designed state schema.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from operator import add\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "\n",
    "# Enums for controlled values\n",
    "class AgentStatus(str, Enum):\n",
    "    IDLE = \"idle\"\n",
    "    THINKING = \"thinking\"\n",
    "    ACTING = \"acting\"\n",
    "    DONE = \"done\"\n",
    "    ERROR = \"error\"\n",
    "\n",
    "# Pydantic for validated sub-structures\n",
    "class Message(BaseModel):\n",
    "    role: str = Field(pattern=r'^(user|assistant|system)$')\n",
    "    content: str = Field(min_length=1)\n",
    "    timestamp: datetime = Field(default_factory=datetime.now)\n",
    "\n",
    "# TypedDict for LangGraph state\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Main state for the conversational agent.\n",
    "    \n",
    "    Fields marked with Annotated[..., add] accumulate across nodes.\n",
    "    Other fields are replaced with new values.\n",
    "    \"\"\"\n",
    "    # Accumulating fields\n",
    "    messages: Annotated[list[dict], add]\n",
    "    action_log: Annotated[list[str], add]\n",
    "    \n",
    "    # Replacing fields\n",
    "    status: str  # Use AgentStatus values\n",
    "    current_task: Optional[str]\n",
    "    iteration: int\n",
    "\n",
    "# Validation helper\n",
    "def validate_message(msg: dict) -> dict:\n",
    "    \"\"\"Validate and normalize a message.\"\"\"\n",
    "    validated = Message(**msg)\n",
    "    return validated.model_dump()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 15.2 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.2.1: Validated User Profile\n",
    "\n",
    "Create a Pydantic model for a user profile with:\n",
    "- Username (3-20 characters, alphanumeric only)\n",
    "- Email (valid email format)\n",
    "- Age (optional, but if provided must be 13-120)\n",
    "- Membership level (enum: \"free\", \"basic\", \"premium\")\n",
    "\n",
    "Test it with both valid and invalid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.2.2: Chat Message Validation\n",
    "\n",
    "Build a LangGraph node that:\n",
    "- Accepts raw message input\n",
    "- Validates it with Pydantic (role must be \"user\" or \"assistant\", content not empty)\n",
    "- Returns the validated message or an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.2.3: Order State Schema\n",
    "\n",
    "Design a complete state schema for an order processing agent:\n",
    "- Order with id, items list, total price, and status\n",
    "- Items with name, quantity (\\>0), and price (\\>0)\n",
    "- Status enum (pending, processing, shipped, delivered, cancelled)\n",
    "- Validation that total equals sum of item prices √ó quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.3: State updates and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: reducer_demo.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.3\n",
    "# File: reducer_demo.py\n",
    "\n",
    "\"\"\"\n",
    "Demonstrates the difference between accumulating and replacing state fields.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class State(TypedDict):\n",
    "    items: Annotated[list[str], add]  # Will accumulate\n",
    "    count: int                         # Will replace\n",
    "\n",
    "def node_a(state):\n",
    "    return {\"items\": [\"from A\"], \"count\": 1}\n",
    "\n",
    "def node_b(state):\n",
    "    return {\"items\": [\"from B\"], \"count\": 2}\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"a\", node_a)\n",
    "graph.add_node(\"b\", node_b)\n",
    "graph.add_edge(START, \"a\")\n",
    "graph.add_edge(\"a\", \"b\")\n",
    "graph.add_edge(\"b\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "result = app.invoke({\"items\": [], \"count\": 0})\n",
    "\n",
    "print(f\"items: {result['items']}\")  # ['from A', 'from B'] - accumulated!\n",
    "print(f\"count: {result['count']}\")  # 2 - replaced!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 15.3 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.3.1: Deduplicating Reducer\n",
    "\n",
    "Create a custom reducer that:\n",
    "- Accumulates messages like `add` does\n",
    "- But removes duplicates (same content)\n",
    "- Preserves the order (first occurrence wins)\n",
    "\n",
    "Test it with a graph where multiple nodes might add the same message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.3.2: Priority Queue Reducer\n",
    "\n",
    "Build a reducer that:\n",
    "- Maintains a sorted list of tasks by priority\n",
    "- Each task is `{\"task\": str, \"priority\": int}`\n",
    "- Higher priority items come first\n",
    "- New items are inserted in the correct position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.3.3: Change Tracker\n",
    "\n",
    "Create a state schema that:\n",
    "- Tracks the current value of several fields\n",
    "- Also tracks a \"changelog\" of what changed and when\n",
    "- Each node automatically logs its changes to the changelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.4: Checkpointing and persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: persistence_demo.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.4\n",
    "# File: persistence_demo.py\n",
    "\n",
    "\"\"\"\n",
    "Complete persistence demonstration.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[str], add]\n",
    "    turn: int\n",
    "\n",
    "def chat_turn(state: ChatState) -> dict:\n",
    "    turn = state[\"turn\"] + 1\n",
    "    return {\n",
    "        \"messages\": [f\"Turn {turn}: Hello!\"],\n",
    "        \"turn\": turn\n",
    "    }\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat\", chat_turn)\n",
    "graph.add_edge(START, \"chat\")\n",
    "graph.add_edge(\"chat\", END)\n",
    "\n",
    "# Run with persistence\n",
    "DB_PATH = \"chat_demo.db\"\n",
    "\n",
    "print(\"=== Session 1: Starting fresh ===\")\n",
    "with SqliteSaver.from_conn_string(DB_PATH) as saver:\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    config = {\"configurable\": {\"thread_id\": \"demo\"}}\n",
    "    \n",
    "    # Two turns\n",
    "    state = {\"messages\": [], \"turn\": 0}\n",
    "    state = app.invoke(state, config)\n",
    "    state = app.invoke(state, config)\n",
    "    \n",
    "    print(f\"Messages: {state['messages']}\")\n",
    "    print(f\"Turn: {state['turn']}\")\n",
    "\n",
    "print(\"\\n=== Session 2: Resuming after 'restart' ===\")\n",
    "with SqliteSaver.from_conn_string(DB_PATH) as saver:\n",
    "    app = graph.compile(checkpointer=saver)\n",
    "    config = {\"configurable\": {\"thread_id\": \"demo\"}}\n",
    "    \n",
    "    # Load existing state\n",
    "    existing = app.get_state(config)\n",
    "    print(f\"Loaded {existing.values['turn']} turns from disk!\")\n",
    "    \n",
    "    # Continue\n",
    "    state = app.invoke(existing.values, config)\n",
    "    print(f\"Messages: {state['messages']}\")\n",
    "    print(f\"Turn: {state['turn']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 15.4 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.4.1: Multi-User Chat System\n",
    "\n",
    "Build a chat system that:\n",
    "- Supports multiple users with separate thread IDs\n",
    "- Persists all conversations to SQLite\n",
    "- Can list all conversations for a given user\n",
    "- Shows message count and last activity per conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.4.2: Checkpoint Cleanup Utility\n",
    "\n",
    "Create a maintenance utility that:\n",
    "- Reports total checkpoints and storage size\n",
    "- Prunes old checkpoints (keep only last N per thread)\n",
    "- Runs database VACUUM to reclaim space\n",
    "- Shows before/after statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.4.3: Conversation Export Tool\n",
    "\n",
    "Build export/import functionality:\n",
    "- Export a conversation to JSON file\n",
    "- Import JSON back into a new thread\n",
    "- Support \"forking\" (copy conversation to new thread)\n",
    "- Preserve all metadata through export/import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.5: Implementing retry logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: retry_wrapper.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.5\n",
    "# File: retry_wrapper.py\n",
    "\n",
    "\"\"\"\n",
    "A reusable retry wrapper for agent nodes.\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import random\n",
    "from functools import wraps\n",
    "\n",
    "def with_retry(max_attempts: int = 3, base_delay: float = 1.0):\n",
    "    \"\"\"\n",
    "    Decorator that adds retry logic to any function.\n",
    "    \n",
    "    Usage:\n",
    "        @with_retry(max_attempts=3)\n",
    "        def my_flaky_function():\n",
    "            # might fail sometimes\n",
    "            pass\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            last_error = None\n",
    "            \n",
    "            for attempt in range(max_attempts):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    last_error = e\n",
    "                    \n",
    "                    # Don't retry on final attempt\n",
    "                    if attempt == max_attempts - 1:\n",
    "                        break\n",
    "                    \n",
    "                    # Calculate wait time\n",
    "                    wait = base_delay * (2 ** attempt)\n",
    "                    jitter = random.uniform(0, wait * 0.1)\n",
    "                    \n",
    "                    print(f\"  ‚ö†Ô∏è Attempt {attempt + 1} failed: {e}\")\n",
    "                    print(f\"  ‚è≥ Retrying in {wait + jitter:.1f}s...\")\n",
    "                    \n",
    "                    time.sleep(wait + jitter)\n",
    "            \n",
    "            # All retries exhausted\n",
    "            raise last_error\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "# Demo usage\n",
    "if __name__ == \"__main__\":\n",
    "    import random\n",
    "    \n",
    "    @with_retry(max_attempts=3, base_delay=0.5)\n",
    "    def flaky_api_call(query: str) -> str:\n",
    "        \"\"\"Simulates an API that fails 60% of the time.\"\"\"\n",
    "        if random.random() < 0.6:\n",
    "            raise ConnectionError(\"Service temporarily unavailable\")\n",
    "        return f\"Result for: {query}\"\n",
    "    \n",
    "    print(\"=== Retry Wrapper Demo ===\\n\")\n",
    "    \n",
    "    for i in range(3):\n",
    "        try:\n",
    "            result = flaky_api_call(f\"Query {i+1}\")\n",
    "            print(f\"Success: {result}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Final failure: {e}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: resilient_node.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.5\n",
    "# File: resilient_node.py\n",
    "\n",
    "\"\"\"\n",
    "A complete example of a resilient LangGraph node.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import random\n",
    "import time\n",
    "\n",
    "class TaskState(TypedDict):\n",
    "    task: str\n",
    "    result: str\n",
    "    status: str\n",
    "    attempt_log: Annotated[list[str], add]\n",
    "\n",
    "def resilient_processor(state: TaskState) -> dict:\n",
    "    \"\"\"\n",
    "    A node with built-in retry logic.\n",
    "    \n",
    "    This demonstrates the pattern without external decorators,\n",
    "    so you can see exactly what's happening.\n",
    "    \"\"\"\n",
    "    max_attempts = 3\n",
    "    base_delay = 1.0\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            # Simulate flaky operation (fails 60% of time)\n",
    "            if random.random() < 0.6:\n",
    "                raise ConnectionError(\"Simulated failure\")\n",
    "            \n",
    "            # Success!\n",
    "            return {\n",
    "                \"result\": f\"Processed: {state['task']}\",\n",
    "                \"status\": \"success\",\n",
    "                \"attempt_log\": [f\"Attempt {attempt + 1}: Success ‚úì\"]\n",
    "            }\n",
    "            \n",
    "        except ConnectionError as e:\n",
    "            log_entry = f\"Attempt {attempt + 1}: Failed - {e}\"\n",
    "            \n",
    "            if attempt < max_attempts - 1:\n",
    "                wait = base_delay * (2 ** attempt)\n",
    "                log_entry += f\" (retrying in {wait}s)\"\n",
    "                time.sleep(wait)\n",
    "            \n",
    "            if attempt == max_attempts - 1:\n",
    "                # Final attempt failed\n",
    "                return {\n",
    "                    \"result\": \"\",\n",
    "                    \"status\": \"failed\",\n",
    "                    \"attempt_log\": [log_entry + \" - giving up\"]\n",
    "                }\n",
    "            \n",
    "            # Will retry - just log this attempt\n",
    "            # (The loop continues, so we don't return yet)\n",
    "\n",
    "# Build and test\n",
    "graph = StateGraph(TaskState)\n",
    "graph.add_node(\"process\", resilient_processor)\n",
    "graph.add_edge(START, \"process\")\n",
    "graph.add_edge(\"process\", END)\n",
    "\n",
    "app = graph.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Run multiple times to see retry behavior\n",
    "print(\"=== Resilient Node Demo ===\\n\")\n",
    "\n",
    "for i in range(3):\n",
    "    config = {\"configurable\": {\"thread_id\": f\"test-{i}\"}}\n",
    "    result = app.invoke({\n",
    "        \"task\": f\"Task #{i + 1}\",\n",
    "        \"result\": \"\",\n",
    "        \"status\": \"pending\",\n",
    "        \"attempt_log\": []\n",
    "    }, config)\n",
    "    \n",
    "    print(f\"Task #{i + 1}: {result['status']}\")\n",
    "    for log in result['attempt_log']:\n",
    "        print(f\"  {log}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 15.5 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.5.1: Smart Retry Decorator\n",
    "\n",
    "Create an improved `@with_retry` decorator that:\n",
    "- Accepts a `RetryPolicy` object for configuration\n",
    "- Only retries specific exception types\n",
    "- Logs each retry attempt with timestamp\n",
    "- Returns metadata about retries alongside the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.5.2: Circuit Breaker Pattern\n",
    "\n",
    "Implement a circuit breaker that:\n",
    "- Tracks failure rate over recent calls\n",
    "- \"Opens\" (stops calling) when failure rate exceeds threshold\n",
    "- Automatically \"closes\" (resumes) after a cooldown period\n",
    "- Integrate it with a LangGraph node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.5.3: Retry Dashboard\n",
    "\n",
    "Build a simple monitoring system that:\n",
    "- Tracks retry statistics across all nodes\n",
    "- Reports which nodes fail most often\n",
    "- Shows average retry count per successful operation\n",
    "- Alerts when retry rate exceeds normal levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.6: Handling partial failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: graceful_degradation.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.6\n",
    "# File: graceful_degradation.py\n",
    "\n",
    "\"\"\"\n",
    "Graceful degradation pattern - continue with partial results when some sources fail.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class ResearchState(TypedDict):\n",
    "    query: str\n",
    "    results: Annotated[list[str], add]\n",
    "    errors: Annotated[list[str], add]\n",
    "    success_count: Annotated[int, add]  # Reducer needed for parallel updates\n",
    "    failure_count: Annotated[int, add]  # Reducer needed for parallel updates\n",
    "\n",
    "def search_source_a(state: ResearchState) -> dict:\n",
    "    \"\"\"Simulates a successful search.\"\"\"\n",
    "    return {\n",
    "        \"results\": [f\"Source A result for: {state['query']}\"],\n",
    "        \"success_count\": 1  # Return increment, reducer will sum\n",
    "    }\n",
    "\n",
    "def search_source_b(state: ResearchState) -> dict:\n",
    "    \"\"\"Simulates a failed search.\"\"\"\n",
    "    # This source is \"down\"\n",
    "    return {\n",
    "        \"errors\": [\"Source B: Connection timeout\"],\n",
    "        \"failure_count\": 1  # Return increment, reducer will sum\n",
    "    }\n",
    "\n",
    "def search_source_c(state: ResearchState) -> dict:\n",
    "    \"\"\"Simulates another successful search.\"\"\"\n",
    "    return {\n",
    "        \"results\": [f\"Source C result for: {state['query']}\"],\n",
    "        \"success_count\": 1  # Return increment, reducer will sum\n",
    "    }\n",
    "\n",
    "def summarize_results(state: ResearchState) -> dict:\n",
    "    \"\"\"Summarize what we got.\"\"\"\n",
    "    print(\"\\n=== Research Results ===\")\n",
    "    print(f\"Successful sources: {state['success_count']}\")\n",
    "    print(f\"Failed sources: {state['failure_count']}\")\n",
    "    \n",
    "    if state[\"results\"]:\n",
    "        print(\"\\nResults retrieved:\")\n",
    "        for r in state[\"results\"]:\n",
    "            print(f\"  ‚úì {r}\")\n",
    "    \n",
    "    if state[\"errors\"]:\n",
    "        print(\"\\nErrors encountered:\")\n",
    "        for e in state[\"errors\"]:\n",
    "            print(f\"  ‚úó {e}\")\n",
    "    \n",
    "    return {}\n",
    "\n",
    "# Build the graph\n",
    "graph = StateGraph(ResearchState)\n",
    "\n",
    "graph.add_node(\"source_a\", search_source_a)\n",
    "graph.add_node(\"source_b\", search_source_b)\n",
    "graph.add_node(\"source_c\", search_source_c)\n",
    "graph.add_node(\"summarize\", summarize_results)\n",
    "\n",
    "# All sources feed into summarize\n",
    "graph.add_edge(START, \"source_a\")\n",
    "graph.add_edge(START, \"source_b\")\n",
    "graph.add_edge(START, \"source_c\")\n",
    "graph.add_edge(\"source_a\", \"summarize\")\n",
    "graph.add_edge(\"source_b\", \"summarize\")\n",
    "graph.add_edge(\"source_c\", \"summarize\")\n",
    "graph.add_edge(\"summarize\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# Run it\n",
    "print(\"=== Graceful Degradation Demo ===\")\n",
    "result = app.invoke({\n",
    "    \"query\": \"AI agents\",\n",
    "    \"results\": [],\n",
    "    \"errors\": [],\n",
    "    \"success_count\": 0,\n",
    "    \"failure_count\": 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: fault_tolerant_node.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.6\n",
    "# File: fault_tolerant_node.py\n",
    "\n",
    "\"\"\"\n",
    "Pattern for fault-tolerant nodes.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import random\n",
    "\n",
    "class RobustState(TypedDict):\n",
    "    input: str\n",
    "    results: Annotated[list[dict], add]\n",
    "    warnings: Annotated[list[str], add]\n",
    "\n",
    "def fault_tolerant_operation(\n",
    "    name: str,\n",
    "    operation: callable,\n",
    "    fallback_value: any = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrap an operation with fault tolerance.\n",
    "    \n",
    "    Returns a node function that:\n",
    "    - Tries the operation\n",
    "    - Falls back on failure\n",
    "    - Always returns useful state\n",
    "    \"\"\"\n",
    "    def node(state: RobustState) -> dict:\n",
    "        try:\n",
    "            result = operation(state)\n",
    "            return {\n",
    "                \"results\": [{\"source\": name, \"data\": result, \"status\": \"ok\"}]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"results\": [{\"source\": name, \"data\": fallback_value, \"status\": \"failed\"}],\n",
    "                \"warnings\": [f\"{name}: {str(e)}\"]\n",
    "            }\n",
    "    return node\n",
    "\n",
    "# Example operations (some will fail randomly)\n",
    "def flaky_api(state):\n",
    "    if random.random() < 0.5:\n",
    "        raise ConnectionError(\"Service unavailable\")\n",
    "    return f\"API data for {state['input']}\"\n",
    "\n",
    "def reliable_cache(state):\n",
    "    return f\"Cached data for {state['input']}\"\n",
    "\n",
    "def sometimes_slow(state):\n",
    "    if random.random() < 0.3:\n",
    "        raise TimeoutError(\"Request timed out\")\n",
    "    return f\"Fresh data for {state['input']}\"\n",
    "\n",
    "# Build graph with fault-tolerant nodes\n",
    "graph = StateGraph(RobustState)\n",
    "\n",
    "graph.add_node(\"api\", fault_tolerant_operation(\"API\", flaky_api, \"N/A\"))\n",
    "graph.add_node(\"cache\", fault_tolerant_operation(\"Cache\", reliable_cache, \"N/A\"))\n",
    "graph.add_node(\"fresh\", fault_tolerant_operation(\"Fresh\", sometimes_slow, \"N/A\"))\n",
    "\n",
    "graph.add_edge(START, \"api\")\n",
    "graph.add_edge(\"api\", \"cache\")\n",
    "graph.add_edge(\"cache\", \"fresh\")\n",
    "graph.add_edge(\"fresh\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# Test it multiple times\n",
    "print(\"=== Fault Tolerant Node Demo ===\\n\")\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    result = app.invoke({\"input\": \"test query\", \"results\": [], \"warnings\": []})\n",
    "    \n",
    "    for r in result[\"results\"]:\n",
    "        status = \"‚úì\" if r[\"status\"] == \"ok\" else \"‚úó\"\n",
    "        print(f\"  {status} {r['source']}: {r['data']}\")\n",
    "    \n",
    "    if result[\"warnings\"]:\n",
    "        print(\"  Warnings:\")\n",
    "        for w in result[\"warnings\"]:\n",
    "            print(f\"    ‚ö†Ô∏è {w}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 15.6 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.6.1: Multi-Source Aggregator\n",
    "\n",
    "Build an agent that:\n",
    "- Queries 4 different \"data sources\" (simulate with functions)\n",
    "- 2 sources randomly fail\n",
    "- Aggregates successful results\n",
    "- Reports which sources failed and why\n",
    "- Returns a confidence score based on how many succeeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.6.2: Fallback Chain\n",
    "\n",
    "Create a node with a chain of fallbacks:\n",
    "- Try primary API (fails 70% of the time)\n",
    "- If that fails, try secondary API (fails 40% of the time)\n",
    "- If that fails, try cache (always succeeds but data is \"stale\")\n",
    "- Track which source ultimately provided the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.6.3: Graceful Feature Degradation\n",
    "\n",
    "Build a \"document analyzer\" that:\n",
    "- Always extracts word count (core feature)\n",
    "- Optionally analyzes sentiment (fails sometimes)\n",
    "- Optionally extracts keywords (fails sometimes)\n",
    "- Optionally summarizes (fails sometimes)\n",
    "- Returns whatever it could compute with clear status for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15.7: State visualization and monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: state_monitor.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.7\n",
    "# File: state_monitor.py\n",
    "\n",
    "\"\"\"\n",
    "Simple state monitoring for LangGraph agents.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "\n",
    "class StateMonitor:\n",
    "    \"\"\"Track state changes over time.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"Agent\"):\n",
    "        self.name = name\n",
    "        self.history = []\n",
    "        self.start_time = datetime.now()\n",
    "    \n",
    "    def record(self, node_name: str, state: dict):\n",
    "        \"\"\"Record state after a node runs.\"\"\"\n",
    "        entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"elapsed\": (datetime.now() - self.start_time).total_seconds(),\n",
    "            \"node\": node_name,\n",
    "            \"state_snapshot\": {k: self._summarize(v) for k, v in state.items()}\n",
    "        }\n",
    "        self.history.append(entry)\n",
    "    \n",
    "    def _summarize(self, value: Any) -> str:\n",
    "        \"\"\"Create a short summary of a value.\"\"\"\n",
    "        if isinstance(value, list):\n",
    "            return f\"list[{len(value)}]\"\n",
    "        elif isinstance(value, dict):\n",
    "            return f\"dict[{len(value)}]\"\n",
    "        elif isinstance(value, str) and len(value) > 30:\n",
    "            return f'\"{value[:30]}...\"'\n",
    "        return repr(value)\n",
    "    \n",
    "    def report(self):\n",
    "        \"\"\"Print a summary report.\"\"\"\n",
    "        print(f\"\\n{'‚ïê' * 50}\")\n",
    "        print(f\"üìà Monitor Report: {self.name}\")\n",
    "        print(f\"{'‚ïê' * 50}\")\n",
    "        print(f\"Total nodes executed: {len(self.history)}\")\n",
    "        print(f\"Total time: {self.history[-1]['elapsed']:.2f}s\" if self.history else \"N/A\")\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ' * 50}\")\n",
    "        print(\"Execution Timeline:\")\n",
    "        print(f\"{'‚îÄ' * 50}\")\n",
    "        \n",
    "        for entry in self.history:\n",
    "            print(f\"  [{entry['elapsed']:5.2f}s] {entry['node']}\")\n",
    "            for key, summary in entry['state_snapshot'].items():\n",
    "                print(f\"           {key}: {summary}\")\n",
    "        \n",
    "        print(f\"{'‚ïê' * 50}\\n\")\n",
    "\n",
    "\n",
    "def monitored_node(monitor: StateMonitor, original_func, node_name: str):\n",
    "    \"\"\"Wrap a node with monitoring.\"\"\"\n",
    "    def wrapper(state):\n",
    "        result = original_func(state)\n",
    "        # Merge result with state for recording\n",
    "        new_state = {**state, **result}\n",
    "        monitor.record(node_name, new_state)\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def visualize_history(history: list[dict]):\n",
    "    \"\"\"Create ASCII timeline of state changes.\"\"\"\n",
    "    print(\"\\nüìú State Evolution Timeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, snapshot in enumerate(history):\n",
    "        # Header\n",
    "        node = snapshot.get(\"node\", f\"Step {i}\")\n",
    "        print(f\"\\n‚îå‚îÄ {node} {'‚îÄ' * (55 - len(node))}\")\n",
    "        \n",
    "        # State changes\n",
    "        state = snapshot.get(\"state_snapshot\", {})\n",
    "        for key, value in state.items():\n",
    "            print(f\"‚îÇ  {key}: {value}\")\n",
    "        \n",
    "        # Connector to next\n",
    "        if i < len(history) - 1:\n",
    "            print(\"‚îÇ\")\n",
    "            print(\"‚ñº\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "# Demo\n",
    "if __name__ == \"__main__\":\n",
    "    monitor = StateMonitor(\"Demo Agent\")\n",
    "    \n",
    "    # Simulate some state changes\n",
    "    monitor.record(\"start\", {\"query\": \"test\", \"messages\": []})\n",
    "    monitor.record(\"process\", {\"query\": \"test\", \"messages\": [\"Hello\"], \"status\": \"processing\"})\n",
    "    monitor.record(\"complete\", {\"query\": \"test\", \"messages\": [\"Hello\", \"Done\"], \"status\": \"complete\"})\n",
    "    \n",
    "    monitor.report()\n",
    "    visualize_history(monitor.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: metrics_tracker.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.7\n",
    "# File: metrics_tracker.py\n",
    "\n",
    "\"\"\"\n",
    "Track operational metrics for agents.\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "class MetricsTracker:\n",
    "    \"\"\"Track operational metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.counters = defaultdict(int)\n",
    "        self.timings = defaultdict(list)\n",
    "        self.errors = []\n",
    "    \n",
    "    def increment(self, metric: str, amount: int = 1):\n",
    "        \"\"\"Increment a counter.\"\"\"\n",
    "        self.counters[metric] += amount\n",
    "    \n",
    "    def record_timing(self, operation: str, duration: float):\n",
    "        \"\"\"Record how long something took.\"\"\"\n",
    "        self.timings[operation].append(duration)\n",
    "    \n",
    "    def record_error(self, node: str, error: str):\n",
    "        \"\"\"Record an error.\"\"\"\n",
    "        self.errors.append({\n",
    "            \"time\": datetime.now().isoformat(),\n",
    "            \"node\": node,\n",
    "            \"error\": error\n",
    "        })\n",
    "        self.increment(\"total_errors\")\n",
    "    \n",
    "    def summary(self) -> dict:\n",
    "        \"\"\"Get metrics summary.\"\"\"\n",
    "        timing_stats = {}\n",
    "        for op, times in self.timings.items():\n",
    "            timing_stats[op] = {\n",
    "                \"count\": len(times),\n",
    "                \"avg\": sum(times) / len(times) if times else 0,\n",
    "                \"max\": max(times) if times else 0\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"counters\": dict(self.counters),\n",
    "            \"timings\": timing_stats,\n",
    "            \"error_count\": len(self.errors),\n",
    "            \"recent_errors\": self.errors[-5:]  # Last 5 errors\n",
    "        }\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print formatted summary.\"\"\"\n",
    "        s = self.summary()\n",
    "        \n",
    "        print(\"\\nüìä Metrics Summary\")\n",
    "        print(\"‚îÄ\" * 40)\n",
    "        \n",
    "        print(\"\\nCounters:\")\n",
    "        for name, value in s[\"counters\"].items():\n",
    "            print(f\"  {name}: {value}\")\n",
    "        \n",
    "        print(\"\\nTimings:\")\n",
    "        for op, stats in s[\"timings\"].items():\n",
    "            print(f\"  {op}: avg={stats['avg']:.3f}s, max={stats['max']:.3f}s ({stats['count']} calls)\")\n",
    "        \n",
    "        if s[\"recent_errors\"]:\n",
    "            print(f\"\\nRecent Errors ({s['error_count']} total):\")\n",
    "            for err in s[\"recent_errors\"]:\n",
    "                print(f\"  [{err['node']}] {err['error']}\")\n",
    "\n",
    "\n",
    "# Demo\n",
    "if __name__ == \"__main__\":\n",
    "    import random\n",
    "    import time\n",
    "    \n",
    "    tracker = MetricsTracker()\n",
    "    \n",
    "    # Simulate some operations\n",
    "    print(\"=== Metrics Tracker Demo ===\\n\")\n",
    "    \n",
    "    for i in range(5):\n",
    "        # Track API calls\n",
    "        tracker.increment(\"api_calls\")\n",
    "        duration = random.uniform(0.1, 0.5)\n",
    "        tracker.record_timing(\"api_call\", duration)\n",
    "        \n",
    "        # Some failures\n",
    "        if random.random() < 0.3:\n",
    "            tracker.record_error(\"api_node\", \"Connection timeout\")\n",
    "        \n",
    "        # Track processed items\n",
    "        tracker.increment(\"items_processed\", random.randint(1, 10))\n",
    "    \n",
    "    tracker.print_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: monitored_agent.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 15, Section 15.7\n",
    "# File: monitored_agent.py\n",
    "\n",
    "\"\"\"\n",
    "Example agent with monitoring.\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    steps: Annotated[list[str], add]\n",
    "    result: str\n",
    "\n",
    "# Simple metrics\n",
    "metrics = {\"nodes_run\": 0, \"total_time\": 0.0}\n",
    "\n",
    "def timed_node(name: str):\n",
    "    \"\"\"Decorator to add timing to nodes.\"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(state):\n",
    "            start = time.time()\n",
    "            result = func(state)\n",
    "            elapsed = time.time() - start\n",
    "            \n",
    "            metrics[\"nodes_run\"] += 1\n",
    "            metrics[\"total_time\"] += elapsed\n",
    "            \n",
    "            print(f\"  ‚úì {name} ({elapsed:.3f}s)\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@timed_node(\"analyze\")\n",
    "def analyze(state: AgentState) -> dict:\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    return {\"steps\": [f\"Analyzed: {state['task']}\"]}\n",
    "\n",
    "@timed_node(\"process\")\n",
    "def process(state: AgentState) -> dict:\n",
    "    time.sleep(0.2)  # Simulate work\n",
    "    return {\"steps\": [\"Processed data\"]}\n",
    "\n",
    "@timed_node(\"complete\")\n",
    "def complete(state: AgentState) -> dict:\n",
    "    time.sleep(0.05)  # Simulate work\n",
    "    return {\"result\": \"Done!\", \"steps\": [\"Completed\"]}\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"analyze\", analyze)\n",
    "graph.add_node(\"process\", process)\n",
    "graph.add_node(\"complete\", complete)\n",
    "graph.add_edge(START, \"analyze\")\n",
    "graph.add_edge(\"analyze\", \"process\")\n",
    "graph.add_edge(\"process\", \"complete\")\n",
    "graph.add_edge(\"complete\", END)\n",
    "\n",
    "app = graph.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Run with monitoring\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Running monitored agent...\\n\")\n",
    "    config = {\"configurable\": {\"thread_id\": \"monitored-run\"}}\n",
    "    \n",
    "    result = app.invoke({\n",
    "        \"task\": \"Process important data\",\n",
    "        \"steps\": [],\n",
    "        \"result\": \"\"\n",
    "    }, config)\n",
    "    \n",
    "    # Report\n",
    "    print(f\"\\nüìä Metrics:\")\n",
    "    print(f\"  Nodes run: {metrics['nodes_run']}\")\n",
    "    print(f\"  Total time: {metrics['total_time']:.3f}s\")\n",
    "    print(f\"\\n‚úÖ Result: {result['result']}\")\n",
    "    print(f\"üìù Steps: {result['steps']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: task_manager_challenge.py\n",
    "\n",
    "\"\"\"\n",
    "Chapter 15 Challenge: Persistent Task Manager Agent\n",
    "\n",
    "Build a complete task management agent that demonstrates:\n",
    "- State schemas with Pydantic validation (15.2)\n",
    "- State management with reducers (15.3)\n",
    "- SQLite persistence (15.4)\n",
    "- Retry logic for external sync (15.5)\n",
    "- Graceful failure handling (15.6)\n",
    "- Monitoring and health checks (15.7)\n",
    "\n",
    "Commands:\n",
    "- add <title>      : Add a new task\n",
    "- complete <id>    : Mark task as complete\n",
    "- list             : Show all tasks\n",
    "- stats            : Show task statistics\n",
    "- history          : Show action history\n",
    "- health           : Run health check\n",
    "- quit             : Exit (tasks persist!)\n",
    "\n",
    "Run this file, add some tasks, quit, run again - your tasks should still be there!\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from operator import add\n",
    "import uuid\n",
    "import time\n",
    "import random\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 1: Enums and Models (15.2 - State Schemas)\n",
    "# =============================================================================\n",
    "\n",
    "# TODO: Define TaskStatus enum with values: pending, in_progress, completed, failed\n",
    "class TaskStatus(str, Enum):\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "# TODO: Define TaskPriority enum with values: low, medium, high, urgent\n",
    "class TaskPriority(str, Enum):\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "# TODO: Define Task Pydantic model with validation\n",
    "# Fields needed: id (str), title (str), description (str), status (TaskStatus), \n",
    "#                priority (TaskPriority), created_at (datetime)\n",
    "# Add a validator that ensures title is not empty\n",
    "class Task(BaseModel):\n",
    "    \"\"\"A task with validation.\"\"\"\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 2: State Schema with Reducers (15.3 - State Transformations)\n",
    "# =============================================================================\n",
    "\n",
    "# TODO: Define a reducer function for accumulating tasks\n",
    "# Hint: Should merge existing tasks with new tasks, updating if same ID exists\n",
    "def task_reducer(existing: list[dict], new: list[dict]) -> list[dict]:\n",
    "    \"\"\"Merge task lists, updating existing tasks by ID.\"\"\"\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "# TODO: Define TaskManagerState TypedDict with:\n",
    "# - tasks: list of task dicts (use Annotated with task_reducer)\n",
    "# - action_history: list of strings (use Annotated with add for accumulation)\n",
    "# - last_error: optional string\n",
    "# - pending_command: optional string\n",
    "class TaskManagerState(TypedDict):\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 3: Monitoring (15.7 - Visualization and Monitoring)\n",
    "# =============================================================================\n",
    "\n",
    "class TaskMonitor:\n",
    "    \"\"\"Track operations and metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.operations = []\n",
    "        self.start_time = datetime.now()\n",
    "    \n",
    "    # TODO: Implement log_operation to record operations with timestamps\n",
    "    def log_operation(self, operation: str, details: str = \"\"):\n",
    "        \"\"\"Log an operation with timestamp.\"\"\"\n",
    "        pass  # Your code here\n",
    "    \n",
    "    # TODO: Implement get_report to return formatted monitoring report\n",
    "    def get_report(self) -> str:\n",
    "        \"\"\"Get monitoring report.\"\"\"\n",
    "        pass  # Your code here\n",
    "\n",
    "\n",
    "# Global monitor instance\n",
    "monitor = TaskMonitor()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 4: Helper Functions\n",
    "# =============================================================================\n",
    "\n",
    "def create_task(title: str, description: str = \"\", priority: str = \"medium\") -> dict:\n",
    "    \"\"\"Create a new task with validation.\"\"\"\n",
    "    # TODO: Create and validate a Task using Pydantic, return as dict\n",
    "    # Handle validation errors gracefully\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "def format_task(task: dict) -> str:\n",
    "    \"\"\"Format a task for display.\"\"\"\n",
    "    status_icons = {\n",
    "        \"pending\": \"‚è≥\",\n",
    "        \"in_progress\": \"üîÑ\", \n",
    "        \"completed\": \"‚úÖ\",\n",
    "        \"failed\": \"‚ùå\"\n",
    "    }\n",
    "    priority_icons = {\n",
    "        \"low\": \"üîµ\",\n",
    "        \"medium\": \"üü°\",\n",
    "        \"high\": \"üü†\",\n",
    "        \"urgent\": \"üî¥\"\n",
    "    }\n",
    "    \n",
    "    icon = status_icons.get(task.get(\"status\", \"pending\"), \"‚ùì\")\n",
    "    pri = priority_icons.get(task.get(\"priority\", \"medium\"), \"‚ö™\")\n",
    "    \n",
    "    return f\"{icon} {pri} [{task['id'][:8]}] {task['title']}\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 5: Graph Nodes (15.1 - State Management)\n",
    "# =============================================================================\n",
    "\n",
    "def parse_command(state: TaskManagerState) -> dict:\n",
    "    \"\"\"Parse the pending command and route appropriately.\"\"\"\n",
    "    command = state.get(\"pending_command\", \"\")\n",
    "    \n",
    "    # TODO: Parse command and return appropriate routing info\n",
    "    # Commands: add, complete, list, stats, history, health\n",
    "    # Return dict with parsed info for next node\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "def add_task_node(state: TaskManagerState) -> dict:\n",
    "    \"\"\"Add a new task to the state.\"\"\"\n",
    "    # TODO: Extract task info from pending_command\n",
    "    # Create task, log operation, return state update\n",
    "    # Remember: return {\"tasks\": [new_task_dict], \"action_history\": [...]}\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "def complete_task_node(state: TaskManagerState) -> dict:\n",
    "    \"\"\"Mark a task as completed.\"\"\"\n",
    "    # TODO: Find task by ID prefix, update status to completed\n",
    "    # Handle case where task not found\n",
    "    # Log operation, return state update\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "def list_tasks_node(state: TaskManagerState) -> dict:\n",
    "    \"\"\"Display all tasks.\"\"\"\n",
    "    tasks = state.get(\"tasks\", [])\n",
    "    \n",
    "    if not tasks:\n",
    "        print(\"\\nüìã No tasks yet! Use 'add <title>' to create one.\")\n",
    "    else:\n",
    "        print(f\"\\nüìã Tasks ({len(tasks)}):\")\n",
    "        print(\"-\" * 40)\n",
    "        for task in tasks:\n",
    "            print(f\"  {format_task(task)}\")\n",
    "    \n",
    "    return {\"action_history\": [f\"Listed {len(tasks)} tasks\"]}\n",
    "\n",
    "\n",
    "def stats_node(state: TaskManagerState) -> dict:\n",
    "    \"\"\"Show task statistics.\"\"\"\n",
    "    tasks = state.get(\"tasks\", [])\n",
    "    \n",
    "    # TODO: Calculate and display statistics:\n",
    "    # - Total tasks\n",
    "    # - Tasks by status (pending, completed, etc.)\n",
    "    # - Tasks by priority\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "def history_node(state: TaskManagerState) -> dict:\n",
    "    \"\"\"Show action history.\"\"\"\n",
    "    history = state.get(\"action_history\", [])\n",
    "    \n",
    "    print(f\"\\nüìú Action History ({len(history)} actions):\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, action in enumerate(history[-10:], 1):  # Last 10 actions\n",
    "        print(f\"  {i}. {action}\")\n",
    "    \n",
    "    return {}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 6: Retry Logic for External Sync (15.5 - Retry Logic)\n",
    "# =============================================================================\n",
    "\n",
    "def sync_tasks_node(state: TaskManagerState) -> dict:\n",
    "    \"\"\"\n",
    "    Simulate syncing tasks to an external service.\n",
    "    This demonstrates retry logic for transient failures.\n",
    "    \"\"\"\n",
    "    # TODO: Implement retry logic with exponential backoff\n",
    "    # Simulate a flaky external API (random failures)\n",
    "    # Use max_retries=3, base_delay=0.5\n",
    "    # On success: return success message in action_history\n",
    "    # On failure after retries: return error in last_error, don't crash\n",
    "    \n",
    "    max_retries = 3\n",
    "    base_delay = 0.5\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Simulate flaky API (30% chance of failure)\n",
    "            if random.random() < 0.3:\n",
    "                raise ConnectionError(\"Sync service unavailable\")\n",
    "            \n",
    "            # Success!\n",
    "            task_count = len(state.get(\"tasks\", []))\n",
    "            monitor.log_operation(\"sync\", f\"Synced {task_count} tasks\")\n",
    "            print(f\"  ‚úÖ Synced {task_count} tasks to cloud\")\n",
    "            return {\"action_history\": [f\"Synced {task_count} tasks successfully\"]}\n",
    "            \n",
    "        except ConnectionError as e:\n",
    "            # TODO: Implement exponential backoff with jitter\n",
    "            # Log the retry attempt\n",
    "            # If last attempt, handle gracefully (don't crash)\n",
    "            pass  # Your code here\n",
    "    \n",
    "    # All retries failed\n",
    "    return {\n",
    "        \"last_error\": \"Sync failed after 3 attempts\",\n",
    "        \"action_history\": [\"Sync failed - will retry later\"]\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 7: Health Check (15.7 - Monitoring)\n",
    "# =============================================================================\n",
    "\n",
    "def health_check_node(state: TaskManagerState) -> dict:\n",
    "    \"\"\"Run health checks on the agent.\"\"\"\n",
    "    # TODO: Implement health checks that verify:\n",
    "    # - State is accessible\n",
    "    # - No recent errors\n",
    "    # - Task counts are consistent\n",
    "    # Print formatted health report\n",
    "    pass  # Your code here\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 8: Graph Construction\n",
    "# =============================================================================\n",
    "\n",
    "def route_command(state: TaskManagerState) -> str:\n",
    "    \"\"\"Route to appropriate node based on command.\"\"\"\n",
    "    command = state.get(\"pending_command\", \"\").lower().split()[0] if state.get(\"pending_command\") else \"\"\n",
    "    \n",
    "    routes = {\n",
    "        \"add\": \"add_task\",\n",
    "        \"complete\": \"complete_task\",\n",
    "        \"list\": \"list_tasks\",\n",
    "        \"stats\": \"stats\",\n",
    "        \"history\": \"history\",\n",
    "        \"health\": \"health_check\",\n",
    "        \"sync\": \"sync_tasks\",\n",
    "    }\n",
    "    \n",
    "    return routes.get(command, \"list_tasks\")\n",
    "\n",
    "\n",
    "def build_graph() -> StateGraph:\n",
    "    \"\"\"Build the task manager graph.\"\"\"\n",
    "    # TODO: Create StateGraph with TaskManagerState\n",
    "    # Add all nodes: add_task, complete_task, list_tasks, stats, history, health_check, sync_tasks\n",
    "    # Add conditional routing from START based on command\n",
    "    # All nodes should route to END\n",
    "    \n",
    "    builder = StateGraph(TaskManagerState)\n",
    "    \n",
    "    # Add nodes\n",
    "    # builder.add_node(\"add_task\", add_task_node)\n",
    "    # ... add other nodes\n",
    "    \n",
    "    # Add conditional entry point\n",
    "    # builder.add_conditional_edges(START, route_command, {...})\n",
    "    \n",
    "    # Add edges to END\n",
    "    # builder.add_edge(\"add_task\", END)\n",
    "    # ... add other edges\n",
    "    \n",
    "    pass  # Your code here - return builder.compile(checkpointer=...)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 9: Main Loop with Persistence (15.4 - Checkpointing)\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point with SQLite persistence.\"\"\"\n",
    "    print(\"üóÇÔ∏è  Task Manager Agent\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Commands: add, complete, list, stats, history, health, sync, quit\")\n",
    "    print(\"Your tasks persist across restarts!\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # TODO: Set up SQLite persistence\n",
    "    # Hint: Use SqliteSaver and pass to graph compilation\n",
    "    db_path = \"task_manager.db\"\n",
    "    \n",
    "    # TODO: Build graph with checkpointer\n",
    "    # app = build_graph()\n",
    "    \n",
    "    # TODO: Set up config with thread_id for user isolation\n",
    "    # Support multiple users by changing thread_id\n",
    "    user_id = input(\"\\nEnter your user ID (or press Enter for 'default'): \").strip() or \"default\"\n",
    "    config = {\"configurable\": {\"thread_id\": f\"user_{user_id}\"}}\n",
    "    \n",
    "    print(f\"\\nüë§ Logged in as: {user_id}\")\n",
    "    \n",
    "    # Try to load existing state\n",
    "    # TODO: Check if user has existing tasks and show count\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            command = input(\"\\n> \").strip()\n",
    "            \n",
    "            if not command:\n",
    "                continue\n",
    "            \n",
    "            if command.lower() == \"quit\":\n",
    "                print(\"\\nüëã Goodbye! Your tasks are saved.\")\n",
    "                break\n",
    "            \n",
    "            # TODO: Invoke graph with command\n",
    "            # result = app.invoke({\"pending_command\": command}, config)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nüëã Goodbye! Your tasks are saved.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {e}\")\n",
    "            monitor.log_operation(\"error\", str(e))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 15.7 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.7.1: State Diff Viewer\n",
    "\n",
    "Build a tool that:\n",
    "- Compares two state snapshots\n",
    "- Shows what changed between them (added, removed, modified)\n",
    "- Formats the diff in a readable way\n",
    "- Highlights significant changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.7.2: Performance Dashboard\n",
    "\n",
    "Create a monitoring dashboard that tracks:\n",
    "- Node execution counts\n",
    "- Average time per node\n",
    "- Success/failure rates per node\n",
    "- Slowest nodes ranking\n",
    "- Print a formatted report after each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15.7.3: Alert System\n",
    "\n",
    "Build a simple alerting system that:\n",
    "- Monitors metrics against thresholds\n",
    "- Triggers alerts when thresholds exceeded (e.g., error rate \\> 10%)\n",
    "- Tracks alert history\n",
    "- Supports different severity levels (warning, critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "- Check your answers in **chapter_15_stateful_agents_solutions.ipynb**\n",
    "- Proceed to **Chapter 16**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}