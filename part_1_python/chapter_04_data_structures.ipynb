{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Data Structures\n",
    "**From: Zero to AI Agent**\n",
    "\n",
    "## Overview\n",
    "In this chapter, you'll learn about:\n",
    "- Lists: creation, indexing, and slicing\n",
    "- List methods and operations\n",
    "- Tuples and their immutability\n",
    "- Dictionaries: key-value pairs\n",
    "- Sets and their operations\n",
    "- Choosing the right data structure\n",
    "- List comprehensions (gentle introduction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4.1: Lists: creation, indexing, and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: first_list.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.1\n",
    "# first_list.py - Creating your first lists\n",
    "\n",
    "# Let's organize our data!\n",
    "# Navigate to your folder first\n",
    "# ~/Desktop/ai_agents_complete/part_1_python/chapter_04_data_structures/\n",
    "\n",
    "# Creating your first list\n",
    "favorite_numbers = [7, 42, 13, 99, 3.14]\n",
    "print(\"My favorite numbers:\", favorite_numbers)\n",
    "\n",
    "# Lists can hold different types of data\n",
    "mixed_bag = [42, \"hello\", 3.14, True, \"Python\"]\n",
    "print(\"A list with different types:\", mixed_bag)\n",
    "\n",
    "# Even an empty list (like an empty toy box, ready to be filled!)\n",
    "empty_list = []\n",
    "print(\"An empty list:\", empty_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: creating_lists.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.1\n",
    "# creating_lists.py - All the ways to create lists\n",
    "\n",
    "# Method 1: Direct creation (what we just did)\n",
    "colors = [\"red\", \"blue\", \"green\", \"yellow\"]\n",
    "print(\"Method 1 - Direct creation:\", colors)\n",
    "\n",
    "# Method 2: Creating from a string\n",
    "sentence = \"Python is amazing\"\n",
    "words = sentence.split()  # Splits the string into a list of words\n",
    "print(\"Method 2 - From string:\", words)\n",
    "\n",
    "# Method 3: Using the list() function\n",
    "numbers_string = \"12345\"\n",
    "digits = list(numbers_string)  # Converts each character to a list item\n",
    "print(\"Method 3 - Using list():\", digits)\n",
    "\n",
    "# Method 4: Creating with range() - remember this from loops?\n",
    "counting = list(range(1, 11))  # Numbers 1 through 10\n",
    "print(\"Method 4 - Using range():\", counting)\n",
    "\n",
    "# Method 5: Repeating elements\n",
    "lots_of_zeros = [0] * 5  # Creates [0, 0, 0, 0, 0]\n",
    "print(\"Method 5 - Repetition:\", lots_of_zeros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: list_indexing.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.1\n",
    "# list_indexing.py - Accessing list elements with indexing\n",
    "\n",
    "# Let's create a list of AI terms we'll be using later\n",
    "ai_terms = [\"neural\", \"network\", \"training\", \"model\", \"agent\", \"prompt\"]\n",
    "\n",
    "# Accessing items by their index (position)\n",
    "first_term = ai_terms[0]   # Gets \"neural\" (index 0)\n",
    "third_term = ai_terms[2]   # Gets \"training\" (index 2)\n",
    "\n",
    "print(f\"First term: {first_term}\")\n",
    "print(f\"Third term: {third_term}\")\n",
    "\n",
    "# You can also modify items using their index\n",
    "ai_terms[1] = \"NETWORK\"    # Changes \"network\" to \"NETWORK\"\n",
    "print(\"After modification:\", ai_terms)\n",
    "\n",
    "# What happens if we try to access an index that doesn't exist?\n",
    "# Uncomment the next line to see the error:\n",
    "# bad_access = ai_terms[10]  # IndexError: list index out of range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: negative_indexing.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.1\n",
    "# negative_indexing.py - Counting from the end with negative indices\n",
    "\n",
    "# Using the same AI terms list\n",
    "ai_terms = [\"neural\", \"network\", \"training\", \"model\", \"agent\", \"prompt\"]\n",
    "\n",
    "# Negative indexing starts from the end\n",
    "last_term = ai_terms[-1]       # Gets \"prompt\"\n",
    "second_to_last = ai_terms[-2]  # Gets \"agent\"\n",
    "third_from_end = ai_terms[-3]  # Gets \"model\"\n",
    "\n",
    "print(f\"Last term: {last_term}\")\n",
    "print(f\"Second to last: {second_to_last}\")\n",
    "print(f\"Third from end: {third_from_end}\")\n",
    "\n",
    "# This is incredibly useful! Imagine you're building a chatbot\n",
    "chat_history = [\"Hello\", \"How are you?\", \"I'm fine\", \"What's the weather?\", \"It's sunny\"]\n",
    "last_message = chat_history[-1]  # Always gets the most recent message\n",
    "print(f\"Most recent message: {last_message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: list_slicing.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.1\n",
    "# list_slicing.py - Extracting portions of lists with slicing\n",
    "\n",
    "# Let's work with a dataset of temperatures (in Celsius)\n",
    "temperatures = [20, 22, 25, 23, 26, 28, 30, 29, 27, 24, 21, 19]\n",
    "print(\"All temperatures:\", temperatures)\n",
    "\n",
    "# Basic slicing\n",
    "first_three = temperatures[0:3]   # Items at index 0, 1, 2 (not 3!)\n",
    "print(\"First three temps:\", first_three)\n",
    "\n",
    "# If you omit the start, it defaults to 0\n",
    "first_four = temperatures[:4]     # Same as [0:4]\n",
    "print(\"First four temps:\", first_four)\n",
    "\n",
    "# If you omit the end, it goes to the end of the list\n",
    "from_index_6 = temperatures[6:]   # From index 6 to the end\n",
    "print(\"From index 6 onward:\", from_index_6)\n",
    "\n",
    "# Get everything (make a copy)\n",
    "all_temps = temperatures[:]       # Copies the entire list\n",
    "print(\"Copy of all temps:\", all_temps)\n",
    "\n",
    "# Using step to skip items\n",
    "every_other = temperatures[::2]   # Every 2nd item\n",
    "print(\"Every other temp:\", every_other)\n",
    "\n",
    "# Reverse the list using step -1\n",
    "reversed_temps = temperatures[::-1]\n",
    "print(\"Reversed:\", reversed_temps)\n",
    "\n",
    "# Combine start, end, and step\n",
    "morning_temps = temperatures[1:7:2]  # Index 1 to 6, every 2nd item\n",
    "print(\"Select morning temps:\", morning_temps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: advanced_slicing.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.1\n",
    "# advanced_slicing.py - Advanced slicing patterns for AI/ML\n",
    "\n",
    "# Simulating a dataset for machine learning\n",
    "dataset = list(range(100))  # 0 to 99, imagine these are data samples\n",
    "\n",
    "# Common AI/ML slicing patterns\n",
    "\n",
    "# 1. Getting batches of data\n",
    "batch_size = 10\n",
    "first_batch = dataset[:batch_size]\n",
    "second_batch = dataset[batch_size:batch_size*2]\n",
    "print(f\"First batch: {first_batch}\")\n",
    "print(f\"Second batch: {second_batch}\")\n",
    "\n",
    "# 2. Train/test split (very common in ML!)\n",
    "split_point = int(len(dataset) * 0.8)  # 80% for training\n",
    "training_data = dataset[:split_point]   # First 80%\n",
    "test_data = dataset[split_point:]       # Last 20%\n",
    "print(f\"Training samples: {len(training_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "# 3. Getting the last n items (like recent chat history)\n",
    "recent_history = dataset[-5:]  # Last 5 items\n",
    "print(f\"Recent items: {recent_history}\")\n",
    "\n",
    "# 4. Skipping header/footer (common with data files)\n",
    "data_with_header = [\"HEADER\", 10, 20, 30, 40, \"FOOTER\"]\n",
    "clean_data = data_with_header[1:-1]  # Skip first and last\n",
    "print(f\"Clean data: {clean_data}\")\n",
    "\n",
    "# 5. Reverse order (useful for backpropagation in neural networks!)\n",
    "forwards = [1, 2, 3, 4, 5]\n",
    "backwards = forwards[::-1]\n",
    "print(f\"Forward: {forwards}\")\n",
    "print(f\"Backward: {backwards}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: lists_and_loops.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.1\n",
    "# lists_and_loops.py - Combining lists with loops from Chapter 3\n",
    "\n",
    "# Using loops with lists (building on Chapter 3!)\n",
    "scores = [85, 92, 78, 95, 88, 73, 91]\n",
    "\n",
    "# For loop through a list (remember this pattern?)\n",
    "print(\"All scores:\")\n",
    "for score in scores:\n",
    "    print(f\"  Score: {score}\")\n",
    "\n",
    "# Using enumerate to get both index and value\n",
    "print(\"\\nScores with position:\")\n",
    "for position, score in enumerate(scores):\n",
    "    print(f\"  Position {position}: {score}\")\n",
    "\n",
    "# Using conditions with lists (Chapter 3 skills!)\n",
    "print(\"\\nHigh scores (90+):\")\n",
    "for score in scores:\n",
    "    if score >= 90:  # Our if statement from Chapter 3!\n",
    "        print(f\"  Excellent: {score}\")\n",
    "\n",
    "# Accessing by index with a loop\n",
    "print(\"\\nFirst half of scores:\")\n",
    "for i in range(len(scores) // 2):  # Using range from Chapter 3\n",
    "    print(f\"  scores[{i}] = {scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: ai_conversation.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.1\n",
    "# ai_conversation.py - Simulating chatbot conversation history\n",
    "\n",
    "# Simulating a simple chatbot conversation history\n",
    "conversation = []  # Start with empty list\n",
    "\n",
    "# Adding user messages (we'll learn append in the next section)\n",
    "conversation = conversation + [\"User: Hello!\"]\n",
    "conversation = conversation + [\"Bot: Hi there! How can I help?\"]\n",
    "conversation = conversation + [\"User: What's the weather?\"]\n",
    "conversation = conversation + [\"Bot: I'll check that for you.\"]\n",
    "\n",
    "# Get the last exchange\n",
    "last_exchange = conversation[-2:]  # Last user message and bot response\n",
    "print(\"Last exchange:\")\n",
    "for message in last_exchange:\n",
    "    print(f\"  {message}\")\n",
    "\n",
    "# Prepare context for AI (like preparing a prompt)\n",
    "context_window = 3  # How many previous messages to include\n",
    "context = conversation[-context_window:] if len(conversation) >= context_window else conversation\n",
    "print(f\"\\nContext for next response ({len(context)} messages):\")\n",
    "for msg in context:\n",
    "    print(f\"  {msg}\")\n",
    "\n",
    "# This is exactly how AI agents maintain conversation context!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 4.1 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1.1: Shopping Cart Manager\n",
    "\n",
    "Create a shopping cart system that:\n",
    "1. Starts with an empty cart (list)\n",
    "2. Adds these items: \"apples\", \"bread\", \"milk\", \"eggs\", \"cheese\"\n",
    "3. Displays the first and last items using indexing\n",
    "4. Removes the third item\n",
    "5. Checks if \"milk\" is in the cart\n",
    "6. Displays the total number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1.2: Grade Analyzer\n",
    "\n",
    "Build a grade tracking system that:\n",
    "1. Creates a list of 10 test scores: [85, 92, 78, 95, 88, 73, 91, 82, 79, 96]\n",
    "2. Finds and displays the highest score (hint: use max())\n",
    "3. Finds and displays the lowest score (hint: use min())\n",
    "4. Calculates the average score\n",
    "5. Extracts the top 3 scores using slicing after sorting\n",
    "6. Counts how many scores are above 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1.3: Matrix Operations\n",
    "\n",
    "Work with a 3x3 matrix (nested list):\n",
    "1. Create a 3x3 matrix: [[1,2,3], [4,5,6], [7,8,9]]\n",
    "2. Access and print the center element (5)\n",
    "3. Extract and print the first row\n",
    "4. Extract and print the last column [3, 6, 9]\n",
    "5. Calculate the sum of diagonal elements [1, 5, 9]\n",
    "6. Create a flattened list containing all elements in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4.2: List methods and operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: list_methods_adding.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.2\n",
    "# list_methods_adding.py - Methods for adding items to lists\n",
    "\n",
    "# Starting with a simple list\n",
    "topics = [\"Python\", \"Lists\", \"Loops\"]\n",
    "print(\"Starting topics:\", topics)\n",
    "\n",
    "# append() - Adds ONE item to the end\n",
    "topics.append(\"Functions\")\n",
    "print(\"After append('Functions'):\", topics)\n",
    "\n",
    "# Be careful - append adds the whole item as ONE element\n",
    "topics.append([\"AI\", \"ML\"])  # This adds the entire list as one item!\n",
    "print(\"After appending a list:\", topics)\n",
    "# Notice the nested list: ['Python', 'Lists', 'Loops', 'Functions', ['AI', 'ML']]\n",
    "\n",
    "# Remove the nested list to clean up\n",
    "topics.pop()  # Remove last item\n",
    "\n",
    "# extend() - Adds EACH item from another list\n",
    "more_topics = [\"Machine Learning\", \"Neural Networks\"]\n",
    "topics.extend(more_topics)\n",
    "print(\"After extend:\", topics)\n",
    "\n",
    "# The difference is clear\n",
    "list_a = [1, 2, 3]\n",
    "list_b = [4, 5]\n",
    "\n",
    "# Using append\n",
    "test_append = list_a.copy()\n",
    "test_append.append(list_b)\n",
    "print(\"\\nAppend result:\", test_append)  # [1, 2, 3, [4, 5]]\n",
    "\n",
    "# Using extend\n",
    "test_extend = list_a.copy()\n",
    "test_extend.extend(list_b)\n",
    "print(\"Extend result:\", test_extend)  # [1, 2, 3, 4, 5]\n",
    "\n",
    "# insert() - Adds an item at a SPECIFIC position\n",
    "topics = [\"Python\", \"Lists\", \"Functions\", \"Classes\"]\n",
    "topics.insert(0, \"Introduction\")  # Insert at the beginning\n",
    "print(\"\\nAfter insert at position 0:\", topics)\n",
    "\n",
    "topics.insert(3, \"Control Flow\")  # Insert at position 3\n",
    "print(\"After insert at position 3:\", topics)\n",
    "\n",
    "# Real-world example: Managing a conversation history\n",
    "chat_history = []\n",
    "chat_history.append(\"User: Hello!\")\n",
    "chat_history.append(\"Bot: Hi there!\")\n",
    "chat_history.insert(0, \"System: Conversation started\")  # Add system message at beginning\n",
    "print(\"\\nChat history:\")\n",
    "for message in chat_history:\n",
    "    print(f\"  {message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: list_methods_removing.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.2\n",
    "# list_methods_removing.py - Methods for removing items from lists\n",
    "\n",
    "# Let's work with a list of tasks\n",
    "tasks = [\"email client\", \"fix bug\", \"write tests\", \"fix bug\", \"deploy\", \"fix bug\"]\n",
    "print(\"Original tasks:\", tasks)\n",
    "\n",
    "# Method 1: remove() - Removes the FIRST occurrence of a value\n",
    "tasks.remove(\"fix bug\")  # Only removes the first \"fix bug\"\n",
    "print(\"After remove('fix bug'):\", tasks)\n",
    "\n",
    "# Method 2: pop() - Removes and RETURNS an item at a specific index\n",
    "completed_task = tasks.pop()  # No index = removes last item\n",
    "print(f\"Completed: {completed_task}\")\n",
    "print(\"Tasks after pop():\", tasks)\n",
    "\n",
    "first_task = tasks.pop(0)  # Remove and return first item\n",
    "print(f\"Did first: {first_task}\")\n",
    "print(\"Tasks after pop(0):\", tasks)\n",
    "\n",
    "# Method 3: clear() - Removes ALL items\n",
    "old_tasks = [\"outdated task 1\", \"outdated task 2\"]\n",
    "print(f\"Old tasks before clear: {old_tasks}\")\n",
    "old_tasks.clear()\n",
    "print(f\"Old tasks after clear: {old_tasks}\")\n",
    "\n",
    "# Method 4: del - Not a method, but a statement (be careful with this one!)\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "del numbers[2]  # Removes the item at index 2\n",
    "print(\"After del numbers[2]:\", numbers)\n",
    "\n",
    "# You can also delete slices!\n",
    "del numbers[1:3]  # Removes items at index 1 and 2\n",
    "print(\"After del numbers[1:3]:\", numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: list_finding_counting.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.2\n",
    "# list_finding_counting.py - Finding and counting items in lists\n",
    "\n",
    "# Sample data: user feedback scores\n",
    "scores = [8, 9, 7, 9, 10, 8, 9, 7, 8, 9, 10, 9]\n",
    "print(\"Feedback scores:\", scores)\n",
    "\n",
    "# count() - How many times does a value appear?\n",
    "nines = scores.count(9)\n",
    "tens = scores.count(10)\n",
    "print(f\"Number of 9s: {nines}\")\n",
    "print(f\"Number of 10s: {tens}\")\n",
    "\n",
    "# index() - Where is a value located?\n",
    "first_ten_position = scores.index(10)\n",
    "print(f\"First 10 is at position: {first_ten_position}\")\n",
    "\n",
    "# Be careful - index() raises an error if item doesn't exist!\n",
    "# Safe way to use index():\n",
    "search_value = 6\n",
    "if search_value in scores:\n",
    "    position = scores.index(search_value)\n",
    "    print(f\"Found {search_value} at position {position}\")\n",
    "else:\n",
    "    print(f\"{search_value} not found in scores\")\n",
    "\n",
    "# in operator - Check if item exists (returns True/False)\n",
    "has_perfect_score = 10 in scores\n",
    "has_failing_score = 5 in scores\n",
    "print(f\"Has perfect score (10)? {has_perfect_score}\")\n",
    "print(f\"Has failing score (5)? {has_failing_score}\")\n",
    "\n",
    "# Real-world AI example: Checking for keywords in user input\n",
    "user_message = \"I want to cancel my subscription\"\n",
    "keywords = user_message.lower().split()\n",
    "if \"cancel\" in keywords or \"unsubscribe\" in keywords:\n",
    "    print(\"User wants to cancel - routing to retention team\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: list_sorting.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.2\n",
    "# list_sorting.py - Sorting and reversing lists\n",
    "\n",
    "# Sorting numbers\n",
    "prices = [29.99, 14.50, 39.99, 24.99, 19.99]\n",
    "print(\"Original prices:\", prices)\n",
    "\n",
    "# sort() - Sorts the list IN PLACE (modifies the original)\n",
    "prices.sort()\n",
    "print(\"After sort() - ascending:\", prices)\n",
    "\n",
    "prices.sort(reverse=True)  # Sort in descending order\n",
    "print(\"After sort(reverse=True):\", prices)\n",
    "\n",
    "# sorted() - Returns a NEW sorted list (doesn't modify original)\n",
    "original = [5, 2, 8, 1, 9]\n",
    "sorted_copy = sorted(original)\n",
    "print(f\"Original: {original}\")  # Unchanged!\n",
    "print(f\"Sorted copy: {sorted_copy}\")\n",
    "\n",
    "# Sorting strings\n",
    "words = [\"python\", \"agent\", \"neural\", \"bot\", \"ai\"]\n",
    "words.sort()\n",
    "print(\"Alphabetically sorted:\", words)\n",
    "\n",
    "# reverse() - Reverses the list IN PLACE\n",
    "countdown = [1, 2, 3, 4, 5]\n",
    "countdown.reverse()\n",
    "print(\"Reversed countdown:\", countdown)\n",
    "\n",
    "# Advanced: Sorting with a key function\n",
    "# Sort by length of string\n",
    "names = [\"Jo\", \"Alexander\", \"Bob\", \"Christina\"]\n",
    "names.sort(key=len)  # Sort by length\n",
    "print(\"Sorted by length:\", names)\n",
    "\n",
    "# Sort ignoring case\n",
    "mixed_case = [\"apple\", \"Banana\", \"cherry\", \"Date\"]\n",
    "mixed_case.sort()  # Capital letters come first!\n",
    "print(\"Default sort:\", mixed_case)\n",
    "\n",
    "mixed_case = [\"apple\", \"Banana\", \"cherry\", \"Date\"]\n",
    "mixed_case.sort(key=str.lower)  # Ignore case\n",
    "print(\"Case-insensitive sort:\", mixed_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: list_copying.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.2\n",
    "# list_copying.py - The critical importance of proper list copying\n",
    "\n",
    "# The WRONG way (creates a reference, not a copy)\n",
    "original_list = [1, 2, 3, 4, 5]\n",
    "not_a_copy = original_list  # This is NOT a copy!\n",
    "\n",
    "not_a_copy.append(6)\n",
    "print(\"Original list:\", original_list)  # [1, 2, 3, 4, 5, 6] - CHANGED!\n",
    "print(\"Not a copy:\", not_a_copy)        # [1, 2, 3, 4, 5, 6]\n",
    "# They're the same list!\n",
    "\n",
    "# The RIGHT ways to copy a list\n",
    "\n",
    "# Method 1: Using copy()\n",
    "list1 = [1, 2, 3, 4, 5]\n",
    "list2 = list1.copy()  # Creates an actual copy\n",
    "list2.append(6)\n",
    "print(\"\\nUsing copy():\")\n",
    "print(\"list1:\", list1)  # [1, 2, 3, 4, 5] - unchanged!\n",
    "print(\"list2:\", list2)  # [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Method 2: Using slicing\n",
    "list3 = [7, 8, 9]\n",
    "list4 = list3[:]  # The [:] creates a copy\n",
    "list4.append(10)\n",
    "print(\"\\nUsing slicing [:]:\")\n",
    "print(\"list3:\", list3)  # [7, 8, 9] - unchanged!\n",
    "print(\"list4:\", list4)  # [7, 8, 9, 10]\n",
    "\n",
    "# Method 3: Using list()\n",
    "list5 = [11, 12, 13]\n",
    "list6 = list(list5)  # Creates a new list\n",
    "list6.append(14)\n",
    "print(\"\\nUsing list():\")\n",
    "print(\"list5:\", list5)  # [11, 12, 13] - unchanged!\n",
    "print(\"list6:\", list6)  # [11, 12, 13, 14]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: list_operations.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.2\n",
    "# list_operations.py - Mathematical operations with lists\n",
    "\n",
    "# Concatenation with +\n",
    "list_a = [1, 2, 3]\n",
    "list_b = [4, 5, 6]\n",
    "combined = list_a + list_b\n",
    "print(f\"{list_a} + {list_b} = {combined}\")\n",
    "\n",
    "# Repetition with *\n",
    "pattern = [0, 1]\n",
    "repeated = pattern * 3\n",
    "print(f\"{pattern} * 3 = {repeated}\")\n",
    "\n",
    "# This is great for initialization!\n",
    "# Creating a game board\n",
    "row = [0] * 5  # Five zeros\n",
    "board = []\n",
    "for i in range(5):\n",
    "    board.append(row.copy())  # Important: copy each row!\n",
    "print(\"Empty board:\")\n",
    "for row in board:\n",
    "    print(row)\n",
    "\n",
    "# Membership testing (we saw this earlier)\n",
    "inventory = [\"sword\", \"shield\", \"potion\", \"map\"]\n",
    "has_potion = \"potion\" in inventory\n",
    "has_armor = \"armor\" in inventory\n",
    "print(f\"Has potion? {has_potion}\")\n",
    "print(f\"Has armor? {has_armor}\")\n",
    "\n",
    "# Length, min, max, sum (for numeric lists)\n",
    "numbers = [10, 5, 8, 3, 15, 12]\n",
    "print(f\"Length: {len(numbers)}\")\n",
    "print(f\"Minimum: {min(numbers)}\")\n",
    "print(f\"Maximum: {max(numbers)}\")\n",
    "print(f\"Sum: {sum(numbers)}\")\n",
    "print(f\"Average: {sum(numbers) / len(numbers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: memory_system.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.2\n",
    "# memory_system.py - Simple conversation memory system for AI agents\n",
    "\n",
    "# Simple conversation memory system using dictionaries and lists\n",
    "# No classes or functions - just direct manipulation\n",
    "\n",
    "# Initialize our memory system\n",
    "memory = {\n",
    "    \"conversations\": [],\n",
    "    \"max_size\": 5,\n",
    "    \"important_messages\": [],\n",
    "    \"message_count\": 0\n",
    "}\n",
    "\n",
    "print(\"Memory system initialized\")\n",
    "print(f\"Max conversation size: {memory['max_size']}\")\n",
    "\n",
    "# Simulate adding messages\n",
    "messages_to_add = [\n",
    "    \"User: Hello AI!\",\n",
    "    \"AI: Hello! How can I help you?\",\n",
    "    \"User: Tell me about Python lists\",\n",
    "    \"AI: Lists are ordered collections in Python\",\n",
    "    \"User: How do I add items?\",\n",
    "    \"AI: Use append() to add items to a list\",\n",
    "    \"User: Thanks, that's helpful!\"\n",
    "]\n",
    "\n",
    "print(\"\\nAdding messages to memory:\")\n",
    "for msg in messages_to_add:\n",
    "    # Add message to conversations\n",
    "    memory[\"conversations\"].append(msg)\n",
    "    memory[\"message_count\"] += 1\n",
    "    \n",
    "    # Check if we exceeded max size (sliding window)\n",
    "    if len(memory[\"conversations\"]) > memory[\"max_size\"]:\n",
    "        removed = memory[\"conversations\"].pop(0)  # Remove oldest\n",
    "        print(f\"  Memory full, removed: {removed}\")\n",
    "    \n",
    "    print(f\"  Added: {msg}\")\n",
    "\n",
    "print(f\"\\nCurrent memory state:\")\n",
    "print(f\"  Total messages processed: {memory['message_count']}\")\n",
    "print(f\"  Messages in memory: {len(memory['conversations'])}\")\n",
    "\n",
    "# Get recent context (last 3 messages)\n",
    "context_size = 3\n",
    "if len(memory[\"conversations\"]) >= context_size:\n",
    "    recent_context = memory[\"conversations\"][-context_size:]\n",
    "else:\n",
    "    recent_context = memory[\"conversations\"].copy()\n",
    "\n",
    "print(f\"\\nRecent context ({len(recent_context)} messages):\")\n",
    "for msg in recent_context:\n",
    "    print(f\"  {msg}\")\n",
    "\n",
    "# Mark important messages\n",
    "important_keywords = [\"thanks\", \"helpful\", \"great\"]\n",
    "for msg in memory[\"conversations\"]:\n",
    "    msg_lower = msg.lower()\n",
    "    for keyword in important_keywords:\n",
    "        if keyword in msg_lower and msg not in memory[\"important_messages\"]:\n",
    "            memory[\"important_messages\"].append(msg)\n",
    "            print(f\"\\nMarked as important: {msg}\")\n",
    "            break\n",
    "\n",
    "# Search for specific keywords\n",
    "search_term = \"list\"\n",
    "print(f\"\\nSearching for messages containing '{search_term}':\")\n",
    "found_messages = []\n",
    "for msg in memory[\"conversations\"]:\n",
    "    if search_term.lower() in msg.lower():\n",
    "        found_messages.append(msg)\n",
    "        print(f\"  Found: {msg}\")\n",
    "\n",
    "print(f\"\\nTotal matches: {len(found_messages)}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n=== Memory Summary ===\")\n",
    "print(f\"Messages in memory: {len(memory['conversations'])}\")\n",
    "print(f\"Important messages: {len(memory['important_messages'])}\")\n",
    "print(f\"Total processed: {memory['message_count']}\")\n",
    "if memory[\"conversations\"]:\n",
    "    print(f\"Oldest message: {memory['conversations'][0]}\")\n",
    "    print(f\"Latest message: {memory['conversations'][-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: common_patterns.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.2\n",
    "# common_patterns.py - Common list patterns for AI applications\n",
    "\n",
    "# Pattern 1: Building a list conditionally\n",
    "responses = [\"good\", \"bad\", \"excellent\", \"poor\", \"great\", \"terrible\", \"okay\"]\n",
    "positive = []\n",
    "for response in responses:\n",
    "    if response in [\"good\", \"excellent\", \"great\"]:\n",
    "        positive.append(response)\n",
    "print(f\"Positive responses: {positive}\")\n",
    "\n",
    "# Pattern 2: Removing duplicates while preserving order\n",
    "messages = [\"hello\", \"world\", \"hello\", \"python\", \"world\", \"ai\"]\n",
    "seen = []\n",
    "unique_messages = []\n",
    "for msg in messages:\n",
    "    if msg not in seen:\n",
    "        seen.append(msg)\n",
    "        unique_messages.append(msg)\n",
    "print(f\"Unique messages: {unique_messages}\")\n",
    "\n",
    "# Pattern 3: Batch processing\n",
    "data = list(range(1, 16))  # 1 to 15\n",
    "batch_size = 5\n",
    "print(\"Processing in batches:\")\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    print(f\"  Processing batch: {batch}\")\n",
    "\n",
    "# Pattern 4: Maintaining a fixed-size history (sliding window)\n",
    "history = []\n",
    "max_history = 3\n",
    "\n",
    "new_items = [\"event1\", \"event2\", \"event3\", \"event4\", \"event5\"]\n",
    "print(\"Building history with sliding window:\")\n",
    "for item in new_items:\n",
    "    history.append(item)\n",
    "    if len(history) > max_history:\n",
    "        history.pop(0)  # Remove oldest\n",
    "    print(f\"  Current history: {history}\")\n",
    "\n",
    "# Pattern 5: Working with nested lists\n",
    "# Student scores: [name, [quiz1, quiz2, quiz3]]\n",
    "students = [\n",
    "    [\"Alice\", [85, 90, 92]],\n",
    "    [\"Bob\", [78, 82, 88]],\n",
    "    [\"Charlie\", [92, 95, 89]]\n",
    "]\n",
    "\n",
    "print(\"\\nStudent Score Analysis:\")\n",
    "for student in students:\n",
    "    name = student[0]\n",
    "    scores = student[1]\n",
    "    average = sum(scores) / len(scores)\n",
    "    highest = max(scores)\n",
    "    print(f\"  {name}: Average = {average:.1f}, Highest = {highest}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: recommendation_tracker.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.2\n",
    "# recommendation_tracker.py - Simple recommendation system\n",
    "\n",
    "# Recommendation system using dictionaries and lists\n",
    "# Track what items users have viewed and liked\n",
    "\n",
    "# Our data storage\n",
    "users_data = {\n",
    "    \"alice\": {\n",
    "        \"viewed\": [\"item1\", \"item2\", \"item3\"],\n",
    "        \"liked\": [\"item1\", \"item3\"],\n",
    "        \"recommendations\": []\n",
    "    },\n",
    "    \"bob\": {\n",
    "        \"viewed\": [\"item2\", \"item4\"],\n",
    "        \"liked\": [\"item4\"],\n",
    "        \"recommendations\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "# All available items in our system\n",
    "all_items = [\"item1\", \"item2\", \"item3\", \"item4\", \"item5\", \"item6\"]\n",
    "\n",
    "# Generate recommendations for each user\n",
    "for username in users_data:\n",
    "    user = users_data[username]\n",
    "    \n",
    "    # Find items they haven't viewed yet\n",
    "    not_viewed = []\n",
    "    for item in all_items:\n",
    "        if item not in user[\"viewed\"]:\n",
    "            not_viewed.append(item)\n",
    "    \n",
    "    # Simple recommendation: items not viewed yet\n",
    "    user[\"recommendations\"] = not_viewed[:3]  # Top 3 recommendations\n",
    "    \n",
    "    print(f\"\\n{username}'s profile:\")\n",
    "    print(f\"  Viewed: {user['viewed']}\")\n",
    "    print(f\"  Liked: {user['liked']}\")\n",
    "    print(f\"  Recommendations: {user['recommendations']}\")\n",
    "\n",
    "# Find popular items (liked by multiple users)\n",
    "all_liked_items = []\n",
    "for username in users_data:\n",
    "    all_liked_items.extend(users_data[username][\"liked\"])\n",
    "\n",
    "print(\"\\n=== Popular Items ===\")\n",
    "for item in all_items:\n",
    "    like_count = all_liked_items.count(item)\n",
    "    if like_count > 0:\n",
    "        print(f\"  {item}: {like_count} likes\")\n",
    "\n",
    "# Find users with similar interests\n",
    "print(\"\\n=== Similar Users ===\")\n",
    "user_list = list(users_data.keys())\n",
    "for i in range(len(user_list)):\n",
    "    for j in range(i + 1, len(user_list)):\n",
    "        user1 = user_list[i]\n",
    "        user2 = user_list[j]\n",
    "        \n",
    "        # Find common liked items\n",
    "        liked1 = users_data[user1][\"liked\"]\n",
    "        liked2 = users_data[user2][\"liked\"]\n",
    "        \n",
    "        common_likes = []\n",
    "        for item in liked1:\n",
    "            if item in liked2:\n",
    "                common_likes.append(item)\n",
    "        \n",
    "        if common_likes:\n",
    "            print(f\"  {user1} and {user2} both like: {common_likes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 4.2 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2.1: Shopping Cart Manager\n",
    "\n",
    "Create a shopping cart system that:\n",
    "1. Start with an empty cart\n",
    "2. Add items: \"apple\", \"banana\", \"apple\", \"orange\", \"banana\", \"grape\"\n",
    "3. Count how many apples and bananas are in the cart\n",
    "4. Remove one banana using remove()\n",
    "5. Sort the cart alphabetically\n",
    "6. Display the final cart and total number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2.2: Score Tracker\n",
    "\n",
    "Build a score tracking system that:\n",
    "1. Start with scores: [75, 82, 90, 68, 95, 78]\n",
    "2. Add three more scores: 88, 92, 79 using extend()\n",
    "3. Find the highest and lowest scores\n",
    "4. Calculate the average score\n",
    "5. Remove the lowest score using remove()\n",
    "6. Sort scores from highest to lowest\n",
    "7. Display the top 3 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2.3: Message Queue\n",
    "\n",
    "Build a message queue that:\n",
    "1. Maintains a maximum of 5 messages\n",
    "2. Process these messages in order: \"msg1\", \"msg2\", \"msg3\", \"msg4\", \"msg5\", \"msg6\", \"msg7\"\n",
    "3. When full, remove the oldest message using pop(0) before adding new ones\n",
    "4. After processing all messages, show the final queue\n",
    "5. Search for any message containing \"5\" using index()\n",
    "6. Count how many times \"msg\" appears in any message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4.3: Tuples and their immutability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: tuple_creation.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.3\n",
    "# tuple_creation.py - Creating tuples in Python\n",
    "\n",
    "# Creating tuples - notice the parentheses!\n",
    "coordinates = (10, 20)\n",
    "print(f\"Coordinates: {coordinates}\")\n",
    "print(f\"Type: {type(coordinates)}\")\n",
    "\n",
    "# Tuple with different data types\n",
    "person = (\"Alice\", 25, \"Engineer\", True)\n",
    "print(f\"Person data: {person}\")\n",
    "\n",
    "# Empty tuple\n",
    "empty = ()\n",
    "print(f\"Empty tuple: {empty}\")\n",
    "\n",
    "# Here's where it gets interesting - parentheses are often optional!\n",
    "colors = \"red\", \"green\", \"blue\"  # This is a tuple!\n",
    "print(f\"Colors: {colors}\")\n",
    "print(f\"Type: {type(colors)}\")\n",
    "\n",
    "# But sometimes parentheses are required for clarity\n",
    "# Without parentheses, this would be confusing:\n",
    "result = (1 + 2, 3 + 4)  # Tuple of (3, 7)\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# Single element tuple - this is tricky!\n",
    "not_a_tuple = (42)  # This is just the number 42 with parentheses\n",
    "actual_tuple = (42,)  # The comma makes it a tuple!\n",
    "print(f\"not_a_tuple: {not_a_tuple}, type: {type(not_a_tuple)}\")\n",
    "print(f\"actual_tuple: {actual_tuple}, type: {type(actual_tuple)}\")\n",
    "\n",
    "# Converting a list to a tuple\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "my_tuple = tuple(my_list)\n",
    "print(f\"List converted to tuple: {my_tuple}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: tuple_accessing.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.3\n",
    "# tuple_accessing.py - Accessing and unpacking tuple elements\n",
    "\n",
    "# AI model configuration tuple\n",
    "model_config = (\"gpt-3\", 175, \"billion\", 96, 12288, 2048)\n",
    "# (name, size, unit, layers, hidden_size, context_length)\n",
    "\n",
    "# Indexing works exactly like lists\n",
    "model_name = model_config[0]\n",
    "num_layers = model_config[3]\n",
    "context = model_config[-1]  # Negative indexing works too!\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Layers: {num_layers}\")\n",
    "print(f\"Context length: {context}\")\n",
    "\n",
    "# Slicing works the same way\n",
    "size_info = model_config[1:3]  # Get size and unit\n",
    "print(f\"Size info: {size_info}\")\n",
    "\n",
    "# You can loop through tuples\n",
    "print(\"Configuration details:\")\n",
    "for item in model_config:\n",
    "    print(f\"  - {item}\")\n",
    "\n",
    "# Unpacking - this is SUPER useful with tuples!\n",
    "point = (3, 7)\n",
    "x, y = point  # Unpacks the tuple into separate variables\n",
    "print(f\"x = {x}, y = {y}\")\n",
    "\n",
    "# Unpacking with AI example\n",
    "response = (\"success\", \"Hello! How can I help?\", 0.92)\n",
    "status, message, confidence = response\n",
    "print(f\"Status: {status}\")\n",
    "print(f\"Message: {message}\")\n",
    "print(f\"Confidence: {confidence}\")\n",
    "\n",
    "# You can even use * to grab multiple elements\n",
    "numbers = (1, 2, 3, 4, 5, 6, 7)\n",
    "first, *middle, last = numbers\n",
    "print(f\"First: {first}\")\n",
    "print(f\"Middle: {middle}\")  # This becomes a list!\n",
    "print(f\"Last: {last}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: tuple_immutability.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.3\n",
    "# tuple_immutability.py - Understanding tuple immutability\n",
    "\n",
    "# Lists are mutable (changeable)\n",
    "list_scores = [85, 90, 78]\n",
    "list_scores[1] = 95  # This works fine\n",
    "print(f\"Modified list: {list_scores}\")\n",
    "\n",
    "# Tuples are immutable (unchangeable)\n",
    "tuple_scores = (85, 90, 78)\n",
    "# tuple_scores[1] = 95  # This would cause an error!\n",
    "# Uncomment the line above to see: TypeError: 'tuple' object does not support item assignment\n",
    "\n",
    "# But wait - you CAN \"modify\" a tuple by creating a new one\n",
    "original = (1, 2, 3)\n",
    "# To \"add\" an element, create a new tuple\n",
    "modified = original + (4,)  # Note the comma for single element!\n",
    "print(f\"Original: {original}\")  # Still (1, 2, 3)\n",
    "print(f\"Modified: {modified}\")  # New tuple (1, 2, 3, 4)\n",
    "\n",
    "# To \"change\" an element, convert to list, modify, convert back\n",
    "config = (\"model_v1\", 100, \"active\")\n",
    "print(f\"Original config: {config}\")\n",
    "\n",
    "# Need to update? Create a new tuple\n",
    "temp_list = list(config)\n",
    "temp_list[0] = \"model_v2\"\n",
    "new_config = tuple(temp_list)\n",
    "print(f\"New config: {new_config}\")\n",
    "print(f\"Original still unchanged: {config}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: tuple_superpowers.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.3\n",
    "# tuple_superpowers.py - Why immutability is actually useful\n",
    "\n",
    "# 1. SAFETY - Protecting important data\n",
    "# Imagine these are critical system settings\n",
    "SYSTEM_SETTINGS = (\"production\", \"api.company.com\", 443, True)\n",
    "# No one can accidentally modify these!\n",
    "# If someone tries: SYSTEM_SETTINGS[0] = \"development\"  # ERROR!\n",
    "\n",
    "print(f\"System settings are protected: {SYSTEM_SETTINGS}\")\n",
    "\n",
    "# 2. DICTIONARY KEYS - Only immutable objects can be dictionary keys\n",
    "# This is useful for coordinate systems, caching, etc.\n",
    "location_names = {\n",
    "    (40.7128, -74.0060): \"New York City\",\n",
    "    (51.5074, -0.1278): \"London\",\n",
    "    (35.6762, 139.6503): \"Tokyo\"\n",
    "}\n",
    "\n",
    "coordinates = (40.7128, -74.0060)\n",
    "print(f\"Location at {coordinates}: {location_names[coordinates]}\")\n",
    "\n",
    "# You CAN'T use lists as dictionary keys\n",
    "# city_data = {[40.7, -74.0]: \"NYC\"}  # This would cause an error!\n",
    "\n",
    "# 3. MULTIPLE RETURN VALUES - Clean way to return multiple values\n",
    "# Calculate rectangle properties\n",
    "width = 10\n",
    "height = 5\n",
    "area = width * height\n",
    "perimeter = 2 * (width + height)\n",
    "\n",
    "# Store multiple results in a tuple\n",
    "rectangle_info = (area, perimeter)\n",
    "print(f\"Rectangle info (area, perimeter): {rectangle_info}\")\n",
    "\n",
    "# Unpack when using\n",
    "calc_area, calc_perimeter = rectangle_info\n",
    "print(f\"Area: {calc_area}, Perimeter: {calc_perimeter}\")\n",
    "\n",
    "# 4. MEMORY EFFICIENCY - Tuples use less memory than lists\n",
    "import sys\n",
    "\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "my_tuple = (1, 2, 3, 4, 5)\n",
    "\n",
    "print(f\"List size: {sys.getsizeof(my_list)} bytes\")\n",
    "print(f\"Tuple size: {sys.getsizeof(my_tuple)} bytes\")\n",
    "# Tuples are smaller!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: named_tuples.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.3\n",
    "# named_tuples.py - Named tuples for clearer code\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "# Create a named tuple class for AI model info\n",
    "ModelInfo = namedtuple('ModelInfo', ['name', 'parameters', 'accuracy', 'trained_on'])\n",
    "\n",
    "# Create instances\n",
    "gpt3 = ModelInfo(\"GPT-3\", 175_000_000_000, 0.92, \"CommonCrawl\")\n",
    "bert = ModelInfo(\"BERT\", 340_000_000, 0.89, \"Wikipedia\")\n",
    "\n",
    "# Access by name (much clearer than index!)\n",
    "print(f\"{gpt3.name} has {gpt3.parameters:,} parameters\")\n",
    "print(f\"Accuracy: {gpt3.accuracy}\")\n",
    "\n",
    "# You can still use indexing\n",
    "print(f\"First field: {gpt3[0]}\")\n",
    "\n",
    "# Named tuples are still immutable\n",
    "# gpt3.accuracy = 0.95  # This would cause an error!\n",
    "\n",
    "# Create another named tuple for evaluation results\n",
    "Result = namedtuple('Result', ['model', 'precision', 'recall', 'f1_score'])\n",
    "\n",
    "# Simulated evaluation\n",
    "eval_result = Result(\"MyAgent\", 0.89, 0.91, 0.90)\n",
    "print(f\"\\nEvaluation Results:\")\n",
    "print(f\"Model: {eval_result.model}\")\n",
    "print(f\"Precision: {eval_result.precision}\")\n",
    "print(f\"Recall: {eval_result.recall}\")\n",
    "print(f\"F1 Score: {eval_result.f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: tuples_vs_lists.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.3\n",
    "# tuples_vs_lists.py - When to use tuples vs lists\n",
    "\n",
    "# Use TUPLES when:\n",
    "# 1. Data shouldn't change (coordinates, configuration, constants)\n",
    "rgb_red = (255, 0, 0)  # Color values should be fixed\n",
    "db_config = (\"localhost\", 5432, \"mydb\", \"readonly\")  # Database settings\n",
    "\n",
    "# 2. You need dictionary keys\n",
    "cache = {\n",
    "    (\"user\", 123): \"cached_data_1\",\n",
    "    (\"post\", 456): \"cached_data_2\"\n",
    "}\n",
    "\n",
    "# 3. Representing a single record/entity\n",
    "person = (\"Bob\", 30, \"Engineer\")  # One person's data\n",
    "point = (10, 20)  # One point in space\n",
    "\n",
    "# Use LISTS when:\n",
    "# 1. Data needs to change\n",
    "shopping_cart = [\"apples\", \"bread\"]  # Will add/remove items\n",
    "shopping_cart.append(\"milk\")\n",
    "\n",
    "# 2. You have a collection of similar items\n",
    "temperatures = [22, 24, 23, 25, 21]  # Collection of readings\n",
    "messages = []  # Will accumulate messages\n",
    "\n",
    "# 3. You need list methods (sort, append, etc.)\n",
    "scores = [85, 92, 78, 95]\n",
    "scores.sort()  # Need to sort\n",
    "\n",
    "# 4. Size will change\n",
    "active_users = []  # Will grow and shrink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: ai_agent_tuples.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.3\n",
    "# ai_agent_tuples.py - Using tuples in AI agent development\n",
    "\n",
    "# AI Agent configuration and state management using tuples and dictionaries\n",
    "\n",
    "# Agent configuration (immutable - use tuple)\n",
    "agent_config = (\"Assistant\", \"gpt-3.5\", 2048, 0.7)  # (name, model, max_tokens, temperature)\n",
    "print(f\"Agent Configuration: {agent_config}\")\n",
    "print(f\"Agent name: {agent_config[0]}\")\n",
    "print(f\"Model: {agent_config[1]}\")\n",
    "\n",
    "# Conversation state (mutable - use dictionary with lists)\n",
    "conversation_state = {\n",
    "    \"config\": agent_config,  # Store the immutable config\n",
    "    \"history\": [],  # Mutable conversation history\n",
    "    \"message_count\": 0,\n",
    "    \"context_window\": 5\n",
    "}\n",
    "\n",
    "# Simulate conversation\n",
    "messages = [\n",
    "    (\"user\", \"Hello!\", \"2024-01-15 10:30:00\"),\n",
    "    (\"assistant\", \"Hi there! How can I help?\", \"2024-01-15 10:30:01\"),\n",
    "    (\"user\", \"What's the weather?\", \"2024-01-15 10:30:15\"),\n",
    "    (\"assistant\", \"I'll check that for you.\", \"2024-01-15 10:30:16\")\n",
    "]\n",
    "\n",
    "print(\"\\nProcessing messages:\")\n",
    "for role, content, timestamp in messages:  # Unpacking tuple\n",
    "    # Each message is stored as a tuple (immutable record)\n",
    "    message_record = (role, content, timestamp)\n",
    "    conversation_state[\"history\"].append(message_record)\n",
    "    conversation_state[\"message_count\"] += 1\n",
    "    print(f\"  Added: {role} - {content}\")\n",
    "\n",
    "# Get recent context\n",
    "context_size = conversation_state[\"context_window\"]\n",
    "recent = conversation_state[\"history\"][-context_size:]\n",
    "\n",
    "print(f\"\\nRecent context ({len(recent)} messages):\")\n",
    "for role, content, timestamp in recent:\n",
    "    print(f\"  [{timestamp}] {role}: {content}\")\n",
    "\n",
    "# Statistics as a tuple (immutable snapshot)\n",
    "stats = (\n",
    "    conversation_state[\"message_count\"],\n",
    "    len(conversation_state[\"history\"]),\n",
    "    conversation_state[\"config\"][0],  # Agent name\n",
    "    conversation_state[\"config\"][1]   # Model\n",
    ")\n",
    "\n",
    "messages_processed, history_length, agent_name, model_used = stats\n",
    "print(f\"\\nStatistics Snapshot:\")\n",
    "print(f\"  Agent: {agent_name}\")\n",
    "print(f\"  Model: {model_used}\")\n",
    "print(f\"  Messages processed: {messages_processed}\")\n",
    "print(f\"  History length: {history_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: tuple_patterns.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.3\n",
    "# tuple_patterns.py - Common tuple patterns in AI development\n",
    "\n",
    "# Pattern 1: Batch processing with coordinates\n",
    "training_data = [\n",
    "    ((0, 0), \"origin\"),\n",
    "    ((1, 0), \"right\"),\n",
    "    ((0, 1), \"up\"),\n",
    "    ((-1, 0), \"left\")\n",
    "]\n",
    "\n",
    "print(\"Training data:\")\n",
    "for coordinates, label in training_data:\n",
    "    x, y = coordinates  # Unpack the tuple\n",
    "    print(f\"  Point at ({x}, {y}) is labeled '{label}'\")\n",
    "\n",
    "# Pattern 2: Multiple return values for model evaluation\n",
    "# Simulate model evaluation\n",
    "accuracy = 0.92\n",
    "loss = 0.08\n",
    "epochs_completed = 100\n",
    "training_time = 45.3\n",
    "\n",
    "# Return as tuple\n",
    "evaluation_results = (accuracy, loss, epochs_completed, training_time)\n",
    "\n",
    "# Clean unpacking\n",
    "acc, loss_val, epochs, time_taken = evaluation_results\n",
    "print(f\"\\nTraining complete: {acc:.2%} accuracy in {time_taken:.1f} seconds\")\n",
    "\n",
    "# Pattern 3: Configuration management\n",
    "MODEL_CONFIGS = {\n",
    "    \"small\": (32, 4, 512, 0.1),    # (batch_size, layers, hidden_dim, dropout)\n",
    "    \"medium\": (64, 8, 1024, 0.2),\n",
    "    \"large\": (128, 12, 2048, 0.3)\n",
    "}\n",
    "\n",
    "selected_config = MODEL_CONFIGS[\"medium\"]\n",
    "batch, layers, hidden, dropout = selected_config\n",
    "print(f\"\\nMedium model: {layers} layers, {hidden} hidden dimensions\")\n",
    "\n",
    "# Pattern 4: Storing immutable state snapshots\n",
    "# Training history - each snapshot is immutable\n",
    "training_history = []\n",
    "\n",
    "# Simulate training epochs\n",
    "epoch_data = [\n",
    "    (1, 0.5, 0.75),  # (epoch, loss, accuracy)\n",
    "    (2, 0.3, 0.85),\n",
    "    (3, 0.2, 0.90)\n",
    "]\n",
    "\n",
    "for epoch, loss, acc in epoch_data:\n",
    "    # Each snapshot is an immutable tuple\n",
    "    snapshot = (epoch, loss, acc)\n",
    "    training_history.append(snapshot)\n",
    "\n",
    "print(\"\\nTraining History:\")\n",
    "for epoch, loss, acc in training_history:\n",
    "    print(f\"  Epoch {epoch}: loss={loss:.2f}, accuracy={acc:.2%}\")\n",
    "\n",
    "# Find best epoch (highest accuracy)\n",
    "if training_history:\n",
    "    best_epoch = max(training_history, key=lambda x: x[2])  # x[2] is accuracy\n",
    "    epoch, loss, acc = best_epoch\n",
    "    print(f\"\\nBest epoch: {epoch} with {acc:.2%} accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: game_state_manager.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.3\n",
    "# game_state_manager.py - Using tuples for immutable game snapshots\n",
    "\n",
    "# Game State Management System\n",
    "# Using tuples for immutable snapshots and lists for history\n",
    "\n",
    "# Initialize game\n",
    "game_data = {\n",
    "    \"player_name\": \"Hero\",\n",
    "    \"current_position\": (0, 0),  # Starting position as tuple\n",
    "    \"current_stats\": {\n",
    "        \"health\": 100,\n",
    "        \"score\": 0,\n",
    "        \"level\": 1\n",
    "    },\n",
    "    \"snapshots\": [],  # Will store immutable snapshots\n",
    "    \"move_history\": []  # Will store move records\n",
    "}\n",
    "\n",
    "print(\"Game initialized!\")\n",
    "print(f\"Player: {game_data['player_name']}\")\n",
    "print(f\"Starting position: {game_data['current_position']}\")\n",
    "\n",
    "# Simulate game moves\n",
    "moves = [\n",
    "    (\"right\", 1, 0, 10),   # (direction, dx, dy, points)\n",
    "    (\"up\", 0, 1, 15),\n",
    "    (\"right\", 1, 0, 20),\n",
    "    (\"down\", 0, -1, -5),   # Lost points!\n",
    "    (\"left\", -1, 0, 25)\n",
    "]\n",
    "\n",
    "print(\"\\nPlaying game:\")\n",
    "for move_num, move_data in enumerate(moves, 1):\n",
    "    direction, dx, dy, points = move_data\n",
    "    \n",
    "    # Update position (create new tuple)\n",
    "    old_x, old_y = game_data[\"current_position\"]\n",
    "    new_position = (old_x + dx, old_y + dy)\n",
    "    old_position = game_data[\"current_position\"]\n",
    "    game_data[\"current_position\"] = new_position\n",
    "    \n",
    "    # Update score\n",
    "    game_data[\"current_stats\"][\"score\"] += points\n",
    "    \n",
    "    # Create immutable snapshot of this moment\n",
    "    snapshot = (\n",
    "        move_num,\n",
    "        new_position,\n",
    "        game_data[\"current_stats\"][\"score\"],\n",
    "        game_data[\"current_stats\"][\"health\"],\n",
    "        direction\n",
    "    )\n",
    "    game_data[\"snapshots\"].append(snapshot)\n",
    "    \n",
    "    # Record the move\n",
    "    move_record = (direction, old_position, new_position, points)\n",
    "    game_data[\"move_history\"].append(move_record)\n",
    "    \n",
    "    print(f\"  Move {move_num}: {direction} to {new_position}, Score: {game_data['current_stats']['score']}\")\n",
    "\n",
    "# Analyze game history\n",
    "print(\"\\n=== Game Analysis ===\")\n",
    "print(f\"Total moves: {len(game_data['snapshots'])}\")\n",
    "print(f\"Final position: {game_data['current_position']}\")\n",
    "print(f\"Final score: {game_data['current_stats']['score']}\")\n",
    "\n",
    "# Find best scoring move\n",
    "if game_data[\"move_history\"]:\n",
    "    best_move = max(game_data[\"move_history\"], key=lambda x: x[3])  # x[3] is points\n",
    "    direction, from_pos, to_pos, points = best_move\n",
    "    print(f\"Best move: {direction} from {from_pos} to {to_pos} (+{points} points)\")\n",
    "\n",
    "# Show all snapshots\n",
    "print(\"\\n=== Game Snapshots ===\")\n",
    "for snapshot in game_data[\"snapshots\"]:\n",
    "    move, pos, score, health, direction = snapshot\n",
    "    print(f\"  After move {move}: Position {pos}, Score {score}, Health {health}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 4.3 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3.1: Color Palette Manager\n",
    "\n",
    "Create a color palette system that:\n",
    "1. Store RGB colors as tuples: red=(255,0,0), green=(0,255,0), blue=(0,0,255)\n",
    "2. Create a mixed color by averaging two color tuples\n",
    "3. Store colors in a dictionary with tuple keys for coordinates\n",
    "4. Return color information as a named tuple with fields: name, rgb, hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3.2: Game State Snapshots\n",
    "\n",
    "Build a simple game state system that:\n",
    "1. Store player position as a tuple (x, y)\n",
    "2. Save game snapshots as tuples: (turn_number, position, score, health)\n",
    "3. Maintain a list of these immutable snapshots\n",
    "4. Find the snapshot with the highest score\n",
    "5. Return game statistics as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3.3: Model Configuration Validator\n",
    "\n",
    "Create a configuration system that:\n",
    "1. Define valid model configs as tuples: (name, layers, parameters, learning_rate)\n",
    "2. Store multiple configurations\n",
    "3. Validate that configurations haven't been modified\n",
    "4. Return the smallest and largest models based on parameters\n",
    "5. Unpack and display configuration details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4.4: Dictionaries: key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: dict_creation.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.4\n",
    "# dict_creation.py - Creating dictionaries in Python\n",
    "\n",
    "# Your first dictionary - a user profile\n",
    "user = {\n",
    "    \"name\": \"Alice\",\n",
    "    \"age\": 28,\n",
    "    \"email\": \"alice@example.com\",\n",
    "    \"is_premium\": True\n",
    "}\n",
    "\n",
    "print(\"User dictionary:\", user)\n",
    "print(f\"Type: {type(user)}\")\n",
    "\n",
    "# Keys can be strings, numbers, or any immutable type (remember tuples?)\n",
    "mixed_keys = {\n",
    "    \"string_key\": \"I'm a string value\",\n",
    "    42: \"I'm accessed with the number 42\",\n",
    "    (1, 2): \"I'm accessed with the tuple (1, 2)\",\n",
    "    3.14: \"I'm accessed with 3.14\"\n",
    "}\n",
    "\n",
    "print(\"\\nMixed keys dictionary:\")\n",
    "for key, value in mixed_keys.items():\n",
    "    print(f\"  {key} -> {value}\")\n",
    "\n",
    "# Empty dictionary (ready to fill!)\n",
    "empty_dict = {}\n",
    "also_empty = dict()  # Alternative way\n",
    "print(f\"\\nEmpty dict: {empty_dict}\")\n",
    "print(f\"Also empty: {also_empty}\")\n",
    "\n",
    "# Creating from pairs\n",
    "pairs = [(\"red\", \"#FF0000\"), (\"green\", \"#00FF00\"), (\"blue\", \"#0000FF\")]\n",
    "color_codes = dict(pairs)\n",
    "print(f\"\\nColor codes from pairs: {color_codes}\")\n",
    "\n",
    "# Using dict() with keyword arguments\n",
    "person = dict(name=\"Bob\", age=30, city=\"New York\")\n",
    "print(f\"\\nPerson created with dict(): {person}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: dict_accessing.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.4\n",
    "# dict_accessing.py - Accessing dictionary values safely\n",
    "\n",
    "# AI model configuration\n",
    "model_config = {\n",
    "    \"model_name\": \"GPT-3\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 2048,\n",
    "    \"top_p\": 0.95,\n",
    "    \"frequency_penalty\": 0.5,\n",
    "    \"presence_penalty\": 0.0\n",
    "}\n",
    "\n",
    "# Access values using keys\n",
    "model = model_config[\"model_name\"]\n",
    "temp = model_config[\"temperature\"]\n",
    "print(f\"Model: {model} with temperature: {temp}\")\n",
    "\n",
    "# Safer access with get() method\n",
    "tokens = model_config.get(\"max_tokens\")\n",
    "print(f\"Max tokens: {tokens}\")\n",
    "\n",
    "# get() with default value if key doesn't exist\n",
    "stream = model_config.get(\"stream\", False)  # Default to False if not found\n",
    "print(f\"Stream enabled: {stream}\")\n",
    "\n",
    "# What happens when key doesn't exist?\n",
    "# bad_access = model_config[\"non_existent\"]  # KeyError!\n",
    "\n",
    "# Safe pattern for checking if key exists\n",
    "if \"top_p\" in model_config:\n",
    "    print(f\"Top-p sampling: {model_config['top_p']}\")\n",
    "\n",
    "# Check if key doesn't exist\n",
    "if \"api_key\" not in model_config:\n",
    "    print(\"No API key in config (good for security!)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: dict_modifying.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.4\n",
    "# dict_modifying.py - Adding, updating, and removing dictionary items\n",
    "\n",
    "# Starting with a basic AI agent state\n",
    "agent_state = {\n",
    "    \"status\": \"idle\",\n",
    "    \"messages_processed\": 0,\n",
    "    \"last_active\": None\n",
    "}\n",
    "\n",
    "print(\"Initial state:\", agent_state)\n",
    "\n",
    "# Adding new key-value pairs\n",
    "agent_state[\"model\"] = \"gpt-3.5-turbo\"\n",
    "agent_state[\"context\"] = []\n",
    "print(\"\\nAfter adding keys:\", agent_state)\n",
    "\n",
    "# Updating existing values\n",
    "agent_state[\"status\"] = \"active\"\n",
    "agent_state[\"messages_processed\"] += 1\n",
    "agent_state[\"last_active\"] = \"2024-01-15 10:30:00\"\n",
    "print(\"\\nAfter updates:\", agent_state)\n",
    "\n",
    "# Update multiple values at once\n",
    "updates = {\n",
    "    \"status\": \"processing\",\n",
    "    \"messages_processed\": 5,\n",
    "    \"error_count\": 0  # This adds a new key too!\n",
    "}\n",
    "agent_state.update(updates)\n",
    "print(\"\\nAfter batch update:\", agent_state)\n",
    "\n",
    "# Removing items\n",
    "del agent_state[\"error_count\"]  # Remove using del\n",
    "removed = agent_state.pop(\"last_active\", None)  # Remove and return value\n",
    "print(f\"\\nRemoved last_active: {removed}\")\n",
    "print(\"State after removals:\", agent_state)\n",
    "\n",
    "# Clear everything\n",
    "# agent_state.clear()  # Empties the dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: dict_methods.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.4\n",
    "# dict_methods.py - Essential dictionary methods\n",
    "\n",
    "# Sample data: User preferences for an AI assistant\n",
    "preferences = {\n",
    "    \"language\": \"en\",\n",
    "    \"voice\": \"neutral\",\n",
    "    \"speed\": \"normal\",\n",
    "    \"personality\": \"helpful\",\n",
    "    \"memory\": True\n",
    "}\n",
    "\n",
    "# keys() - Get all keys\n",
    "all_keys = preferences.keys()\n",
    "print(\"All preference keys:\", list(all_keys))\n",
    "\n",
    "# values() - Get all values\n",
    "all_values = preferences.values()\n",
    "print(\"All preference values:\", list(all_values))\n",
    "\n",
    "# items() - Get key-value pairs\n",
    "print(\"\\nAll preferences:\")\n",
    "for key, value in preferences.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# pop() with default\n",
    "removed = preferences.pop(\"non_existent\", \"default_value\")\n",
    "print(f\"\\nPopped non-existent key: {removed}\")\n",
    "\n",
    "# setdefault() - Get value or set it if missing\n",
    "theme = preferences.setdefault(\"theme\", \"dark\")\n",
    "print(f\"Theme (set to default): {theme}\")\n",
    "print(f\"Preferences now include theme: {preferences}\")\n",
    "\n",
    "# Copy dictionary (remember the list copying lesson?)\n",
    "backup = preferences.copy()\n",
    "backup[\"language\"] = \"es\"\n",
    "print(f\"\\nOriginal language: {preferences['language']}\")\n",
    "print(f\"Backup language: {backup['language']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: nested_dictionaries.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.4\n",
    "# nested_dictionaries.py - Working with complex nested data structures\n",
    "\n",
    "# Complex AI conversation data\n",
    "conversation = {\n",
    "    \"id\": \"conv_123\",\n",
    "    \"user\": {\n",
    "        \"name\": \"Alice\",\n",
    "        \"id\": \"user_456\",\n",
    "        \"preferences\": {\n",
    "            \"language\": \"en\",\n",
    "            \"style\": \"concise\"\n",
    "        }\n",
    "    },\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hi there!\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather?\"}\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"created\": \"2024-01-15\",\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"token_count\": 45\n",
    "    }\n",
    "}\n",
    "\n",
    "# Accessing nested data\n",
    "user_name = conversation[\"user\"][\"name\"]\n",
    "language = conversation[\"user\"][\"preferences\"][\"language\"]\n",
    "first_message = conversation[\"messages\"][0][\"content\"]\n",
    "token_count = conversation[\"metadata\"][\"token_count\"]\n",
    "\n",
    "print(f\"User: {user_name} (language: {language})\")\n",
    "print(f\"First message: {first_message}\")\n",
    "print(f\"Tokens used: {token_count}\")\n",
    "\n",
    "# Safely navigating nested structures\n",
    "# Use get() chains for safety\n",
    "style = conversation.get(\"user\", {}).get(\"preferences\", {}).get(\"style\", \"default\")\n",
    "print(f\"Style preference: {style}\")\n",
    "\n",
    "# Modifying nested data\n",
    "conversation[\"metadata\"][\"token_count\"] += 10\n",
    "conversation[\"user\"][\"preferences\"][\"style\"] = \"detailed\"\n",
    "print(f\"\\nUpdated token count: {conversation['metadata']['token_count']}\")\n",
    "print(f\"Updated style: {conversation['user']['preferences']['style']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: json_and_apis.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.4\n",
    "# json_and_apis.py - Working with JSON and API responses\n",
    "\n",
    "# Simulating an API response (this is what you'll get from OpenAI, etc.)\n",
    "api_response = {\n",
    "    \"id\": \"chatcmpl-123\",\n",
    "    \"object\": \"chat.completion\",\n",
    "    \"created\": 1677652288,\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"choices\": [\n",
    "        {\n",
    "            \"index\": 0,\n",
    "            \"message\": {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"The weather today is sunny with a high of 72\u00b0F.\"\n",
    "            },\n",
    "            \"finish_reason\": \"stop\"\n",
    "        }\n",
    "    ],\n",
    "    \"usage\": {\n",
    "        \"prompt_tokens\": 12,\n",
    "        \"completion_tokens\": 15,\n",
    "        \"total_tokens\": 27\n",
    "    }\n",
    "}\n",
    "\n",
    "# Extracting the actual response\n",
    "assistant_message = api_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "total_tokens = api_response[\"usage\"][\"total_tokens\"]\n",
    "model_used = api_response[\"model\"]\n",
    "\n",
    "print(f\"Model: {model_used}\")\n",
    "print(f\"Response: {assistant_message}\")\n",
    "print(f\"Tokens used: {total_tokens}\")\n",
    "\n",
    "# Converting to/from JSON (you'll use this constantly!)\n",
    "import json\n",
    "\n",
    "# Dictionary to JSON string\n",
    "json_string = json.dumps({\"name\": \"Alice\", \"age\": 30}, indent=2)\n",
    "print(f\"\\nJSON string:\\n{json_string}\")\n",
    "\n",
    "# JSON string back to dictionary\n",
    "parsed = json.loads(json_string)\n",
    "print(f\"\\nParsed back to dict: {parsed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: dict_patterns.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.4\n",
    "# dict_patterns.py - Essential dictionary patterns for AI development\n",
    "\n",
    "# Pattern 1: Configuration Management\n",
    "agent_config = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_history\": 10,\n",
    "    \"system_prompt\": \"You are a helpful assistant.\",\n",
    "    \"features\": {\n",
    "        \"memory\": True,\n",
    "        \"web_search\": False,\n",
    "        \"code_execution\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Agent Configuration:\")\n",
    "print(f\"  Model: {agent_config['model']}\")\n",
    "print(f\"  Temperature: {agent_config['temperature']}\")\n",
    "\n",
    "# Update configuration\n",
    "agent_config[\"temperature\"] = 0.9\n",
    "agent_config[\"max_history\"] = 20\n",
    "print(f\"\\nUpdated config:\")\n",
    "print(f\"  Temperature: {agent_config['temperature']}\")\n",
    "print(f\"  Max history: {agent_config['max_history']}\")\n",
    "\n",
    "# Check if feature is enabled\n",
    "feature_to_check = \"memory\"\n",
    "if feature_to_check in agent_config[\"features\"]:\n",
    "    is_enabled = agent_config[\"features\"][feature_to_check]\n",
    "    print(f\"  {feature_to_check} enabled: {is_enabled}\")\n",
    "\n",
    "# Pattern 2: Response Cache\n",
    "response_cache = {}\n",
    "\n",
    "# Create cache key (using tuple as key!)\n",
    "prompt1 = \"What is Python?\"\n",
    "model1 = \"gpt-3.5\"\n",
    "cache_key1 = (prompt1.lower().strip(), model1)\n",
    "\n",
    "# Store response in cache\n",
    "response_cache[cache_key1] = {\n",
    "    \"response\": \"Python is a programming language...\",\n",
    "    \"timestamp\": \"2024-01-15 10:30:00\",\n",
    "    \"hits\": 0\n",
    "}\n",
    "\n",
    "# Check cache\n",
    "prompt2 = \"what is python?\"  # Different case\n",
    "model2 = \"gpt-3.5\"\n",
    "cache_key2 = (prompt2.lower().strip(), model2)\n",
    "\n",
    "if cache_key2 in response_cache:\n",
    "    cached_data = response_cache[cache_key2]\n",
    "    cached_data[\"hits\"] += 1\n",
    "    print(f\"\\nCache hit! Response: {cached_data['response'][:30]}...\")\n",
    "    print(f\"Cache hits: {cached_data['hits']}\")\n",
    "\n",
    "# Pattern 3: Entity Tracking\n",
    "entities = {}\n",
    "\n",
    "# Track entities mentioned in conversation\n",
    "entity_mentions = [\n",
    "    (\"Alice\", \"person\", {\"age\": 30, \"role\": \"developer\"}),\n",
    "    (\"Python\", \"technology\", {\"version\": \"3.11\"}),\n",
    "    (\"Alice\", \"person\", {\"city\": \"New York\"}),  # Update Alice\n",
    "    (\"Bob\", \"person\", {\"age\": 25})\n",
    "]\n",
    "\n",
    "for name, entity_type, attributes in entity_mentions:\n",
    "    if name not in entities:\n",
    "        entities[name] = {\n",
    "            \"type\": entity_type,\n",
    "            \"mentions\": 0,\n",
    "            \"attributes\": {}\n",
    "        }\n",
    "    \n",
    "    entities[name][\"mentions\"] += 1\n",
    "    entities[name][\"attributes\"].update(attributes)\n",
    "\n",
    "print(\"\\nEntity Tracking:\")\n",
    "for name, data in entities.items():\n",
    "    print(f\"  {name} ({data['type']}): {data['mentions']} mentions\")\n",
    "    print(f\"    Attributes: {data['attributes']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: conversation_memory.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.4\n",
    "# conversation_memory.py - Building a memory system with dictionaries\n",
    "\n",
    "# Conversation memory system using dictionaries\n",
    "memory_system = {\n",
    "    \"conversations\": {},  # Will store conversations by user_id\n",
    "    \"user_profiles\": {},  # Will store user information\n",
    "    \"context_cache\": {},  # Recent context by user\n",
    "    \"max_size\": 10       # Maximum messages per conversation\n",
    "}\n",
    "\n",
    "# Initialize users\n",
    "user_ids = [\"user_123\", \"user_456\"]\n",
    "for user_id in user_ids:\n",
    "    memory_system[\"conversations\"][user_id] = []\n",
    "    memory_system[\"user_profiles\"][user_id] = {\n",
    "        \"name\": f\"User_{user_id[-3:]}\",\n",
    "        \"first_seen\": \"2024-01-15\",\n",
    "        \"message_count\": 0,\n",
    "        \"topics\": []  # Topics discussed\n",
    "    }\n",
    "\n",
    "print(\"Memory system initialized for users:\", user_ids)\n",
    "\n",
    "# Add messages for user_123\n",
    "messages = [\n",
    "    (\"user\", \"Hello AI!\", \"2024-01-15 10:30:00\"),\n",
    "    (\"assistant\", \"Hello! How can I help you?\", \"2024-01-15 10:30:01\"),\n",
    "    (\"user\", \"Tell me about Python lists\", \"2024-01-15 10:30:15\"),\n",
    "    (\"assistant\", \"Lists are ordered collections in Python\", \"2024-01-15 10:30:16\"),\n",
    "    (\"user\", \"How do I add items?\", \"2024-01-15 10:30:30\"),\n",
    "    (\"assistant\", \"Use append() to add items to a list\", \"2024-01-15 10:30:31\"),\n",
    "]\n",
    "\n",
    "current_user = \"user_123\"\n",
    "print(f\"\\nAdding messages for {current_user}:\")\n",
    "\n",
    "for role, content, timestamp in messages:\n",
    "    # Create message record\n",
    "    message = {\n",
    "        \"role\": role,\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"tokens\": len(content.split()) * 2  # Rough estimate\n",
    "    }\n",
    "    \n",
    "    # Add to conversation\n",
    "    memory_system[\"conversations\"][current_user].append(message)\n",
    "    \n",
    "    # Update user profile\n",
    "    if role == \"user\":\n",
    "        memory_system[\"user_profiles\"][current_user][\"message_count\"] += 1\n",
    "        \n",
    "        # Simple topic extraction\n",
    "        if \"python\" in content.lower():\n",
    "            if \"programming\" not in memory_system[\"user_profiles\"][current_user][\"topics\"]:\n",
    "                memory_system[\"user_profiles\"][current_user][\"topics\"].append(\"programming\")\n",
    "        if \"list\" in content.lower():\n",
    "            if \"data structures\" not in memory_system[\"user_profiles\"][current_user][\"topics\"]:\n",
    "                memory_system[\"user_profiles\"][current_user][\"topics\"].append(\"data structures\")\n",
    "    \n",
    "    print(f\"  Added: {role} - {content[:30]}...\")\n",
    "    \n",
    "    # Check if exceeded max size\n",
    "    if len(memory_system[\"conversations\"][current_user]) > memory_system[\"max_size\"]:\n",
    "        removed = memory_system[\"conversations\"][current_user].pop(0)\n",
    "        print(f\"  Memory full! Removed oldest message\")\n",
    "\n",
    "# Get context for user\n",
    "context_size = 3\n",
    "user_conversation = memory_system[\"conversations\"][current_user]\n",
    "if len(user_conversation) >= context_size:\n",
    "    recent_context = user_conversation[-context_size:]\n",
    "else:\n",
    "    recent_context = user_conversation.copy()\n",
    "\n",
    "# Cache the context\n",
    "memory_system[\"context_cache\"][current_user] = {\n",
    "    \"messages\": recent_context,\n",
    "    \"summary\": f\"{len(recent_context)} recent messages\",\n",
    "    \"total_tokens\": sum(m[\"tokens\"] for m in recent_context)\n",
    "}\n",
    "\n",
    "print(f\"\\nContext for {current_user}:\")\n",
    "for msg in recent_context:\n",
    "    print(f\"  [{msg['timestamp']}] {msg['role']}: {msg['content'][:40]}...\")\n",
    "\n",
    "# Display user profile\n",
    "profile = memory_system[\"user_profiles\"][current_user]\n",
    "print(f\"\\nUser Profile for {current_user}:\")\n",
    "print(f\"  Name: {profile['name']}\")\n",
    "print(f\"  Messages sent: {profile['message_count']}\")\n",
    "print(f\"  Topics: {profile['topics']}\")\n",
    "print(f\"  First seen: {profile['first_seen']}\")\n",
    "\n",
    "# Search for keywords\n",
    "search_term = \"list\"\n",
    "print(f\"\\nSearching for '{search_term}' in conversations:\")\n",
    "found_messages = []\n",
    "for msg in memory_system[\"conversations\"][current_user]:\n",
    "    if search_term.lower() in msg[\"content\"].lower():\n",
    "        found_messages.append(msg)\n",
    "        print(f\"  Found in {msg['role']} message: {msg['content'][:50]}...\")\n",
    "\n",
    "print(f\"Total matches: {len(found_messages)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: advanced_techniques.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.4\n",
    "# advanced_techniques.py - Advanced dictionary techniques\n",
    "\n",
    "# Merging dictionaries\n",
    "defaults = {\"color\": \"blue\", \"size\": \"medium\", \"quantity\": 1}\n",
    "user_choices = {\"color\": \"red\", \"quantity\": 3}\n",
    "\n",
    "# Merge (user choices override defaults)\n",
    "final = {**defaults, **user_choices}\n",
    "print(f\"Final options: {final}\")\n",
    "\n",
    "# Dictionary comprehensions\n",
    "# Square numbers\n",
    "squares = {n: n**2 for n in range(1, 6)}\n",
    "print(f\"\\nSquares: {squares}\")\n",
    "\n",
    "# Filter a dictionary\n",
    "scores = {\"Alice\": 85, \"Bob\": 92, \"Charlie\": 78, \"Diana\": 95}\n",
    "high_scores = {name: score for name, score in scores.items() if score >= 90}\n",
    "print(f\"High scores: {high_scores}\")\n",
    "\n",
    "# Invert a dictionary (swap keys and values)\n",
    "color_codes = {\"red\": \"#FF0000\", \"green\": \"#00FF00\", \"blue\": \"#0000FF\"}\n",
    "code_to_color = {code: color for color, code in color_codes.items()}\n",
    "print(f\"Inverted: {code_to_color}\")\n",
    "\n",
    "# Grouping data\n",
    "students = [\n",
    "    {\"name\": \"Alice\", \"grade\": \"A\"},\n",
    "    {\"name\": \"Bob\", \"grade\": \"B\"},\n",
    "    {\"name\": \"Charlie\", \"grade\": \"A\"},\n",
    "    {\"name\": \"Diana\", \"grade\": \"B\"},\n",
    "    {\"name\": \"Eve\", \"grade\": \"A\"}\n",
    "]\n",
    "\n",
    "# Group by grade\n",
    "by_grade = {}\n",
    "for student in students:\n",
    "    grade = student[\"grade\"]\n",
    "    if grade not in by_grade:\n",
    "        by_grade[grade] = []\n",
    "    by_grade[grade].append(student[\"name\"])\n",
    "\n",
    "print(\"\\nStudents by grade:\")\n",
    "for grade, names in by_grade.items():\n",
    "    print(f\"  Grade {grade}: {names}\")\n",
    "\n",
    "# Word frequency counter\n",
    "text = \"the quick brown fox jumps over the lazy dog the fox\"\n",
    "word_counter = {}\n",
    "\n",
    "for word in text.split():\n",
    "    if word in word_counter:\n",
    "        word_counter[word] += 1\n",
    "    else:\n",
    "        word_counter[word] = 1\n",
    "\n",
    "print(\"\\nWord frequencies:\")\n",
    "for word, count in word_counter.items():\n",
    "    print(f\"  {word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 4.4 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.4.1: Product Inventory System\n",
    "\n",
    "Create an inventory system that:\n",
    "1. Store products with name, price, and quantity\n",
    "2. Add new products\n",
    "3. Update quantities\n",
    "4. Calculate total inventory value\n",
    "5. Find products below a certain stock level\n",
    "6. Generate a restock report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.4.2: Student Grade Manager\n",
    "\n",
    "Build a grade management system that:\n",
    "1. Store students with their grades in multiple subjects\n",
    "2. Add new students and grades\n",
    "3. Calculate average grade per student\n",
    "4. Find the top performer\n",
    "5. Generate a report card for a specific student\n",
    "6. List all students failing any subject (grade \\< 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.4.3: API Response Handler\n",
    "\n",
    "Create a system that:\n",
    "1. Process mock API responses (nested dictionaries)\n",
    "2. Extract specific fields safely\n",
    "3. Handle missing keys gracefully\n",
    "4. Count total API calls by endpoint\n",
    "5. Cache responses to avoid duplicate calls\n",
    "6. Generate usage statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4.5: Sets and their operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: set_creation.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.5\n",
    "# set_creation.py - Creating sets in Python\n",
    "\n",
    "# Creating sets - notice just values, no key:value pairs\n",
    "fruits = {\"apple\", \"banana\", \"orange\", \"grape\"}\n",
    "print(f\"Fruits set: {fruits}\")\n",
    "print(f\"Type: {type(fruits)}\")\n",
    "\n",
    "# Sets automatically remove duplicates!\n",
    "numbers = {1, 2, 3, 2, 1, 4, 3, 5}  # Duplicates: 1, 2, 3\n",
    "print(f\"Numbers set: {numbers}\")  # Only unique values remain\n",
    "\n",
    "# Creating from a list (removes duplicates)\n",
    "temperatures = [22, 24, 22, 23, 24, 25, 23, 22]\n",
    "unique_temps = set(temperatures)\n",
    "print(f\"Original list: {temperatures}\")\n",
    "print(f\"Unique temperatures: {unique_temps}\")\n",
    "\n",
    "# Empty set - CAREFUL with this one!\n",
    "# wrong_way = {}  # This creates an empty DICTIONARY, not a set!\n",
    "right_way = set()  # This creates an empty set\n",
    "also_right = {1, 2, 3}\n",
    "also_right.clear()  # Now it's empty\n",
    "print(f\"Empty set: {right_way}\")\n",
    "print(f\"Type of {{}}: {type({})}\")  # It's a dict!\n",
    "print(f\"Type of set(): {type(set())}\")  # It's a set!\n",
    "\n",
    "# Creating from a string (gets unique characters)\n",
    "word = \"programming\"\n",
    "unique_letters = set(word)\n",
    "print(f\"Unique letters in '{word}': {unique_letters}\")\n",
    "\n",
    "# Creating from range\n",
    "evens = set(range(0, 10, 2))\n",
    "print(f\"Even numbers: {evens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: set_operations.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.5\n",
    "# set_operations.py - Basic set operations: add, remove, check\n",
    "\n",
    "# Working with a set of skills for an AI developer\n",
    "skills = {\"Python\", \"Machine Learning\", \"Data Analysis\"}\n",
    "print(f\"Initial skills: {skills}\")\n",
    "\n",
    "# Adding elements\n",
    "skills.add(\"Deep Learning\")\n",
    "skills.add(\"Python\")  # Try to add duplicate - nothing happens!\n",
    "print(f\"After adding: {skills}\")\n",
    "\n",
    "# Adding multiple elements\n",
    "new_skills = [\"Statistics\", \"SQL\", \"Cloud Computing\", \"SQL\"]  # Note: SQL appears twice\n",
    "skills.update(new_skills)  # Adds all unique elements\n",
    "print(f\"After update: {skills}\")\n",
    "\n",
    "# Removing elements - different methods\n",
    "skills.remove(\"SQL\")  # Removes SQL (raises error if not found)\n",
    "print(f\"After remove: {skills}\")\n",
    "\n",
    "# Safe removal with discard (no error if not found)\n",
    "skills.discard(\"JavaScript\")  # Not in set, but no error\n",
    "skills.discard(\"Statistics\")  # Removes if present\n",
    "print(f\"After discard: {skills}\")\n",
    "\n",
    "# Pop removes and returns an arbitrary element\n",
    "if skills:  # Check if not empty\n",
    "    popped = skills.pop()\n",
    "    print(f\"Popped: {popped}\")\n",
    "    print(f\"Remaining: {skills}\")\n",
    "\n",
    "# Checking membership (SUPER FAST!)\n",
    "ai_skills = {\"Python\", \"TensorFlow\", \"PyTorch\", \"Scikit-learn\", \"Pandas\"}\n",
    "\n",
    "# This is incredibly fast even with huge sets\n",
    "if \"Python\" in ai_skills:\n",
    "    print(\"Python is in the skill set\")\n",
    "\n",
    "if \"Java\" not in ai_skills:\n",
    "    print(\"Java is not in the skill set\")\n",
    "\n",
    "# Length and clearing\n",
    "print(f\"Number of skills: {len(ai_skills)}\")\n",
    "# ai_skills.clear()  # Removes all elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: set_mathematics.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.5\n",
    "# set_mathematics.py - Mathematical set operations\n",
    "\n",
    "# Two teams and their programming languages\n",
    "team_a = {\"Python\", \"JavaScript\", \"Go\", \"Rust\"}\n",
    "team_b = {\"Python\", \"Java\", \"JavaScript\", \"C++\"}\n",
    "\n",
    "print(f\"Team A knows: {team_a}\")\n",
    "print(f\"Team B knows: {team_b}\")\n",
    "\n",
    "# UNION - All languages known by either team (OR)\n",
    "all_languages = team_a | team_b  # Using | operator\n",
    "# OR\n",
    "all_languages = team_a.union(team_b)  # Using method\n",
    "print(f\"\\nAll languages (union): {all_languages}\")\n",
    "\n",
    "# INTERSECTION - Languages known by both teams (AND)\n",
    "common_languages = team_a & team_b  # Using & operator\n",
    "# OR\n",
    "common_languages = team_a.intersection(team_b)  # Using method\n",
    "print(f\"Common languages (intersection): {common_languages}\")\n",
    "\n",
    "# DIFFERENCE - Languages only Team A knows\n",
    "team_a_exclusive = team_a - team_b  # Using - operator\n",
    "# OR\n",
    "team_a_exclusive = team_a.difference(team_b)  # Using method\n",
    "print(f\"Only Team A knows (difference): {team_a_exclusive}\")\n",
    "\n",
    "# SYMMETRIC DIFFERENCE - Languages known by one team but not both (XOR)\n",
    "unique_to_one_team = team_a ^ team_b  # Using ^ operator\n",
    "# OR\n",
    "unique_to_one_team = team_a.symmetric_difference(team_b)  # Using method\n",
    "print(f\"Known by only one team (symmetric difference): {unique_to_one_team}\")\n",
    "\n",
    "# Real-world example: Finding common interests\n",
    "alice_interests = {\"AI\", \"Python\", \"Reading\", \"Hiking\", \"Photography\"}\n",
    "bob_interests = {\"Python\", \"Gaming\", \"AI\", \"Cooking\", \"Photography\"}\n",
    "\n",
    "common = alice_interests & bob_interests\n",
    "print(f\"\\nAlice and Bob both like: {common}\")\n",
    "\n",
    "alice_unique = alice_interests - bob_interests\n",
    "print(f\"Only Alice likes: {alice_unique}\")\n",
    "\n",
    "all_interests = alice_interests | bob_interests\n",
    "print(f\"All interests combined: {all_interests}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: set_comparisons.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.5\n",
    "# set_comparisons.py - Subset and superset operations\n",
    "\n",
    "# AI technology hierarchy\n",
    "ml_basics = {\"Python\", \"Statistics\", \"Linear Algebra\"}\n",
    "ml_advanced = {\"Python\", \"Statistics\", \"Linear Algebra\", \"Deep Learning\", \"NLP\"}\n",
    "data_science = {\"Python\", \"Statistics\", \"SQL\", \"Visualization\"}\n",
    "\n",
    "# Is ml_basics a subset of ml_advanced?\n",
    "print(f\"ML basics \u2286 ML advanced? {ml_basics.issubset(ml_advanced)}\")\n",
    "print(f\"ML basics \u2286 ML advanced? {ml_basics <= ml_advanced}\")  # Alternative\n",
    "\n",
    "# Is ml_advanced a superset of ml_basics?\n",
    "print(f\"ML advanced \u2287 ML basics? {ml_advanced.issuperset(ml_basics)}\")\n",
    "print(f\"ML advanced \u2287 ML basics? {ml_advanced >= ml_basics}\")  # Alternative\n",
    "\n",
    "# Are ml_basics and data_science disjoint (no common elements)?\n",
    "print(f\"ML basics \u2229 Data Science = \u2205? {ml_basics.isdisjoint(data_science)}\")\n",
    "# False, because they share Python and Statistics\n",
    "\n",
    "# Proper subset (subset but not equal)\n",
    "print(f\"ML basics \u2282 ML advanced? {ml_basics < ml_advanced}\")\n",
    "print(f\"ML basics = ML basics? {ml_basics == ml_basics}\")\n",
    "\n",
    "# Practical example: Permission checking\n",
    "user_permissions = {\"read\", \"write\", \"execute\"}\n",
    "required_permissions = {\"read\", \"write\"}\n",
    "admin_permissions = {\"read\", \"write\", \"execute\", \"delete\", \"admin\"}\n",
    "\n",
    "# Check if user has all required permissions\n",
    "has_access = required_permissions.issubset(user_permissions)\n",
    "print(f\"\\nUser has required permissions? {has_access}\")\n",
    "\n",
    "# Check if user is admin (has all admin permissions)\n",
    "is_admin = user_permissions == admin_permissions\n",
    "print(f\"User is admin? {is_admin}\")\n",
    "\n",
    "# Check if user has ANY admin permission\n",
    "has_some_admin = not user_permissions.isdisjoint(admin_permissions)\n",
    "print(f\"User has some admin permissions? {has_some_admin}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: frozen_sets.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.5\n",
    "# frozen_sets.py - Working with immutable sets\n",
    "\n",
    "# Creating frozen sets\n",
    "constants = frozenset([3.14159, 2.71828, 1.41421])\n",
    "print(f\"Mathematical constants: {constants}\")\n",
    "\n",
    "# Frozen sets can be dictionary keys (regular sets cannot!)\n",
    "user_groups = {\n",
    "    frozenset([\"admin\", \"user\"]): \"Full Access\",\n",
    "    frozenset([\"user\"]): \"Limited Access\",\n",
    "    frozenset([\"guest\"]): \"Read Only\"\n",
    "}\n",
    "\n",
    "current_user_groups = frozenset([\"user\"])\n",
    "access_level = user_groups.get(current_user_groups, \"No Access\")\n",
    "print(f\"User access level: {access_level}\")\n",
    "\n",
    "# Frozen sets support all non-mutating operations\n",
    "set1 = frozenset([1, 2, 3])\n",
    "set2 = frozenset([2, 3, 4])\n",
    "\n",
    "print(f\"Union: {set1 | set2}\")\n",
    "print(f\"Intersection: {set1 & set2}\")\n",
    "print(f\"Difference: {set1 - set2}\")\n",
    "\n",
    "# But you can't modify them\n",
    "# set1.add(4)  # This would raise an AttributeError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: text_processing.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.5\n",
    "# text_processing.py - Using sets for natural language processing\n",
    "\n",
    "# Text analysis using sets\n",
    "text1 = \"The quick brown fox jumps over the lazy dog and the dog runs away with the fox\"\n",
    "text2 = \"Machine learning is a subset of artificial intelligence and artificial intelligence is the future\"\n",
    "\n",
    "# Process text 1\n",
    "words1 = text1.lower().split()\n",
    "vocabulary1 = set(words1)  # Unique words\n",
    "\n",
    "# Process text 2\n",
    "words2 = text2.lower().split()\n",
    "vocabulary2 = set(words2)\n",
    "\n",
    "# Common English stop words\n",
    "stop_words = {\"the\", \"is\", \"at\", \"which\", \"on\", \"a\", \"an\", \"and\", \"or\", \"but\", \"in\", \"with\", \"to\", \"for\", \"of\"}\n",
    "\n",
    "# Content words (excluding stop words)\n",
    "content_words1 = vocabulary1 - stop_words\n",
    "content_words2 = vocabulary2 - stop_words\n",
    "\n",
    "# Analysis\n",
    "print(\"Text 1 Analysis:\")\n",
    "print(f\"  Total words: {len(words1)}\")\n",
    "print(f\"  Unique words: {len(vocabulary1)}\")\n",
    "print(f\"  Content words: {content_words1}\")\n",
    "print(f\"  Lexical diversity: {len(vocabulary1) / len(words1):.2f}\")\n",
    "\n",
    "print(\"\\nText 2 Analysis:\")\n",
    "print(f\"  Total words: {len(words2)}\")\n",
    "print(f\"  Unique words: {len(vocabulary2)}\")\n",
    "print(f\"  Content words: {content_words2}\")\n",
    "print(f\"  Lexical diversity: {len(vocabulary2) / len(words2):.2f}\")\n",
    "\n",
    "# Compare vocabularies\n",
    "print(f\"\\nCommon content words: {content_words1 & content_words2}\")\n",
    "print(f\"Words only in text 1: {content_words1 - content_words2}\")\n",
    "print(f\"Words only in text 2: {content_words2 - content_words1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: set_patterns.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.5\n",
    "# set_patterns.py - Essential patterns for AI development\n",
    "\n",
    "# Pattern 1: Duplicate Detection in Datasets\n",
    "dataset = {\n",
    "    \"seen_ids\": set(),\n",
    "    \"duplicates\": [],\n",
    "    \"unique_data\": []\n",
    "}\n",
    "\n",
    "# Sample data with duplicates\n",
    "samples = [\n",
    "    (\"id_001\", \"data1\"),\n",
    "    (\"id_002\", \"data2\"),\n",
    "    (\"id_001\", \"data1_duplicate\"),  # Duplicate!\n",
    "    (\"id_003\", \"data3\"),\n",
    "    (\"id_002\", \"data2_duplicate\"),  # Duplicate!\n",
    "]\n",
    "\n",
    "print(\"Processing dataset:\")\n",
    "for sample_id, data in samples:\n",
    "    if sample_id in dataset[\"seen_ids\"]:\n",
    "        dataset[\"duplicates\"].append((sample_id, data))\n",
    "        print(f\"  Duplicate detected: {sample_id}\")\n",
    "    else:\n",
    "        dataset[\"seen_ids\"].add(sample_id)\n",
    "        dataset[\"unique_data\"].append((sample_id, data))\n",
    "        print(f\"  Added unique sample: {sample_id}\")\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Total unique: {len(dataset['seen_ids'])}\")\n",
    "print(f\"  Duplicates found: {len(dataset['duplicates'])}\")\n",
    "\n",
    "# Pattern 2: Feature Selection for ML\n",
    "all_features = {\"age\", \"income\", \"education\", \"location\", \"gender\", \"occupation\"}\n",
    "selected_features = set()\n",
    "excluded_features = set()\n",
    "\n",
    "# Select features\n",
    "features_to_add = [\"age\", \"income\", \"education\", \"invalid_feature\"]\n",
    "valid_features = set(features_to_add) & all_features\n",
    "invalid_features = set(features_to_add) - all_features\n",
    "\n",
    "if invalid_features:\n",
    "    print(f\"\\nWarning: Invalid features ignored: {invalid_features}\")\n",
    "\n",
    "selected_features.update(valid_features)\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# Exclude features\n",
    "excluded_features.add(\"gender\")  # Remove for privacy\n",
    "selected_features -= excluded_features\n",
    "\n",
    "# Get unused features\n",
    "unused_features = all_features - selected_features - excluded_features\n",
    "print(f\"Final features: {selected_features}\")\n",
    "print(f\"Unused features: {unused_features}\")\n",
    "\n",
    "# Pattern 3: User Session Tracking\n",
    "session_tracker = {\n",
    "    \"active_sessions\": set(),\n",
    "    \"completed_sessions\": set(),\n",
    "    \"all_users\": set()\n",
    "}\n",
    "\n",
    "# Simulate user activity\n",
    "actions = [\n",
    "    (\"start\", \"user1\"),\n",
    "    (\"start\", \"user2\"),\n",
    "    (\"start\", \"user3\"),\n",
    "    (\"end\", \"user1\"),\n",
    "    (\"start\", \"user1\"),  # Returning user\n",
    "    (\"start\", \"user4\"),\n",
    "    (\"end\", \"user2\"),\n",
    "]\n",
    "\n",
    "print(\"\\nSession tracking:\")\n",
    "for action, user_id in actions:\n",
    "    if action == \"start\":\n",
    "        if user_id in session_tracker[\"active_sessions\"]:\n",
    "            print(f\"  {user_id} already has active session\")\n",
    "        else:\n",
    "            session_tracker[\"active_sessions\"].add(user_id)\n",
    "            session_tracker[\"all_users\"].add(user_id)\n",
    "            print(f\"  Session started for {user_id}\")\n",
    "    else:  # end\n",
    "        if user_id not in session_tracker[\"active_sessions\"]:\n",
    "            print(f\"  No active session for {user_id}\")\n",
    "        else:\n",
    "            session_tracker[\"active_sessions\"].remove(user_id)\n",
    "            session_tracker[\"completed_sessions\"].add(user_id)\n",
    "            print(f\"  Session ended for {user_id}\")\n",
    "\n",
    "# Calculate metrics\n",
    "active_count = len(session_tracker[\"active_sessions\"])\n",
    "total_users = len(session_tracker[\"all_users\"])\n",
    "returning_users = len(session_tracker[\"completed_sessions\"])\n",
    "new_users = len(session_tracker[\"all_users\"] - session_tracker[\"completed_sessions\"])\n",
    "\n",
    "print(f\"\\nSession Metrics:\")\n",
    "print(f\"  Active now: {active_count}\")\n",
    "print(f\"  Total users: {total_users}\")\n",
    "print(f\"  Returning users: {returning_users}\")\n",
    "print(f\"  New users: {new_users}\")\n",
    "print(f\"  Active user IDs: {session_tracker['active_sessions']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: set_comprehensions.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.5\n",
    "# set_comprehensions.py - Creating sets elegantly\n",
    "\n",
    "# Basic set comprehension\n",
    "squares = {x**2 for x in range(10)}\n",
    "print(f\"Squares: {squares}\")\n",
    "\n",
    "# With condition\n",
    "even_squares = {x**2 for x in range(10) if x % 2 == 0}\n",
    "print(f\"Even squares: {even_squares}\")\n",
    "\n",
    "# From string - unique words longer than 3 characters\n",
    "text = \"the quick brown fox jumps over the lazy fox\"\n",
    "long_words = {word for word in text.split() if len(word) > 3}\n",
    "print(f\"Long words: {long_words}\")\n",
    "\n",
    "# Normalizing data\n",
    "emails = [\"Alice@EXAMPLE.com\", \"bob@example.com\", \"ALICE@Example.com\", \"charlie@test.com\"]\n",
    "unique_emails = {email.lower() for email in emails}\n",
    "print(f\"Unique emails (normalized): {unique_emails}\")\n",
    "\n",
    "# Extracting from nested data\n",
    "users = [\n",
    "    {\"name\": \"Alice\", \"tags\": [\"python\", \"ai\", \"ml\"]},\n",
    "    {\"name\": \"Bob\", \"tags\": [\"python\", \"web\", \"api\"]},\n",
    "    {\"name\": \"Charlie\", \"tags\": [\"ai\", \"data\", \"python\"]}\n",
    "]\n",
    "\n",
    "all_tags = {tag for user in users for tag in user[\"tags\"]}\n",
    "print(f\"All unique tags: {all_tags}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: set_performance.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.5\n",
    "# set_performance.py - Why sets are incredibly fast\n",
    "\n",
    "import time\n",
    "\n",
    "# Create large collections\n",
    "large_list = list(range(1000000))\n",
    "large_set = set(range(1000000))\n",
    "\n",
    "# Test membership with list (slow for large lists)\n",
    "start = time.time()\n",
    "result = 999999 in large_list  # Has to check each element until found\n",
    "list_time = time.time() - start\n",
    "\n",
    "# Test membership with set (always fast)\n",
    "start = time.time()\n",
    "result = 999999 in large_set  # Direct lookup\n",
    "set_time = time.time() - start\n",
    "\n",
    "print(f\"List lookup time: {list_time:.6f} seconds\")\n",
    "print(f\"Set lookup time: {set_time:.6f} seconds\")\n",
    "print(f\"Set is {list_time/set_time:.0f}x faster!\")\n",
    "\n",
    "# Practical example: Checking many items\n",
    "words_to_check = [\"python\", \"programming\", \"ai\", \"machine\", \"learning\"] * 1000\n",
    "valid_words = {\"python\", \"programming\", \"ai\", \"computer\", \"science\", \"data\"}\n",
    "\n",
    "# Using set for validation (fast)\n",
    "start = time.time()\n",
    "valid_count = sum(1 for word in words_to_check if word in valid_words)\n",
    "print(f\"\\nValidation with set: {time.time() - start:.4f} seconds\")\n",
    "print(f\"Found {valid_count} valid words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: recommendation_system.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.5\n",
    "# recommendation_system.py - Building a recommendation engine with sets\n",
    "\n",
    "# Simple recommendation system using set operations\n",
    "\n",
    "# User interests database\n",
    "user_interests = {\n",
    "    \"alice\": {\"python\", \"ai\", \"machine-learning\", \"data-science\"},\n",
    "    \"bob\": {\"javascript\", \"web\", \"react\", \"node\"},\n",
    "    \"charlie\": {\"python\", \"ai\", \"deep-learning\", \"nlp\"},\n",
    "    \"diana\": {\"python\", \"web\", \"django\", \"api\"}\n",
    "}\n",
    "\n",
    "# Content tags database\n",
    "content_items = {\n",
    "    \"article_1\": {\"python\", \"tutorial\", \"beginners\"},\n",
    "    \"article_2\": {\"ai\", \"machine-learning\", \"python\"},\n",
    "    \"article_3\": {\"javascript\", \"react\", \"tutorial\"},\n",
    "    \"article_4\": {\"python\", \"django\", \"web\"},\n",
    "    \"article_5\": {\"deep-learning\", \"nlp\", \"ai\"},\n",
    "    \"video_1\": {\"python\", \"data-science\", \"pandas\"},\n",
    "    \"video_2\": {\"node\", \"javascript\", \"api\"}\n",
    "}\n",
    "\n",
    "# User viewing history\n",
    "user_history = {\n",
    "    \"alice\": {\"article_1\", \"article_2\"},\n",
    "    \"bob\": {\"article_3\"},\n",
    "    \"charlie\": set(),\n",
    "    \"diana\": {\"article_4\"}\n",
    "}\n",
    "\n",
    "# Generate recommendations for each user\n",
    "print(\"Generating recommendations:\\n\")\n",
    "for username in user_interests:\n",
    "    user_int = user_interests[username]\n",
    "    viewed = user_history.get(username, set())\n",
    "    \n",
    "    # Find unviewed content\n",
    "    all_content = set(content_items.keys())\n",
    "    unviewed = all_content - viewed\n",
    "    \n",
    "    # Score each unviewed content\n",
    "    recommendations = []\n",
    "    for content_id in unviewed:\n",
    "        content_tags = content_items[content_id]\n",
    "        \n",
    "        # Calculate relevance (number of matching tags)\n",
    "        relevance = len(user_int & content_tags)\n",
    "        \n",
    "        if relevance > 0:\n",
    "            recommendations.append((content_id, relevance))\n",
    "    \n",
    "    # Sort by relevance\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Display top 3 recommendations\n",
    "    print(f\"{username}'s recommendations:\")\n",
    "    top_recs = recommendations[:3]\n",
    "    if top_recs:\n",
    "        for content_id, score in top_recs:\n",
    "            print(f\"  {content_id}: relevance score {score}\")\n",
    "    else:\n",
    "        print(f\"  No recommendations found\")\n",
    "    print()\n",
    "\n",
    "# Find similar users (Jaccard similarity)\n",
    "print(\"Finding similar users:\\n\")\n",
    "user_list = list(user_interests.keys())\n",
    "for i in range(len(user_list)):\n",
    "    for j in range(i + 1, len(user_list)):\n",
    "        user1 = user_list[i]\n",
    "        user2 = user_list[j]\n",
    "        \n",
    "        interests1 = user_interests[user1]\n",
    "        interests2 = user_interests[user2]\n",
    "        \n",
    "        # Calculate Jaccard similarity\n",
    "        intersection = len(interests1 & interests2)\n",
    "        union = len(interests1 | interests2)\n",
    "        \n",
    "        if union > 0:\n",
    "            similarity = intersection / union\n",
    "            if similarity > 0.3:  # Threshold\n",
    "                print(f\"{user1} and {user2}: {similarity:.2f} similarity\")\n",
    "                print(f\"  Common interests: {interests1 & interests2}\")\n",
    "\n",
    "# Popular content analysis\n",
    "print(\"\\nPopular content (viewed by multiple users):\")\n",
    "all_viewed = set()\n",
    "for viewed_set in user_history.values():\n",
    "    all_viewed |= viewed_set\n",
    "\n",
    "view_counts = {}\n",
    "for content_id in all_viewed:\n",
    "    count = sum(1 for viewed in user_history.values() if content_id in viewed)\n",
    "    if count > 1:\n",
    "        view_counts[content_id] = count\n",
    "\n",
    "for content_id, count in view_counts.items():\n",
    "    print(f\"  {content_id}: {count} views\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 4.5 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.5.1: Email List Manager\n",
    "\n",
    "Create a system that:\n",
    "1. Manage email lists for different campaigns\n",
    "2. Add emails to lists (no duplicates allowed)\n",
    "3. Find common subscribers between campaigns\n",
    "4. Identify exclusive subscribers for each campaign\n",
    "5. Merge campaign lists without duplicates\n",
    "6. Generate statistics about overlap between campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.5.2: Skill Matcher\n",
    "\n",
    "Build a job matching system that:\n",
    "1. Store job requirements as sets of skills\n",
    "2. Store candidate skills as sets\n",
    "3. Find perfect matches (candidate has all required skills)\n",
    "4. Find partial matches with match percentage\n",
    "5. Identify missing skills for each candidate\n",
    "6. Recommend training based on skill gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.5.3: Document Similarity Analyzer\n",
    "\n",
    "Create a text analysis system that:\n",
    "1. Extract unique words from documents\n",
    "2. Calculate vocabulary overlap between documents\n",
    "3. Find common themes (shared important words)\n",
    "4. Identify unique vocabulary per document\n",
    "5. Calculate similarity scores\n",
    "6. Group similar documents together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4.6: Choosing the right data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: decision_guide.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.6\n",
    "# decision_guide.py - Quick decision guide for choosing data structures\n",
    "\n",
    "# THE GOLDEN QUESTIONS TO ASK YOURSELF:\n",
    "\n",
    "# 1. Do I need to store key-value pairs or look things up by name?\n",
    "#    \u2192 Use a DICTIONARY\n",
    "user = {\"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"}\n",
    "\n",
    "# 2. Do I need to ensure uniqueness or perform set operations?\n",
    "#    \u2192 Use a SET\n",
    "unique_visitors = {\"user123\", \"user456\", \"user789\"}\n",
    "\n",
    "# 3. Will this data never change once created?\n",
    "#    \u2192 Use a TUPLE\n",
    "coordinates = (40.7128, -74.0060)  # NYC coordinates won't change\n",
    "\n",
    "# 4. Do I need an ordered, changeable collection?\n",
    "#    \u2192 Use a LIST\n",
    "shopping_cart = [\"apples\", \"bread\", \"milk\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: when_to_use_lists.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.6\n",
    "# when_to_use_lists.py - When to choose lists for your data\n",
    "\n",
    "# 1. ORDER MATTERS and items might change\n",
    "timeline_events = [\n",
    "    \"User logged in\",\n",
    "    \"Viewed product\",\n",
    "    \"Added to cart\",\n",
    "    \"Completed purchase\"\n",
    "]\n",
    "# The sequence of events is crucial!\n",
    "\n",
    "# 2. You need to access items by position\n",
    "temperatures = [22, 24, 23, 25, 21, 26, 22]\n",
    "monday_temp = temperatures[0]  # First day\n",
    "friday_temp = temperatures[4]  # Fifth day\n",
    "\n",
    "# 3. You'll be adding/removing items frequently\n",
    "task_queue = []\n",
    "task_queue.append(\"Process payment\")\n",
    "task_queue.append(\"Send email\")\n",
    "current_task = task_queue.pop(0)  # Process first task\n",
    "\n",
    "# 4. Duplicates are allowed and meaningful\n",
    "dice_rolls = [6, 3, 6, 2, 6, 1, 4, 6]  # Multiple 6s are valid\n",
    "\n",
    "# 5. You need to sort or reverse\n",
    "scores = [85, 92, 78, 95, 88]\n",
    "scores.sort()  # In-place sorting\n",
    "\n",
    "# Real-world LIST examples in AI:\n",
    "\n",
    "# Conversation history (order matters, can grow)\n",
    "chat_messages = [\n",
    "    \"User: Hello\",\n",
    "    \"Bot: Hi there!\",\n",
    "    \"User: How are you?\"\n",
    "]\n",
    "chat_messages.append(\"Bot: I'm doing great!\")\n",
    "\n",
    "# Training data batches (need specific order)\n",
    "training_batches = [\n",
    "    [1, 2, 3, 4],  # Batch 1\n",
    "    [5, 6, 7, 8],  # Batch 2\n",
    "    [9, 10, 11, 12]  # Batch 3\n",
    "]\n",
    "\n",
    "# Sequential predictions\n",
    "predictions = []\n",
    "for i in range(5):\n",
    "    predictions.append(f\"Prediction {i}\")\n",
    "\n",
    "print(\"List examples:\")\n",
    "print(f\"Timeline has {len(timeline_events)} events\")\n",
    "print(f\"Task queue: {task_queue}\")\n",
    "print(f\"Chat messages: {len(chat_messages)} messages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: when_to_use_tuples.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.6\n",
    "# when_to_use_tuples.py - When to choose tuples for your data\n",
    "\n",
    "# 1. Data represents a single, unchangeable entity\n",
    "rgb_red = (255, 0, 0)  # Color definition\n",
    "database_config = (\"localhost\", 5432, \"mydb\", \"readonly\")\n",
    "\n",
    "# 2. You need to use it as a dictionary key\n",
    "location_data = {\n",
    "    (40.7128, -74.0060): \"New York\",\n",
    "    (51.5074, -0.1278): \"London\"\n",
    "}\n",
    "# Lists can't be dictionary keys, but tuples can!\n",
    "\n",
    "# 3. Returning multiple values (conceptually)\n",
    "# Calculate both area and perimeter\n",
    "width, height = 10, 5\n",
    "result = (width * height, 2 * (width + height))  # (area, perimeter)\n",
    "area, perimeter = result\n",
    "\n",
    "# 4. Protecting data from accidental changes\n",
    "SYSTEM_CONSTANTS = (3.14159, 2.71828, 1.41421)\n",
    "# No one can accidentally modify these\n",
    "\n",
    "# 5. Representing fixed records\n",
    "user_record = (\"Alice\", 30, \"alice@example.com\", True)  # Fixed structure\n",
    "\n",
    "# Real-world TUPLE examples in AI:\n",
    "\n",
    "# Model configuration (shouldn't change during runtime)\n",
    "MODEL_CONFIG = (\"gpt-3.5\", 2048, 0.7, \"production\")\n",
    "model, max_tokens, temperature, environment = MODEL_CONFIG\n",
    "\n",
    "# Training metrics snapshot (immutable record)\n",
    "epoch_results = (1, 0.85, 0.15, 42.3)  # (epoch, accuracy, loss, time)\n",
    "\n",
    "# Fixed coordinate pairs for computer vision\n",
    "bounding_box = ((100, 100), (200, 200))  # ((x1, y1), (x2, y2))\n",
    "\n",
    "print(\"Tuple examples:\")\n",
    "print(f\"RGB Red: {rgb_red}\")\n",
    "print(f\"Database config: {database_config}\")\n",
    "print(f\"Model: {model}, Max tokens: {max_tokens}\")\n",
    "print(f\"Area: {area}, Perimeter: {perimeter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: when_to_use_dictionaries.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.6\n",
    "# when_to_use_dictionaries.py - When to choose dictionaries for your data\n",
    "\n",
    "# 1. You need to look up values by a meaningful key\n",
    "phone_book = {\n",
    "    \"Alice\": \"555-1234\",\n",
    "    \"Bob\": \"555-5678\",\n",
    "    \"Charlie\": \"555-9012\"\n",
    "}\n",
    "alice_phone = phone_book[\"Alice\"]\n",
    "\n",
    "# 2. You're mapping relationships\n",
    "word_counts = {\n",
    "    \"python\": 15,\n",
    "    \"code\": 8,\n",
    "    \"function\": 12\n",
    "}\n",
    "python_count = word_counts[\"python\"]\n",
    "\n",
    "# 3. Storing structured data (like JSON)\n",
    "user_profile = {\n",
    "    \"username\": \"alice123\",\n",
    "    \"settings\": {\n",
    "        \"theme\": \"dark\",\n",
    "        \"notifications\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. Building caches or lookup tables\n",
    "fibonacci_cache = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "    5: 5\n",
    "}\n",
    "\n",
    "# 5. Grouping related data\n",
    "product = {\n",
    "    \"id\": \"PROD-123\",\n",
    "    \"name\": \"Laptop\",\n",
    "    \"price\": 999.99,\n",
    "    \"in_stock\": True\n",
    "}\n",
    "\n",
    "# Real-world DICTIONARY examples in AI:\n",
    "\n",
    "# API responses (always come as dictionaries/JSON)\n",
    "ai_response = {\n",
    "    \"text\": \"Hello! How can I help?\",\n",
    "    \"confidence\": 0.95,\n",
    "    \"tokens_used\": 15,\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "\n",
    "# Feature engineering (mapping features to values)\n",
    "user_features = {\n",
    "    \"age\": 25,\n",
    "    \"purchase_count\": 10,\n",
    "    \"is_premium\": True,\n",
    "    \"last_activity\": \"2024-01-15\"\n",
    "}\n",
    "\n",
    "# Entity tracking in NLP\n",
    "entities = {\n",
    "    \"persons\": [\"Alice\", \"Bob\"],\n",
    "    \"locations\": [\"New York\", \"Boston\"],\n",
    "    \"organizations\": [\"OpenAI\", \"Google\"]\n",
    "}\n",
    "\n",
    "print(\"Dictionary examples:\")\n",
    "print(f\"Alice's phone: {alice_phone}\")\n",
    "print(f\"Python word count: {python_count}\")\n",
    "print(f\"AI response confidence: {ai_response['confidence']}\")\n",
    "print(f\"Entities found: {len(entities)} types\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: when_to_use_sets.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.6\n",
    "# when_to_use_sets.py - When to choose sets for your data\n",
    "\n",
    "# 1. You need only unique items\n",
    "unique_visitors = set()\n",
    "unique_visitors.add(\"user123\")\n",
    "unique_visitors.add(\"user456\")\n",
    "unique_visitors.add(\"user123\")  # Won't be added again\n",
    "print(unique_visitors)  # {'user123', 'user456'}\n",
    "\n",
    "# 2. You need FAST membership testing\n",
    "valid_commands = {\"start\", \"stop\", \"pause\", \"resume\"}\n",
    "user_input = \"start\"\n",
    "if user_input in valid_commands:  # Super fast!\n",
    "    print(\"Valid command\")\n",
    "\n",
    "# 3. You need set operations (union, intersection, difference)\n",
    "skills_required = {\"Python\", \"SQL\", \"ML\"}\n",
    "skills_candidate = {\"Python\", \"SQL\", \"Java\", \"ML\"}\n",
    "has_all_required = skills_required.issubset(skills_candidate)  # True\n",
    "\n",
    "# 4. Removing duplicates from data\n",
    "numbers = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]\n",
    "unique_numbers = list(set(numbers))  # [1, 2, 3, 4]\n",
    "\n",
    "# 5. Finding commonalities or differences\n",
    "team_a = {\"Python\", \"JavaScript\", \"Go\"}\n",
    "team_b = {\"Python\", \"Java\", \"C++\"}\n",
    "common_languages = team_a & team_b  # {'Python'}\n",
    "\n",
    "# Real-world SET examples in AI:\n",
    "\n",
    "# Tracking unique entities in conversations\n",
    "mentioned_topics = set()\n",
    "mentioned_topics.add(\"weather\")\n",
    "mentioned_topics.add(\"sports\")\n",
    "mentioned_topics.add(\"weather\")  # Duplicate ignored\n",
    "\n",
    "# Vocabulary in NLP\n",
    "text = \"the cat sat on the mat\"\n",
    "vocabulary = set(text.split())  # Unique words only\n",
    "\n",
    "# Feature selection\n",
    "all_features = {\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"}\n",
    "selected_features = {\"f1\", \"f3\", \"f5\"}\n",
    "excluded_features = all_features - selected_features\n",
    "\n",
    "print(\"Set examples:\")\n",
    "print(f\"Unique visitors: {unique_visitors}\")\n",
    "print(f\"Has all required skills: {has_all_required}\")\n",
    "print(f\"Common languages: {common_languages}\")\n",
    "print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "print(f\"Excluded features: {excluded_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: combining_structures.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.6\n",
    "# combining_structures.py - Combining data structures for maximum power\n",
    "\n",
    "# 1. LIST OF DICTIONARIES - Perfect for records\n",
    "users = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"age\": 30},\n",
    "    {\"id\": 2, \"name\": \"Bob\", \"age\": 25},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"age\": 35}\n",
    "]\n",
    "\n",
    "# Easy to iterate\n",
    "for user in users:\n",
    "    print(f\"{user['name']} is {user['age']} years old\")\n",
    "\n",
    "# 2. DICTIONARY OF LISTS - Perfect for grouping\n",
    "students_by_grade = {\n",
    "    \"A\": [\"Alice\", \"Amy\", \"Anna\"],\n",
    "    \"B\": [\"Bob\", \"Bill\", \"Betty\"],\n",
    "    \"C\": [\"Charlie\", \"Carl\"]\n",
    "}\n",
    "\n",
    "# Easy to access groups\n",
    "a_students = students_by_grade[\"A\"]\n",
    "\n",
    "# 3. DICTIONARY OF SETS - Perfect for unique groupings\n",
    "user_permissions = {\n",
    "    \"admin\": {\"read\", \"write\", \"delete\", \"modify\"},\n",
    "    \"editor\": {\"read\", \"write\", \"modify\"},\n",
    "    \"viewer\": {\"read\"}\n",
    "}\n",
    "\n",
    "# Check permissions\n",
    "if \"delete\" in user_permissions.get(\"editor\", set()):\n",
    "    print(\"Editor can delete\")\n",
    "else:\n",
    "    print(\"Editor cannot delete\")\n",
    "\n",
    "# 4. LIST OF TUPLES - Perfect for paired data\n",
    "coordinates = [\n",
    "    (10, 20),\n",
    "    (30, 40),\n",
    "    (50, 60)\n",
    "]\n",
    "for x, y in coordinates:\n",
    "    print(f\"Point at ({x}, {y})\")\n",
    "\n",
    "# 5. DICTIONARY OF DICTIONARIES - Perfect for nested data\n",
    "company_data = {\n",
    "    \"employees\": {\n",
    "        \"alice\": {\"role\": \"developer\", \"salary\": 70000},\n",
    "        \"bob\": {\"role\": \"designer\", \"salary\": 65000}\n",
    "    },\n",
    "    \"departments\": {\n",
    "        \"engineering\": {\"head\": \"alice\", \"budget\": 500000},\n",
    "        \"design\": {\"head\": \"bob\", \"budget\": 200000}\n",
    "    }\n",
    "}\n",
    "\n",
    "# 6. SET OF TUPLES - Perfect for unique pairs\n",
    "edges = {\n",
    "    (\"A\", \"B\"),\n",
    "    (\"B\", \"C\"),\n",
    "    (\"A\", \"C\")\n",
    "}\n",
    "print(f\"Graph has {len(edges)} edges\")\n",
    "\n",
    "print(\"\\nCombining structures examples:\")\n",
    "print(f\"Number of users: {len(users)}\")\n",
    "print(f\"A students: {a_students}\")\n",
    "print(f\"Admin permissions: {user_permissions['admin']}\")\n",
    "print(f\"Alice's role: {company_data['employees']['alice']['role']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: performance_comparison.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.6\n",
    "# performance_comparison.py - Comparing performance of different data structures\n",
    "\n",
    "import time\n",
    "\n",
    "# Setup\n",
    "n = 100000\n",
    "test_list = list(range(n))\n",
    "test_set = set(range(n))\n",
    "test_dict = {}\n",
    "for i in range(n):\n",
    "    test_dict[i] = i\n",
    "\n",
    "# MEMBERSHIP TESTING\n",
    "search_value = n - 1\n",
    "\n",
    "# List (slow for large collections)\n",
    "start = time.time()\n",
    "result = search_value in test_list\n",
    "list_time = time.time() - start\n",
    "\n",
    "# Set (always fast)\n",
    "start = time.time()\n",
    "result = search_value in test_set\n",
    "set_time = time.time() - start\n",
    "\n",
    "# Dictionary (always fast)\n",
    "start = time.time()\n",
    "result = search_value in test_dict\n",
    "dict_time = time.time() - start\n",
    "\n",
    "print(f\"Membership testing for {n} items:\")\n",
    "print(f\"  List: {list_time:.6f} seconds\")\n",
    "print(f\"  Set: {set_time:.6f} seconds\")\n",
    "print(f\"  Dict: {dict_time:.6f} seconds\")\n",
    "\n",
    "# ADDING ITEMS\n",
    "# List append (fast)\n",
    "start = time.time()\n",
    "test_list.append(n)\n",
    "print(f\"\\nAdding one item:\")\n",
    "print(f\"  List append: {time.time() - start:.6f} seconds\")\n",
    "\n",
    "# Set add (fast)\n",
    "start = time.time()\n",
    "test_set.add(n)\n",
    "print(f\"  Set add: {time.time() - start:.6f} seconds\")\n",
    "\n",
    "# Dictionary assignment (fast)\n",
    "start = time.time()\n",
    "test_dict[n] = n\n",
    "print(f\"  Dict assign: {time.time() - start:.6f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: decision_flowchart.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.6\n",
    "# decision_flowchart.py - Step-by-step decision process for choosing data structures\n",
    "# Demonstrates the decision process without functions\n",
    "\n",
    "print(\"=\" * 40)\n",
    "print(\"DATA STRUCTURE DECISION FLOWCHART\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# The decision process:\n",
    "# 1. Do you need key-value pairs? -> DICTIONARY\n",
    "# 2. Do you need uniqueness? -> SET\n",
    "# 3. Will the data change? -> LIST (if yes) or TUPLE (if no)\n",
    "\n",
    "# Scenario 1: User profiles with lookup by ID\n",
    "print(\"\\nScenario 1: User profiles with lookup by ID\")\n",
    "print(\"  Question: Do you need key-value pairs? YES\")\n",
    "print(\"  Answer: Use DICTIONARY\")\n",
    "example_1 = {\"user_123\": {\"name\": \"Alice\", \"age\": 25}}\n",
    "print(f\"  Example: {example_1}\")\n",
    "\n",
    "# Scenario 2: Unique visitor tracking\n",
    "print(\"\\nScenario 2: Unique visitor tracking\")\n",
    "print(\"  Question: Do you need key-value pairs? NO\")\n",
    "print(\"  Question: Do you need uniqueness? YES\")\n",
    "print(\"  Answer: Use SET\")\n",
    "example_2 = {\"visitor_1\", \"visitor_2\", \"visitor_3\"}\n",
    "print(f\"  Example: {example_2}\")\n",
    "\n",
    "# Scenario 3: Shopping cart that changes\n",
    "print(\"\\nScenario 3: Shopping cart that changes\")\n",
    "print(\"  Question: Do you need key-value pairs? NO\")\n",
    "print(\"  Question: Do you need uniqueness? NO\")\n",
    "print(\"  Question: Will the data change? YES\")\n",
    "print(\"  Answer: Use LIST\")\n",
    "example_3 = [\"apple\", \"banana\", \"milk\"]\n",
    "print(f\"  Example: {example_3}\")\n",
    "\n",
    "# Scenario 4: GPS coordinates that never change\n",
    "print(\"\\nScenario 4: GPS coordinates that never change\")\n",
    "print(\"  Question: Do you need key-value pairs? NO\")\n",
    "print(\"  Question: Do you need uniqueness? NO\")\n",
    "print(\"  Question: Will the data change? NO\")\n",
    "print(\"  Answer: Use TUPLE\")\n",
    "example_4 = (37.7749, -122.4194)\n",
    "print(f\"  Example: {example_4}\")\n",
    "\n",
    "# Interactive decision helper\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"INTERACTIVE DECISION HELPER\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "needs_key_value = input(\"Do you need key-value pairs? (yes/no): \").lower().strip() == \"yes\"\n",
    "\n",
    "if needs_key_value:\n",
    "    print(\"\\nRecommendation: Use DICTIONARY\")\n",
    "    print(\"Example: my_dict = {'key': 'value'}\")\n",
    "else:\n",
    "    needs_unique = input(\"Do you need uniqueness (no duplicates)? (yes/no): \").lower().strip() == \"yes\"\n",
    "\n",
    "    if needs_unique:\n",
    "        print(\"\\nRecommendation: Use SET\")\n",
    "        print(\"Example: my_set = {1, 2, 3}\")\n",
    "    else:\n",
    "        will_change = input(\"Will the data change after creation? (yes/no): \").lower().strip() == \"yes\"\n",
    "\n",
    "        if will_change:\n",
    "            print(\"\\nRecommendation: Use LIST\")\n",
    "            print(\"Example: my_list = [1, 2, 3]\")\n",
    "        else:\n",
    "            print(\"\\nRecommendation: Use TUPLE\")\n",
    "            print(\"Example: my_tuple = (1, 2, 3)\")\n",
    "\n",
    "print(\"=\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: common_mistakes.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.6\n",
    "# common_mistakes.py - Common mistakes and how to avoid them\n",
    "\n",
    "# MISTAKE 1: Using lists for lookups (slow!)\n",
    "# Bad:\n",
    "users_list = [\"alice\", \"bob\", \"charlie\"]\n",
    "if \"charlie\" in users_list:  # Has to check each item\n",
    "    print(\"Found (slow way)\")\n",
    "\n",
    "# Good:\n",
    "users_set = {\"alice\", \"bob\", \"charlie\"}\n",
    "if \"charlie\" in users_set:  # Instant lookup\n",
    "    print(\"Found (fast way)\")\n",
    "\n",
    "# MISTAKE 2: Using dictionaries when order matters\n",
    "# Bad (in older Python):\n",
    "steps_dict = {\n",
    "    1: \"Wash vegetables\",\n",
    "    2: \"Cut vegetables\",\n",
    "    3: \"Cook vegetables\"\n",
    "}\n",
    "# Dictionary order wasn't guaranteed in older Python!\n",
    "\n",
    "# Good:\n",
    "steps_list = [\n",
    "    \"Wash vegetables\",\n",
    "    \"Cut vegetables\",\n",
    "    \"Cook vegetables\"\n",
    "]\n",
    "print(f\"Step 1: {steps_list[0]}\")\n",
    "\n",
    "# MISTAKE 3: Modifying a list while iterating\n",
    "# Bad:\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "# This would cause problems:\n",
    "# for n in numbers:\n",
    "#     if n % 2 == 0:\n",
    "#         numbers.remove(n)  # Dangerous!\n",
    "\n",
    "# Good:\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "odd_numbers = []\n",
    "for n in numbers:\n",
    "    if n % 2 != 0:\n",
    "        odd_numbers.append(n)\n",
    "print(f\"Odd numbers: {odd_numbers}\")\n",
    "\n",
    "# MISTAKE 4: Not using sets for uniqueness\n",
    "# Bad:\n",
    "seen = []\n",
    "data = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]\n",
    "for item in data:\n",
    "    if item not in seen:  # Slow for large lists\n",
    "        seen.append(item)\n",
    "\n",
    "# Good:\n",
    "seen_set = set()\n",
    "for item in data:\n",
    "    seen_set.add(item)  # Automatically handles uniqueness\n",
    "print(f\"Unique items: {seen_set}\")\n",
    "\n",
    "# MISTAKE 5: Forgetting tuples can't be modified\n",
    "# Bad:\n",
    "config = (\"localhost\", 5432)\n",
    "# config[0] = \"remotehost\"  # This would cause an error!\n",
    "\n",
    "# Good:\n",
    "config_list = [\"localhost\", 5432]  # If you need to modify\n",
    "config_list[0] = \"remotehost\"\n",
    "print(f\"Modified config: {config_list}\")\n",
    "\n",
    "print(\"\\nRemember: Choose the right tool for the job!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: recommendation_system_design.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.6\n",
    "# recommendation_system_design.py - Choosing the right data structures for a recommendation system\n",
    "\n",
    "# CHOOSING DATA STRUCTURES FOR A RECOMMENDATION SYSTEM\n",
    "\n",
    "# 1. User profiles - Need key-value lookup by user_id\n",
    "#    \u2192 DICTIONARY\n",
    "user_profiles = {\n",
    "    \"user123\": {\n",
    "        \"name\": \"Alice\",\n",
    "        \"joined\": \"2024-01-01\"\n",
    "    },\n",
    "    \"user456\": {\n",
    "        \"name\": \"Bob\",\n",
    "        \"joined\": \"2024-01-15\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. User interests - Need unique items per user\n",
    "#    \u2192 DICTIONARY OF SETS\n",
    "user_interests = {\n",
    "    \"user123\": {\"python\", \"ai\", \"web\"},\n",
    "    \"user456\": {\"javascript\", \"web\", \"mobile\"}\n",
    "}\n",
    "\n",
    "# 3. Content items - Need to iterate in order\n",
    "#    \u2192 LIST OF DICTIONARIES\n",
    "content = [\n",
    "    {\"id\": \"c1\", \"title\": \"Learn Python\", \"tags\": {\"python\", \"programming\"}},\n",
    "    {\"id\": \"c2\", \"title\": \"Web Development\", \"tags\": {\"web\", \"javascript\"}},\n",
    "    {\"id\": \"c3\", \"title\": \"AI Basics\", \"tags\": {\"ai\", \"python\"}}\n",
    "]\n",
    "\n",
    "# 4. View history - Order matters for recency\n",
    "#    \u2192 DICTIONARY OF LISTS\n",
    "view_history = {\n",
    "    \"user123\": [\"c1\", \"c3\"],  # Ordered by time\n",
    "    \"user456\": [\"c2\"]\n",
    "}\n",
    "\n",
    "# 5. Cached recommendations - Fast lookup, immutable\n",
    "#    \u2192 DICTIONARY WITH TUPLE VALUES\n",
    "cached_recommendations = {\n",
    "    \"user123\": (\"c2\",),  # Tuple of recommendations\n",
    "    \"user456\": (\"c1\", \"c3\")\n",
    "}\n",
    "\n",
    "# Using our chosen structures effectively\n",
    "print(\"Generating recommendations for user123:\")\n",
    "\n",
    "# Get user interests (SET operations)\n",
    "interests = user_interests[\"user123\"]\n",
    "\n",
    "# Find unviewed content (SET operations)\n",
    "viewed = set(view_history[\"user123\"])\n",
    "\n",
    "# Score each content item\n",
    "recommendations = []\n",
    "for item in content:\n",
    "    content_id = item[\"id\"]\n",
    "    if content_id not in viewed:  # Fast SET lookup\n",
    "        # Calculate relevance (SET intersection)\n",
    "        relevance = len(interests & item[\"tags\"])\n",
    "        if relevance > 0:\n",
    "            recommendations.append((content_id, relevance))\n",
    "\n",
    "# Sort and display\n",
    "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "print(f\"Recommendations: {recommendations}\")\n",
    "\n",
    "print(\"\\nData structure choices:\")\n",
    "print(\"- User profiles: Dictionary (fast lookup by ID)\")\n",
    "print(\"- User interests: Dict of sets (unique interests per user)\")\n",
    "print(\"- Content: List of dicts (ordered, detailed items)\")\n",
    "print(\"- View history: Dict of lists (ordered history per user)\")\n",
    "print(\"- Cached: Dict of tuples (immutable recommendations)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 4.6 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.6.1: Task Management System\n",
    "\n",
    "Design data structures for a task management system that needs to:\n",
    "1. Store tasks with title, priority, and status\n",
    "2. Track unique tags across all tasks\n",
    "3. Maintain task order by creation time\n",
    "4. Quickly look up tasks by ID\n",
    "5. Group tasks by status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.6.2: Quiz Application\n",
    "\n",
    "Choose data structures for a quiz app that needs to:\n",
    "1. Store questions with multiple choice answers\n",
    "2. Track which questions a user has answered\n",
    "3. Maintain question order\n",
    "4. Store correct answers securely\n",
    "5. Calculate scores quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.6.3: Social Network Features\n",
    "\n",
    "Pick data structures for social features that need to:\n",
    "1. Store user friendships (bidirectional)\n",
    "2. Track unique hashtags in posts\n",
    "3. Maintain a feed in chronological order\n",
    "4. Store user metadata\n",
    "5. Find mutual friends efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4.7: List comprehensions (gentle introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: first_comprehension.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# first_comprehension.py - Your first list comprehension\n",
    "\n",
    "# The way you know - using a loop\n",
    "squares_loop = []\n",
    "for x in range(5):\n",
    "    squares_loop.append(x ** 2)\n",
    "print(\"Using loop:\", squares_loop)\n",
    "\n",
    "# The SAME thing using a list comprehension\n",
    "squares_comp = [x ** 2 for x in range(5)]\n",
    "print(\"Using comprehension:\", squares_comp)\n",
    "\n",
    "# They produce the exact same result!\n",
    "# [0, 1, 4, 9, 16]\n",
    "\n",
    "# Anatomy of a list comprehension:\n",
    "# [expression for item in iterable]\n",
    "#  \u2191          \u2191        \u2191\n",
    "#  \u2502          \u2502        \u2514\u2500\u2500 Where the items come from (range, list, etc.)\n",
    "#  \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Variable name for each item\n",
    "#  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 What to do with each item\n",
    "\n",
    "# More examples to build intuition\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Double each number\n",
    "doubled = [n * 2 for n in numbers]\n",
    "print(\"Doubled:\", doubled)  # [2, 4, 6, 8, 10]\n",
    "\n",
    "# Convert to strings\n",
    "strings = [str(n) for n in numbers]\n",
    "print(\"As strings:\", strings)  # ['1', '2', '3', '4', '5']\n",
    "\n",
    "# Create a list of lengths\n",
    "words = [\"hi\", \"hello\", \"python\", \"ai\"]\n",
    "lengths = [len(word) for word in words]\n",
    "print(\"Word lengths:\", lengths)  # [2, 5, 6, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: comprehension_with_conditions.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# comprehension_with_conditions.py - Adding conditions to filter lists\n",
    "\n",
    "# The loop way you know\n",
    "evens_loop = []\n",
    "for x in range(10):\n",
    "    if x % 2 == 0:\n",
    "        evens_loop.append(x)\n",
    "print(\"Evens (loop):\", evens_loop)\n",
    "\n",
    "# The comprehension way with a condition\n",
    "evens_comp = [x for x in range(10) if x % 2 == 0]\n",
    "print(\"Evens (comprehension):\", evens_comp)\n",
    "\n",
    "# Both give: [0, 2, 4, 6, 8]\n",
    "\n",
    "# The pattern with conditions:\n",
    "# [expression for item in iterable if condition]\n",
    "#  \u2191          \u2191        \u2191           \u2191\n",
    "#  \u2502          \u2502        \u2502           \u2514\u2500\u2500 Only include if this is True\n",
    "#  \u2502          \u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Where items come from\n",
    "#  \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Variable for each item\n",
    "#  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 What to do with item\n",
    "\n",
    "# More examples with conditions\n",
    "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Only positive numbers\n",
    "positives = [n for n in numbers if n > 0]\n",
    "print(\"Positives:\", positives)\n",
    "\n",
    "# Only numbers greater than 5\n",
    "big_numbers = [n for n in numbers if n > 5]\n",
    "print(\"Greater than 5:\", big_numbers)  # [6, 7, 8, 9, 10]\n",
    "\n",
    "# Squares of only even numbers\n",
    "even_squares = [n ** 2 for n in numbers if n % 2 == 0]\n",
    "print(\"Squares of evens:\", even_squares)  # [4, 16, 36, 64, 100]\n",
    "\n",
    "# Words that are longer than 3 characters\n",
    "words = [\"hi\", \"hello\", \"python\", \"ai\", \"code\"]\n",
    "long_words = [word for word in words if len(word) > 3]\n",
    "print(\"Long words:\", long_words)  # ['hello', 'python', 'code']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: transforming_data.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# transforming_data.py - Real-world examples of data transformation\n",
    "\n",
    "# Example 1: Processing user input\n",
    "user_inputs = [\"  Hello  \", \"WORLD \", \" python\", \"  AI  \"]\n",
    "\n",
    "# Clean and lowercase all inputs\n",
    "cleaned = [text.strip().lower() for text in user_inputs]\n",
    "print(\"Cleaned inputs:\", cleaned)  # ['hello', 'world', 'python', 'ai']\n",
    "\n",
    "# Example 2: Extracting data\n",
    "users = [\n",
    "    {\"name\": \"Alice\", \"age\": 30},\n",
    "    {\"name\": \"Bob\", \"age\": 25},\n",
    "    {\"name\": \"Charlie\", \"age\": 35}\n",
    "]\n",
    "\n",
    "# Get all names\n",
    "names = [user[\"name\"] for user in users]\n",
    "print(\"Names:\", names)  # ['Alice', 'Bob', 'Charlie']\n",
    "\n",
    "# Get names of users over 30\n",
    "adults = [user[\"name\"] for user in users if user[\"age\"] > 30]\n",
    "print(\"Over 30:\", adults)  # ['Charlie']\n",
    "\n",
    "# Example 3: File extensions\n",
    "files = [\"photo.jpg\", \"document.pdf\", \"image.png\", \"script.py\", \"data.csv\"]\n",
    "\n",
    "# Get only image files\n",
    "images = [f for f in files if f.endswith((\".jpg\", \".png\"))]\n",
    "print(\"Images:\", images)  # ['photo.jpg', 'image.png']\n",
    "\n",
    "# Example 4: Converting temperatures\n",
    "celsius = [0, 20, 30, 100]\n",
    "fahrenheit = [c * 9/5 + 32 for c in celsius]\n",
    "print(\"Fahrenheit:\", fahrenheit)  # [32.0, 68.0, 86.0, 212.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: nested_comprehensions.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# nested_comprehensions.py - Nested loops in comprehensions\n",
    "\n",
    "# The loop way\n",
    "pairs_loop = []\n",
    "for x in [1, 2, 3]:\n",
    "    for y in ['a', 'b']:\n",
    "        pairs_loop.append((x, y))\n",
    "print(\"Pairs (loop):\", pairs_loop)\n",
    "\n",
    "# The comprehension way\n",
    "pairs_comp = [(x, y) for x in [1, 2, 3] for y in ['a', 'b']]\n",
    "print(\"Pairs (comprehension):\", pairs_comp)\n",
    "\n",
    "# Both give: [(1, 'a'), (1, 'b'), (2, 'a'), (2, 'b'), (3, 'a'), (3, 'b')]\n",
    "\n",
    "# Practical example: Multiplication table\n",
    "table = [i * j for i in range(1, 4) for j in range(1, 4)]\n",
    "print(\"Multiplication:\", table)  # [1, 2, 3, 2, 4, 6, 3, 6, 9]\n",
    "\n",
    "# With better formatting\n",
    "table_formatted = [(i, j, i*j) for i in range(1, 4) for j in range(1, 4)]\n",
    "print(\"\\nMultiplication table:\")\n",
    "for i, j, result in table_formatted:\n",
    "    print(f\"{i} \u00d7 {j} = {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: when_not_to_use.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# when_not_to_use.py - When NOT to use list comprehensions\n",
    "\n",
    "# TOO COMPLEX - Hard to read!\n",
    "# Don't do this:\n",
    "# result = [x if x > 0 else -x if x < 0 else 0 for x in numbers if x != 5]\n",
    "\n",
    "# Better as a regular loop:\n",
    "numbers = [-3, -1, 0, 1, 5, 7]\n",
    "result = []\n",
    "for x in numbers:\n",
    "    if x != 5:\n",
    "        if x > 0:\n",
    "            result.append(x)\n",
    "        elif x < 0:\n",
    "            result.append(-x)\n",
    "        else:\n",
    "            result.append(0)\n",
    "print(\"Result:\", result)\n",
    "\n",
    "# SIDE EFFECTS - Don't use comprehensions just for side effects\n",
    "# Bad - using comprehension just to print (creates useless list):\n",
    "# [print(x) for x in range(5)]  # Don't do this!\n",
    "\n",
    "# Good - use a regular loop for side effects:\n",
    "print(\"Printing with loop (correct way):\")\n",
    "for x in range(5):\n",
    "    print(x, end=\" \")\n",
    "print()\n",
    "\n",
    "# TOO LONG - If it doesn't fit on one line, use a loop\n",
    "# Bad - too long to read easily:\n",
    "# data = [complicated_expression(x) * another_function(x) / some_calculation(x) for x in very_long_iterable_name if complex_condition(x) and another_condition(x)]\n",
    "\n",
    "# Good - break it up:\n",
    "items = [1, 2, 3, 4, 5]\n",
    "data = []\n",
    "for x in items:\n",
    "    if x > 2 and x < 5:  # condition1 and condition2\n",
    "        value = x * 2  # expression\n",
    "        data.append(value)\n",
    "print(\"Clean loop result:\", data)\n",
    "\n",
    "print(\"\\nRemember: Readability counts! If it's hard to read, use a regular loop.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: ai_data_science.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# ai_data_science.py - List comprehensions for AI and data science\n",
    "\n",
    "# Preparing text data for NLP\n",
    "raw_texts = [\"Hello World!\", \"  Python AI  \", \"Machine Learning\"]\n",
    "\n",
    "# Clean and tokenize\n",
    "processed = [text.strip().lower().split() for text in raw_texts]\n",
    "print(\"Tokenized:\", processed)\n",
    "# [['hello', 'world!'], ['python', 'ai'], ['machine', 'learning']]\n",
    "\n",
    "# Filter out short words\n",
    "filtered = [[word for word in text if len(word) > 2] for text in processed]\n",
    "print(\"Filtered:\", filtered)\n",
    "\n",
    "# Creating feature vectors\n",
    "words = [\"python\", \"ai\", \"machine\", \"learning\"]\n",
    "vocabulary = [\"python\", \"java\", \"ai\", \"machine\", \"learning\", \"code\"]\n",
    "\n",
    "# Binary features (1 if word in vocabulary, 0 if not)\n",
    "features = [1 if word in words else 0 for word in vocabulary]\n",
    "print(\"Features:\", features)  # [1, 0, 1, 1, 1, 0]\n",
    "\n",
    "# Batch processing\n",
    "data = list(range(20))\n",
    "batch_size = 5\n",
    "\n",
    "# Create batches\n",
    "batches = [data[i:i+batch_size] for i in range(0, len(data), batch_size)]\n",
    "print(\"Batches:\", batches)\n",
    "# [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]\n",
    "\n",
    "# Normalizing scores\n",
    "scores = [85, 92, 78, 95, 88]\n",
    "max_score = max(scores)\n",
    "normalized = [score / max_score for score in scores]\n",
    "print(\"Normalized:\", normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: other_comprehensions.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# other_comprehensions.py - Dictionary and set comprehensions\n",
    "\n",
    "# Dictionary comprehension\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Create a dictionary of squares\n",
    "squares_dict = {n: n**2 for n in numbers}\n",
    "print(\"Squares dict:\", squares_dict)\n",
    "# {1: 1, 2: 4, 3: 9, 4: 16, 5: 25}\n",
    "\n",
    "# Word lengths dictionary\n",
    "words = [\"hello\", \"world\", \"python\"]\n",
    "word_lengths = {word: len(word) for word in words}\n",
    "print(\"Word lengths:\", word_lengths)\n",
    "# {'hello': 5, 'world': 5, 'python': 6}\n",
    "\n",
    "# Filtering in dictionary comprehension\n",
    "scores = {\"Alice\": 85, \"Bob\": 92, \"Charlie\": 78, \"Diana\": 95}\n",
    "high_scores = {name: score for name, score in scores.items() if score > 90}\n",
    "print(\"High scores:\", high_scores)\n",
    "# {'Bob': 92, 'Diana': 95}\n",
    "\n",
    "# Set comprehension\n",
    "numbers = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]\n",
    "\n",
    "# Create a set of unique squares\n",
    "unique_squares = {n**2 for n in numbers}\n",
    "print(\"Unique squares:\", unique_squares)\n",
    "# {1, 4, 9, 16}\n",
    "\n",
    "# Words containing 'a'\n",
    "words = [\"apple\", \"banana\", \"cherry\", \"date\"]\n",
    "words_with_a = {word for word in words if 'a' in word}\n",
    "print(\"Words with 'a':\", words_with_a)\n",
    "# {'apple', 'banana', 'date'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: performance_test.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# performance_test.py - Testing if comprehensions are faster than loops\n",
    "\n",
    "import time\n",
    "\n",
    "# Large dataset\n",
    "n = 1000000\n",
    "data = list(range(n))\n",
    "\n",
    "# Using a loop\n",
    "start = time.time()\n",
    "squares_loop = []\n",
    "for x in data:\n",
    "    squares_loop.append(x ** 2)\n",
    "loop_time = time.time() - start\n",
    "\n",
    "# Using comprehension\n",
    "start = time.time()\n",
    "squares_comp = [x ** 2 for x in data]\n",
    "comp_time = time.time() - start\n",
    "\n",
    "print(f\"Loop time: {loop_time:.3f} seconds\")\n",
    "print(f\"Comprehension time: {comp_time:.3f} seconds\")\n",
    "print(f\"Comprehension is {loop_time/comp_time:.1f}x faster!\")\n",
    "\n",
    "# Comprehensions are usually faster because:\n",
    "# 1. They're optimized at the C level\n",
    "# 2. Less Python bytecode to interpret\n",
    "# 3. No repeated append() method calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: common_patterns_lc.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# common_patterns.py - Common patterns and recipes\n",
    "\n",
    "# Pattern 1: Flatten a list of lists\n",
    "nested = [[1, 2], [3, 4], [5, 6]]\n",
    "flat = [item for sublist in nested for item in sublist]\n",
    "print(\"Flattened:\", flat)  # [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Pattern 2: Remove None values\n",
    "data = [1, None, 2, None, 3, 4, None, 5]\n",
    "clean = [x for x in data if x is not None]\n",
    "print(\"Without None:\", clean)  # [1, 2, 3, 4, 5]\n",
    "\n",
    "# Pattern 3: Extract from nested structures\n",
    "data = [\n",
    "    {\"name\": \"Alice\", \"score\": 85},\n",
    "    {\"name\": \"Bob\", \"score\": 92},\n",
    "    {\"name\": \"Charlie\", \"score\": 78}\n",
    "]\n",
    "passing = [d[\"name\"] for d in data if d[\"score\"] >= 80]\n",
    "print(\"Passing students:\", passing)  # ['Alice', 'Bob']\n",
    "\n",
    "# Pattern 4: Create enumerated pairs\n",
    "items = [\"a\", \"b\", \"c\"]\n",
    "enumerated = [(i, item) for i, item in enumerate(items)]\n",
    "print(\"Enumerated:\", enumerated)  # [(0, 'a'), (1, 'b'), (2, 'c')]\n",
    "\n",
    "# Pattern 5: Zip multiple lists\n",
    "names = [\"Alice\", \"Bob\", \"Charlie\"]\n",
    "ages = [30, 25, 35]\n",
    "combined = [(name, age) for name, age in zip(names, ages)]\n",
    "print(\"Combined:\", combined)  # [('Alice', 30), ('Bob', 25), ('Charlie', 35)]\n",
    "\n",
    "# Pattern 6: String operations\n",
    "sentences = [\"Hello world\", \"Python programming\", \"AI is cool\"]\n",
    "word_counts = [len(s.split()) for s in sentences]\n",
    "print(\"Word counts:\", word_counts)  # [2, 2, 3]\n",
    "\n",
    "# Pattern 7: Working with ranges\n",
    "# Even numbers from 0 to 20\n",
    "evens = [x for x in range(21) if x % 2 == 0]\n",
    "print(\"Evens:\", evens)\n",
    "\n",
    "# Squares of numbers from 1 to 10\n",
    "squares = [x**2 for x in range(1, 11)]\n",
    "print(\"Squares:\", squares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: writing_tips.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# writing_tips.py - Tips for writing good comprehensions\n",
    "\n",
    "# Good examples:\n",
    "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "words = [\"hello\", \"world\", \"python\", \"programming\", \"ai\"]\n",
    "people = [\n",
    "    {\"name\": \"Alice\", \"age\": 25},\n",
    "    {\"name\": \"Bob\", \"age\": 17},\n",
    "    {\"name\": \"Charlie\", \"age\": 30}\n",
    "]\n",
    "\n",
    "# 1. Keep them simple\n",
    "squares = [x**2 for x in range(10)]\n",
    "print(\"Simple squares:\", squares[:5])\n",
    "\n",
    "# 2. Clear variable names\n",
    "uppercase = [word.upper() for word in words]\n",
    "print(\"Uppercase words:\", uppercase[:3])\n",
    "\n",
    "# 3. Readable conditions\n",
    "adults = [person for person in people if person[\"age\"] >= 18]\n",
    "print(\"Adults:\", [p[\"name\"] for p in adults])\n",
    "\n",
    "# Bad examples (too complex):\n",
    "# Don't do this - too hard to read:\n",
    "# result = [[y for y in row if y > 0] for row in matrix if sum(row) > 10]\n",
    "\n",
    "# When in doubt, write the loop first, then convert:\n",
    "print(\"\\nLoop to comprehension conversion:\")\n",
    "\n",
    "# Step 1: Write the loop\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "result_loop = []\n",
    "for x in data:\n",
    "    if x % 2 == 0:\n",
    "        result_loop.append(x * 2)\n",
    "print(\"Loop result:\", result_loop)\n",
    "\n",
    "# Step 2: Convert to comprehension\n",
    "result_comp = [x * 2 for x in data if x % 2 == 0]\n",
    "print(\"Comprehension result:\", result_comp)\n",
    "\n",
    "print(\"\\nRemember:\")\n",
    "print(\"1. Keep them simple - If you need to read it twice, it's too complex\")\n",
    "print(\"2. One line only - If it wraps to multiple lines, use a regular loop\")\n",
    "print(\"3. Clear variable names - Use 'word' not 'w', 'number' not 'n'\")\n",
    "print(\"4. Don't sacrifice readability - Shorter isn't always better\")\n",
    "print(\"5. Use them for building, not printing - They create lists, not side effects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: text_analysis.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4, Section 4.7\n",
    "# text_analysis.py - Real-world text analysis with comprehensions\n",
    "\n",
    "# Sample text data\n",
    "documents = [\n",
    "    \"Python is great for AI and machine learning\",\n",
    "    \"Data science requires Python skills\",\n",
    "    \"Machine learning is part of artificial intelligence\",\n",
    "    \"Python makes data analysis easy\"\n",
    "]\n",
    "\n",
    "# Tokenize all documents (split into words)\n",
    "tokenized = [doc.lower().split() for doc in documents]\n",
    "print(\"Tokenized documents:\")\n",
    "for i, tokens in enumerate(tokenized):\n",
    "    print(f\"  Doc {i}: {tokens[:5]}...\")  # Show first 5 words\n",
    "\n",
    "# Extract all unique words (vocabulary)\n",
    "all_words = [word for doc in tokenized for word in doc]\n",
    "vocabulary = list(set(all_words))\n",
    "print(f\"\\nVocabulary size: {len(vocabulary)}\")\n",
    "\n",
    "# Count word frequencies\n",
    "word_freq = {}\n",
    "for word in all_words:\n",
    "    if word not in word_freq:\n",
    "        word_freq[word] = 0\n",
    "    word_freq[word] += 1\n",
    "\n",
    "# Find common words (appear more than once)\n",
    "common_words = [word for word, freq in word_freq.items() if freq > 1]\n",
    "print(f\"Common words: {common_words}\")\n",
    "\n",
    "# Create document vectors (1 if word appears, 0 if not)\n",
    "target_words = [\"python\", \"ai\", \"machine\", \"learning\", \"data\"]\n",
    "\n",
    "doc_vectors = []\n",
    "for doc in tokenized:\n",
    "    vector = [1 if word in doc else 0 for word in target_words]\n",
    "    doc_vectors.append(vector)\n",
    "\n",
    "print(\"\\nDocument vectors:\")\n",
    "print(\"Words:\", target_words)\n",
    "for i, vector in enumerate(doc_vectors):\n",
    "    print(f\"Doc {i}: {vector}\")\n",
    "\n",
    "# Find documents containing \"python\"\n",
    "python_docs = [i for i, doc in enumerate(tokenized) if \"python\" in doc]\n",
    "print(f\"\\nDocuments containing 'python': {python_docs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: datamaster.py\n",
    "\n",
    "# From: Zero to AI Agent, Chapter 4 Challenge Project\n",
    "# datamaster.py - Your Personal Data Analysis System\n",
    "# A data analysis challenge using all Python data structures (without classes or functions)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"DATAMASTER - Personal Data Analysis System\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\")\n",
    "print(\"This is a CHALLENGE PROJECT!\")\n",
    "print(\"Try to implement these features using what you've learned.\")\n",
    "print(\"\")\n",
    "\n",
    "# Initialize your data structures\n",
    "datasets = {}  # Dictionary to store named datasets\n",
    "unique_values = set()  # Track all unique values seen\n",
    "history = []  # List of operations performed\n",
    "metadata = {}  # Dictionary for dataset information\n",
    "cache = {}  # Dictionary for cached results\n",
    "\n",
    "# Sample data to work with\n",
    "print(\"Loading sample sales data...\")\n",
    "sales_data = [\n",
    "    {\"id\": 1, \"product\": \"Widget A\", \"price\": 29.99, \"quantity\": 10, \"region\": \"North\"},\n",
    "    {\"id\": 2, \"product\": \"Widget B\", \"price\": 49.99, \"quantity\": 5, \"region\": \"South\"},\n",
    "    {\"id\": 3, \"product\": \"Widget A\", \"price\": 29.99, \"quantity\": 8, \"region\": \"East\"},\n",
    "    {\"id\": 4, \"product\": \"Widget C\", \"price\": 19.99, \"quantity\": 20, \"region\": \"North\"},\n",
    "    {\"id\": 5, \"product\": \"Widget B\", \"price\": 49.99, \"quantity\": 3, \"region\": \"West\"},\n",
    "]\n",
    "\n",
    "datasets[\"sales\"] = sales_data\n",
    "metadata[\"sales\"] = {\"rows\": len(sales_data), \"source\": \"sample\"}\n",
    "history.append((\"import\", \"sales\", \"5 records\"))\n",
    "print(f\"Loaded {len(sales_data)} sales records\")\n",
    "print(\"\")\n",
    "\n",
    "# CHALLENGE 1: Get unique products\n",
    "print(\"CHALLENGE 1: Find unique products\")\n",
    "print(\"-\" * 40)\n",
    "# Use a set to find unique products\n",
    "unique_products = {record[\"product\"] for record in sales_data}\n",
    "print(f\"Unique products: {unique_products}\")\n",
    "print(\"\")\n",
    "\n",
    "# CHALLENGE 2: Calculate total revenue by product\n",
    "print(\"CHALLENGE 2: Total revenue by product\")\n",
    "print(\"-\" * 40)\n",
    "# Use a dictionary to accumulate totals\n",
    "revenue_by_product = {}\n",
    "for record in sales_data:\n",
    "    product = record[\"product\"]\n",
    "    revenue = record[\"price\"] * record[\"quantity\"]\n",
    "    revenue_by_product[product] = revenue_by_product.get(product, 0) + revenue\n",
    "\n",
    "for product, revenue in revenue_by_product.items():\n",
    "    print(f\"  {product}: ${revenue:.2f}\")\n",
    "print(\"\")\n",
    "\n",
    "# CHALLENGE 3: Group sales by region\n",
    "print(\"CHALLENGE 3: Sales by region\")\n",
    "print(\"-\" * 40)\n",
    "# Use dictionary with lists as values\n",
    "sales_by_region = {}\n",
    "for record in sales_data:\n",
    "    region = record[\"region\"]\n",
    "    if region not in sales_by_region:\n",
    "        sales_by_region[region] = []\n",
    "    sales_by_region[region].append(record)\n",
    "\n",
    "for region, records in sales_by_region.items():\n",
    "    print(f\"  {region}: {len(records)} sales\")\n",
    "print(\"\")\n",
    "\n",
    "# CHALLENGE 4: Find records with high quantities using list comprehension\n",
    "print(\"CHALLENGE 4: High quantity sales (quantity > 5)\")\n",
    "print(\"-\" * 40)\n",
    "high_quantity_sales = [record for record in sales_data if record[\"quantity\"] > 5]\n",
    "for sale in high_quantity_sales:\n",
    "    print(f\"  {sale['product']}: {sale['quantity']} units\")\n",
    "print(\"\")\n",
    "\n",
    "# CHALLENGE 5: Calculate statistics\n",
    "print(\"CHALLENGE 5: Price statistics\")\n",
    "print(\"-\" * 40)\n",
    "prices = [record[\"price\"] for record in sales_data]\n",
    "prices_sorted = sorted(prices)\n",
    "\n",
    "total_price = 0\n",
    "for p in prices:\n",
    "    total_price = total_price + p\n",
    "\n",
    "min_price = prices_sorted[0]\n",
    "max_price = prices_sorted[-1]\n",
    "avg_price = total_price / len(prices)\n",
    "\n",
    "print(f\"  Minimum price: ${min_price:.2f}\")\n",
    "print(f\"  Maximum price: ${max_price:.2f}\")\n",
    "print(f\"  Average price: ${avg_price:.2f}\")\n",
    "print(\"\")\n",
    "\n",
    "# Show operation history\n",
    "print(\"=\" * 50)\n",
    "print(\"OPERATION HISTORY\")\n",
    "print(\"=\" * 50)\n",
    "for operation, dataset, details in history:\n",
    "    print(f\"  [{operation}] {dataset}: {details}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"=\" * 50)\n",
    "print(\"YOUR CHALLENGES:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"1. Add more data to the datasets dictionary\")\n",
    "print(\"2. Create a query system using list comprehensions\")\n",
    "print(\"3. Implement a caching system for expensive operations\")\n",
    "print(\"4. Add customer data and find correlations with sales\")\n",
    "print(\"5. Generate a comprehensive report using all data structures\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 4.7 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.7.1: Data Cleaning\n",
    "\n",
    "You have messy data that needs cleaning:\n",
    "- A list of strings with extra spaces: [\"  hello  \", \" WORLD \", \"  Python  \"]\n",
    "- Create a cleaned list with stripped, lowercase strings\n",
    "- Filter out any strings shorter than 4 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.7.2: Grade Processing\n",
    "\n",
    "Given a list of student records:\n",
    "```python\n",
    "students = [\n",
    "    {\"name\": \"Alice\", \"grade\": 85},\n",
    "    {\"name\": \"Bob\", \"grade\": 92},\n",
    "    {\"name\": \"Charlie\", \"grade\": 78},\n",
    "    {\"name\": \"Diana\", \"grade\": 95},\n",
    "    {\"name\": \"Eve\", \"grade\": 88}\n",
    "]\n",
    "```\n",
    "Use comprehensions to:\n",
    "- Extract all names\n",
    "- Get names of students with grades \\>= 90\n",
    "- Create a dictionary of name: grade pairs\n",
    "- Calculate letter grades (A if \\>= 90, B if \\>= 80, C otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.7.3: Number Processing\n",
    "\n",
    "Given numbers = range(1, 21):\n",
    "- Create a list of all even numbers\n",
    "- Create a list of squares of odd numbers\n",
    "- Create a dictionary where keys are numbers and values are \"even\" or \"odd\"\n",
    "- Create a list of tuples (number, square, cube) for numbers 1-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "- Check your answers in **chapter_04_data_structures_solutions.ipynb**\n",
    "- Proceed to **Chapter 5**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}