{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Building Your First LLM Application - Solutions\n",
    "**From: Zero to AI Agent**\n",
    "\n",
    "Try the exercises in the main notebook first before viewing these solutions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.1.1: Personality Bot\n",
    "\n",
    "Create a chatbot that can switch between different personalities (pirate, chef, poet, robot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define personalities\n",
    "personalities = {\n",
    "    \"pirate\": \"You are a friendly pirate. Speak with pirate slang, say 'arr' and 'matey' often.\",\n",
    "    \"chef\": \"You are a passionate French chef. Use cooking metaphors and French words.\",\n",
    "    \"poet\": \"You are a romantic poet. Speak in a lyrical manner, sometimes in rhyme.\",\n",
    "    \"robot\": \"You are a helpful robot. Be logical, occasionally say 'BEEP BOOP'.\"\n",
    "}\n",
    "\n",
    "class PersonalityBot:\n",
    "    def __init__(self):\n",
    "        self.current_personality = \"pirate\"\n",
    "        self.conversation = [{\"role\": \"system\", \"content\": personalities[self.current_personality]}]\n",
    "    \n",
    "    def switch_personality(self, personality):\n",
    "        if personality in personalities:\n",
    "            self.current_personality = personality\n",
    "            self.conversation = [{\"role\": \"system\", \"content\": personalities[personality]}]\n",
    "            return f\"Switched to {personality}!\"\n",
    "        return f\"Unknown. Choose from: {list(personalities.keys())}\"\n",
    "    \n",
    "    def chat(self, message):\n",
    "        self.conversation.append({\"role\": \"user\", \"content\": message})\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=self.conversation,\n",
    "            temperature=0.9\n",
    "        )\n",
    "        ai_message = response.choices[0].message.content\n",
    "        self.conversation.append({\"role\": \"assistant\", \"content\": ai_message})\n",
    "        if len(self.conversation) > 10:\n",
    "            self.conversation = [self.conversation[0]] + self.conversation[-9:]\n",
    "        return ai_message\n",
    "\n",
    "# Demo\n",
    "bot = PersonalityBot()\n",
    "print(f\"Current: {bot.current_personality}\")\n",
    "print(bot.chat(\"Tell me about your day\"))\n",
    "print(\"\\n\" + bot.switch_personality(\"robot\"))\n",
    "print(bot.chat(\"Tell me about your day\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.1.2: Conversation Saver\n",
    "\n",
    "Create a chat that can save and load conversations to/from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class ConversationSaver:\n",
    "    def __init__(self):\n",
    "        self.conversation = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "        self.message_count = 0\n",
    "    \n",
    "    def save(self):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        # Save as JSON for loading later\n",
    "        json_file = f\"conversation_{timestamp}.json\"\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump({\"messages\": self.conversation, \"count\": self.message_count}, f, indent=2)\n",
    "        return json_file\n",
    "    \n",
    "    def load(self, filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            self.conversation = data[\"messages\"]\n",
    "            self.message_count = data[\"count\"]\n",
    "        return f\"Loaded {self.message_count} messages\"\n",
    "    \n",
    "    def chat(self, message):\n",
    "        self.conversation.append({\"role\": \"user\", \"content\": message})\n",
    "        self.message_count += 1\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=self.conversation\n",
    "        )\n",
    "        ai_message = response.choices[0].message.content\n",
    "        self.conversation.append({\"role\": \"assistant\", \"content\": ai_message})\n",
    "        self.message_count += 1\n",
    "        return ai_message\n",
    "\n",
    "# Demo\n",
    "saver = ConversationSaver()\n",
    "print(saver.chat(\"Hello, my name is Bob\"))\n",
    "saved_file = saver.save()\n",
    "print(f\"Saved to: {saved_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.1.3: Cost Calculator\n",
    "\n",
    "Create a chat that tracks and displays API costs in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostTrackerChat:\n",
    "    def __init__(self, model=\"gpt-3.5-turbo\"):\n",
    "        self.model = model\n",
    "        self.conversation = [{\"role\": \"system\", \"content\": \"You are helpful.\"}]\n",
    "        self.total_cost = 0.0\n",
    "        self.call_count = 0\n",
    "        self.pricing = {\n",
    "            \"gpt-3.5-turbo\": {\"input\": 0.0005, \"output\": 0.0015},\n",
    "            \"gpt-4\": {\"input\": 0.03, \"output\": 0.06}\n",
    "        }\n",
    "    \n",
    "    def chat(self, message):\n",
    "        self.conversation.append({\"role\": \"user\", \"content\": message})\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.conversation\n",
    "        )\n",
    "        ai_message = response.choices[0].message.content\n",
    "        self.conversation.append({\"role\": \"assistant\", \"content\": ai_message})\n",
    "        \n",
    "        # Calculate cost\n",
    "        rates = self.pricing.get(self.model, self.pricing[\"gpt-3.5-turbo\"])\n",
    "        cost = (response.usage.prompt_tokens / 1000 * rates[\"input\"]) + \\\n",
    "               (response.usage.completion_tokens / 1000 * rates[\"output\"])\n",
    "        self.total_cost += cost\n",
    "        self.call_count += 1\n",
    "        \n",
    "        return {\"response\": ai_message, \"cost\": cost, \"total\": self.total_cost}\n",
    "\n",
    "# Demo\n",
    "tracker = CostTrackerChat()\n",
    "result = tracker.chat(\"What is Python?\")\n",
    "print(f\"Response: {result['response'][:80]}...\")\n",
    "print(f\"This call: ${result['cost']:.6f} | Total: ${result['total']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.2.1: Temperature Tester\n",
    "\n",
    "Create a tool that generates responses at different temperature settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_temperatures(prompt, temperatures=[0, 0.7, 1.5]):\n",
    "    print(f\"Prompt: '{prompt}'\\n\" + \"=\" * 50)\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temp,\n",
    "            max_tokens=100\n",
    "        )\n",
    "        label = \"Focused\" if temp == 0 else \"Balanced\" if temp == 0.7 else \"Creative\"\n",
    "        print(f\"\\nTemp {temp} ({label}):\")\n",
    "        print(response.choices[0].message.content)\n",
    "\n",
    "# Demo\n",
    "test_temperatures(\"Write a one-sentence description of a sunset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.2.2: Conversation Counter\n",
    "\n",
    "Build a chatbot that counts messages and tracks statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationCounter:\n",
    "    def __init__(self):\n",
    "        self.message_count = 0\n",
    "        self.total_words = 0\n",
    "        self.estimated_cost = 0.0\n",
    "    \n",
    "    def chat(self, message):\n",
    "        self.message_count += 1\n",
    "        self.total_words += len(message.split())\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": message}]\n",
    "        )\n",
    "        \n",
    "        ai_response = response.choices[0].message.content\n",
    "        self.total_words += len(ai_response.split())\n",
    "        self.estimated_cost += (response.usage.total_tokens / 1000) * 0.002\n",
    "        \n",
    "        return {\"response\": ai_response, \"words\": len(ai_response.split()), \"cost\": self.estimated_cost}\n",
    "    \n",
    "    def stats(self):\n",
    "        return {\"messages\": self.message_count, \"words\": self.total_words, \"cost\": self.estimated_cost}\n",
    "\n",
    "# Demo\n",
    "counter = ConversationCounter()\n",
    "result = counter.chat(\"Hello!\")\n",
    "print(f\"Response: {result['response']}\")\n",
    "print(f\"Stats: {counter.stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.2.3: Personality Switcher\n",
    "\n",
    "Create a chatbot with multiple personalities with different temperature settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalities = {\n",
    "    \"teacher\": {\"prompt\": \"You are a patient teacher.\", \"temp\": 0.3},\n",
    "    \"friend\": {\"prompt\": \"You are a casual friend.\", \"temp\": 0.9},\n",
    "    \"coach\": {\"prompt\": \"You are an energetic coach.\", \"temp\": 1.2}\n",
    "}\n",
    "\n",
    "class PersonalitySwitcher:\n",
    "    def __init__(self):\n",
    "        self.current = \"teacher\"\n",
    "        self.conversation = [{\"role\": \"system\", \"content\": personalities[self.current][\"prompt\"]}]\n",
    "    \n",
    "    def switch(self, personality):\n",
    "        if personality in personalities:\n",
    "            self.current = personality\n",
    "            self.conversation = [{\"role\": \"system\", \"content\": personalities[personality][\"prompt\"]}]\n",
    "            return f\"Switched to {personality}\"\n",
    "        return \"Unknown personality\"\n",
    "    \n",
    "    def chat(self, message):\n",
    "        self.conversation.append({\"role\": \"user\", \"content\": message})\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=self.conversation,\n",
    "            temperature=personalities[self.current][\"temp\"]\n",
    "        )\n",
    "        ai_response = response.choices[0].message.content\n",
    "        self.conversation.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "        return ai_response\n",
    "\n",
    "# Demo\n",
    "switcher = PersonalitySwitcher()\n",
    "print(switcher.chat(\"How do I learn Python?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.3.1: Token Predictor\n",
    "\n",
    "Build a tool that predicts token counts and compares to actual counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tokens(text):\n",
    "    char_est = len(text) // 4\n",
    "    word_est = int(len(text.split()) * 1.3)\n",
    "    return {'char': char_est, 'word': word_est, 'avg': (char_est + word_est) // 2}\n",
    "\n",
    "def test_prediction(prompt):\n",
    "    est = predict_tokens(prompt)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    actual = response.usage.prompt_tokens\n",
    "    error = abs(est['avg'] - actual)\n",
    "    \n",
    "    print(f\"Predicted: {est['avg']}, Actual: {actual}, Error: {error}\")\n",
    "    return error\n",
    "\n",
    "# Demo\n",
    "test_prediction(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.3.2: Response Timer\n",
    "\n",
    "Create a tool that tests how prompt length affects response time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_api_call(prompt):\n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    return elapsed, response.usage.total_tokens\n",
    "\n",
    "# Test different lengths\n",
    "prompts = [(\"Short\", \"Hi\"), (\"Medium\", \"Write a haiku\"), (\"Long\", \"Explain relativity in detail\")]\n",
    "\n",
    "for name, prompt in prompts:\n",
    "    elapsed, tokens = time_api_call(prompt)\n",
    "    print(f\"{name}: {elapsed:.2f}s, {tokens} tokens, {tokens/elapsed:.0f} tok/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.3.3: Model Comparison\n",
    "\n",
    "Build a tool that compares responses from different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(prompt, models=[\"gpt-3.5-turbo\"]):\n",
    "    print(f\"Prompt: '{prompt}'\\n\")\n",
    "    for model in models:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=100\n",
    "            )\n",
    "            tokens = response.usage.total_tokens\n",
    "            cost = tokens * 0.002 / 1000 if 'gpt-3.5' in model else tokens * 0.03 / 1000\n",
    "            print(f\"{model}: {tokens} tokens, ${cost:.6f}\")\n",
    "            print(f\"  {response.choices[0].message.content[:80]}...\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"{model}: Error - {e}\")\n",
    "\n",
    "# Demo\n",
    "compare_models(\"Write a haiku\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.4.1: Error Logger\n",
    "\n",
    "Create an error logging system for API errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "class ErrorLogger:\n",
    "    def __init__(self):\n",
    "        self.errors = []\n",
    "    \n",
    "    def log(self, error, context=\"\"):\n",
    "        self.errors.append({\n",
    "            'time': datetime.now().isoformat(),\n",
    "            'type': type(error).__name__,\n",
    "            'message': str(error)[:100],\n",
    "            'context': context\n",
    "        })\n",
    "    \n",
    "    def report(self):\n",
    "        if not self.errors:\n",
    "            return \"No errors logged\"\n",
    "        counts = Counter(e['type'] for e in self.errors)\n",
    "        return f\"Errors: {len(self.errors)}\\n\" + \"\\n\".join(f\"  {t}: {c}\" for t, c in counts.items())\n",
    "\n",
    "# Demo\n",
    "logger = ErrorLogger()\n",
    "try:\n",
    "    raise ValueError(\"Test error\")\n",
    "except Exception as e:\n",
    "    logger.log(e, \"Testing\")\n",
    "print(logger.report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.4.2: Resilient Caller\n",
    "\n",
    "Build an adaptive API caller with health-based parameter adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResilientCaller:\n",
    "    def __init__(self):\n",
    "        self.health = 100\n",
    "        self.errors = 0\n",
    "        self.successes = 0\n",
    "    \n",
    "    def call(self, messages):\n",
    "        # Adjust params based on health\n",
    "        max_tokens = None if self.health > 80 else 100 if self.health > 50 else 50\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "            self.successes += 1\n",
    "            self.health = min(100, self.health + 5)\n",
    "            return response.choices[0].message.content, None\n",
    "        except Exception as e:\n",
    "            self.errors += 1\n",
    "            self.health = max(0, self.health - 20)\n",
    "            return None, str(e)\n",
    "    \n",
    "    def status(self):\n",
    "        state = \"Healthy\" if self.health > 80 else \"Degraded\" if self.health > 50 else \"Critical\"\n",
    "        return f\"{state} ({self.health}%), Errors: {self.errors}, Successes: {self.successes}\"\n",
    "\n",
    "# Demo\n",
    "caller = ResilientCaller()\n",
    "result, error = caller.call([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "print(f\"Result: {result}\")\n",
    "print(f\"Status: {caller.status()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.4.3: Circuit Breaker\n",
    "\n",
    "Implement the circuit breaker pattern for API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class State(Enum):\n",
    "    CLOSED = \"CLOSED\"\n",
    "    OPEN = \"OPEN\"\n",
    "    HALF_OPEN = \"HALF_OPEN\"\n",
    "\n",
    "class CircuitBreaker:\n",
    "    def __init__(self, threshold=3, timeout=30):\n",
    "        self.state = State.CLOSED\n",
    "        self.failures = 0\n",
    "        self.threshold = threshold\n",
    "        self.timeout = timeout\n",
    "        self.last_failure = None\n",
    "    \n",
    "    def call(self, messages):\n",
    "        if self.state == State.OPEN:\n",
    "            if self.last_failure and (datetime.now() - self.last_failure).seconds >= self.timeout:\n",
    "                self.state = State.HALF_OPEN\n",
    "            else:\n",
    "                return None, \"Circuit OPEN\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=messages\n",
    "            )\n",
    "            if self.state == State.HALF_OPEN:\n",
    "                self.state = State.CLOSED\n",
    "            self.failures = 0\n",
    "            return response.choices[0].message.content, None\n",
    "        except Exception as e:\n",
    "            self.failures += 1\n",
    "            self.last_failure = datetime.now()\n",
    "            if self.failures >= self.threshold:\n",
    "                self.state = State.OPEN\n",
    "            return None, str(e)\n",
    "\n",
    "# Demo\n",
    "cb = CircuitBreaker()\n",
    "result, error = cb.call([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "print(f\"Result: {result}\")\n",
    "print(f\"State: {cb.state.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.5.1: Topic Tracker\n",
    "\n",
    "Create a class that tracks conversation topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class TopicTracker:\n",
    "    def __init__(self):\n",
    "        self.topics = Counter()\n",
    "        self.keywords = {\n",
    "            'programming': ['code', 'python', 'function', 'variable'],\n",
    "            'ai': ['ai', 'machine learning', 'neural', 'model'],\n",
    "            'data': ['data', 'database', 'sql', 'analysis']\n",
    "        }\n",
    "    \n",
    "    def analyze(self, message):\n",
    "        msg_lower = message.lower()\n",
    "        detected = []\n",
    "        for topic, kws in self.keywords.items():\n",
    "            if any(kw in msg_lower for kw in kws):\n",
    "                detected.append(topic)\n",
    "                self.topics[topic] += 1\n",
    "        return detected or ['general']\n",
    "    \n",
    "    def report(self):\n",
    "        if not self.topics:\n",
    "            return \"No topics tracked\"\n",
    "        total = sum(self.topics.values())\n",
    "        return \"\\n\".join(f\"{t}: {c/total*100:.0f}%\" for t, c in self.topics.most_common())\n",
    "\n",
    "# Demo\n",
    "tracker = TopicTracker()\n",
    "tracker.analyze(\"How do I write Python code?\")\n",
    "tracker.analyze(\"What is machine learning?\")\n",
    "print(tracker.report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.5.2: Response Timer Class\n",
    "\n",
    "Build a class that monitors API response performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class ResponseTimer:\n",
    "    def __init__(self, slow_threshold=2.0):\n",
    "        self.times = []\n",
    "        self.slow_threshold = slow_threshold\n",
    "    \n",
    "    def start(self):\n",
    "        return time.time()\n",
    "    \n",
    "    def end(self, start):\n",
    "        elapsed = time.time() - start\n",
    "        self.times.append(elapsed)\n",
    "        return elapsed\n",
    "    \n",
    "    def stats(self):\n",
    "        if not self.times:\n",
    "            return \"No data\"\n",
    "        return {\n",
    "            'avg': sum(self.times) / len(self.times),\n",
    "            'min': min(self.times),\n",
    "            'max': max(self.times),\n",
    "            'slow': sum(1 for t in self.times if t > self.slow_threshold)\n",
    "        }\n",
    "\n",
    "# Demo\n",
    "timer = ResponseTimer()\n",
    "start = timer.start()\n",
    "client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hi\"}])\n",
    "print(f\"Elapsed: {timer.end(start):.2f}s\")\n",
    "print(f\"Stats: {timer.stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.5.3: Mood Detector\n",
    "\n",
    "Create a class that detects user mood and adjusts responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoodDetector:\n",
    "    def __init__(self):\n",
    "        self.moods = {\n",
    "            'happy': (['happy', 'great', 'awesome', 'love'], 'enthusiastic'),\n",
    "            'sad': (['sad', 'depressed', 'unhappy'], 'supportive'),\n",
    "            'angry': (['angry', 'frustrated', 'annoyed'], 'calm'),\n",
    "            'confused': (['confused', 'unclear', 'lost'], 'patient')\n",
    "        }\n",
    "        self.current = 'neutral'\n",
    "    \n",
    "    def detect(self, message):\n",
    "        msg_lower = message.lower()\n",
    "        for mood, (words, _) in self.moods.items():\n",
    "            if any(w in msg_lower for w in words):\n",
    "                self.current = mood\n",
    "                return mood\n",
    "        self.current = 'neutral'\n",
    "        return 'neutral'\n",
    "    \n",
    "    def style(self):\n",
    "        if self.current in self.moods:\n",
    "            return self.moods[self.current][1]\n",
    "        return 'balanced'\n",
    "\n",
    "# Demo\n",
    "detector = MoodDetector()\n",
    "for msg in [\"I'm frustrated!\", \"This is awesome!\", \"Help me please\"]:\n",
    "    mood = detector.detect(msg)\n",
    "    print(f\"'{msg[:20]}...' -> {mood} (be {detector.style()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.6.1: Export Master\n",
    "\n",
    "Create a class that exports conversations to multiple formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class ExportMaster:\n",
    "    def to_html(self, messages, filename=\"export.html\"):\n",
    "        html = \"<html><body><h1>Conversation</h1>\"\n",
    "        for m in messages:\n",
    "            label = \"You\" if m['role'] == 'user' else \"AI\"\n",
    "            html += f\"<p><b>{label}:</b> {m['content']}</p>\"\n",
    "        html += \"</body></html>\"\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(html)\n",
    "        return filename\n",
    "    \n",
    "    def to_csv(self, messages, filename=\"export.csv\"):\n",
    "        with open(filename, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Role', 'Content', 'Words'])\n",
    "            for m in messages:\n",
    "                writer.writerow([m['role'], m['content'], len(m['content'].split())])\n",
    "        return filename\n",
    "    \n",
    "    def to_markdown(self, messages, filename=\"export.md\"):\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(\"# Conversation\\n\\n\")\n",
    "            for m in messages:\n",
    "                label = \"You\" if m['role'] == 'user' else \"AI\"\n",
    "                f.write(f\"### {label}\\n{m['content']}\\n\\n\")\n",
    "        return filename\n",
    "\n",
    "# Demo\n",
    "sample = [{\"role\": \"user\", \"content\": \"Hi\"}, {\"role\": \"assistant\", \"content\": \"Hello!\"}]\n",
    "exporter = ExportMaster()\n",
    "print(f\"HTML: {exporter.to_html(sample)}\")\n",
    "print(f\"CSV: {exporter.to_csv(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.6.2: Smart Organizer\n",
    "\n",
    "Build a class that organizes conversations by topic and date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "class SmartOrganizer:\n",
    "    def __init__(self, storage=\"organized\"):\n",
    "        self.storage = Path(storage)\n",
    "        self.storage.mkdir(exist_ok=True)\n",
    "    \n",
    "    def detect_topic(self, messages):\n",
    "        keywords = {'programming': ['code', 'python'], 'ai': ['ai', 'learning']}\n",
    "        for m in messages:\n",
    "            if m['role'] == 'user':\n",
    "                for topic, kws in keywords.items():\n",
    "                    if any(kw in m['content'].lower() for kw in kws):\n",
    "                        return topic\n",
    "        return 'general'\n",
    "    \n",
    "    def organize(self, messages):\n",
    "        topic = self.detect_topic(messages)\n",
    "        topic_dir = self.storage / topic\n",
    "        topic_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filepath = topic_dir / f\"conv_{timestamp}.json\"\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump({'topic': topic, 'messages': messages}, f)\n",
    "        \n",
    "        return {'topic': topic, 'file': str(filepath)}\n",
    "\n",
    "# Demo\n",
    "organizer = SmartOrganizer()\n",
    "sample = [{\"role\": \"user\", \"content\": \"How do I write Python code?\"}]\n",
    "print(organizer.organize(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8.6.3: History Analytics\n",
    "\n",
    "Create a class that analyzes conversation history for insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import statistics\n",
    "\n",
    "class HistoryAnalytics:\n",
    "    def __init__(self):\n",
    "        self.conversations = []\n",
    "    \n",
    "    def add(self, messages):\n",
    "        self.conversations.append({'messages': messages, 'count': len(messages)})\n",
    "    \n",
    "    def topics(self):\n",
    "        stop_words = {'the', 'is', 'a', 'to', 'for', 'what', 'how'}\n",
    "        words = Counter()\n",
    "        for conv in self.conversations:\n",
    "            for m in conv['messages']:\n",
    "                if m['role'] == 'user':\n",
    "                    for w in m['content'].lower().split():\n",
    "                        if len(w) > 3 and w not in stop_words:\n",
    "                            words[w.strip('.,!?')] += 1\n",
    "        return words.most_common(5)\n",
    "    \n",
    "    def lengths(self):\n",
    "        counts = [c['count'] for c in self.conversations]\n",
    "        if not counts:\n",
    "            return \"No data\"\n",
    "        return {'avg': statistics.mean(counts), 'min': min(counts), 'max': max(counts)}\n",
    "\n",
    "# Demo\n",
    "analytics = HistoryAnalytics()\n",
    "analytics.add([{\"role\": \"user\", \"content\": \"How do I learn Python?\"}])\n",
    "analytics.add([{\"role\": \"user\", \"content\": \"Explain Python functions\"}])\n",
    "print(f\"Topics: {analytics.topics()}\")\n",
    "print(f\"Lengths: {analytics.lengths()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this chapter you learned to build LLM applications with:\n",
    "- Basic API calls and chatbots\n",
    "- Temperature and token management\n",
    "- Error handling and resilience patterns\n",
    "- Conversation analysis and export\n",
    "\n",
    "Next: **Chapter 9: Prompt Engineering**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
